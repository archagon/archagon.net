<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Archagon Was Here (Jekyll Test)</title>
    <description>Archagon was here... or was he? Yes, he was. This is Alexei Baboulevitch&#39;s personal blog webspacehomepage, featuring writing on software development, travel, photography, and more.
</description>
    <link>http://beta-blog.archagon.net/</link>
    <atom:link href="http://beta-blog.archagon.net/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 02 Jan 2017 11:44:13 -0800</pubDate>
    <lastBuildDate>Mon, 02 Jan 2017 11:44:13 -0800</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>Cheap and Painless eGPU Thrills on a 2013 MacBook Pro</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/egpu/egpu.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My late-2013 15” MacBook Pro’s discrete GPU — an NVIDIA GeForce GT 750M — was pretty good for gaming during the first year of its life.  But around the time that the new generation of consoles dropped, AAA games on the PC started becoming unplayable, even at postage-stamp resolutions with the lowest possible settings. I lived on a strict diet of indie games from 2015 to 2016 — thank goodness for well-tuned titles like Overwatch and The Witness! — but the itch to try games like the new Mirror’s Edge and Deus Ex became too great. Initially, I thought it might be time to switch out my MacBook for the upcoming 2016 model, but the winter reveal wasn’t particularly tempting: CPU performance was about the same as mine and the GPU was — at best — 3 times as powerful. (Still need to see the benchmarks on that — educated guess.) Worth it for a few hundred bucks, but $2000? No way! &lt;/p&gt;

&lt;p&gt;Building a gaming PC wasn’t an option due to my mobile lifestyle, and in any case the kind of CPU I could buy for cheap would be comically underpowered compared to the i7 4850HQ I already had in front of me. So I started looking into the scary world of external Thunderbolt GPUs, colloquially known as eGPU. Modern Thunderbolt 3 (allegedly) supports external GPUs in an official capacity, but older Thunderbolt 2 can get the job done as well, even though it’s unsanctioned by Intel. I’m usually reluctant to pursue these sorts of under-the-radar hobbyist projects, but there was enough prior art to make it worth a shot!&lt;/p&gt;

&lt;p&gt;Unlike many gaming enthusiasts, my goal was to optimize for simplicity over power: the fewer hacks and workarounds I had to use, the better. I already knew I’d have to use an external monitor and do my gaming in BootCamp, which was already the case. I knew there would be some performance loss from the limited bandwidth of TB2. I gathered that there may be timing issues and other problems that would require a bevy of software hacks to fix — mostly on the Windows side of things. But I was most concerned about the hardware hacking required to get the thing up and running in the first place.&lt;/p&gt;

&lt;p&gt;The majority of published eGPU builds involve enormous graphics cards connected to hotwired desktop PSUs, sitting in unseemly, torn-apart Thunderbolt-to-PCI chassises. It was clear that the anointed case for the job was the &lt;a href=&quot;http://amzn.to/2itWCP9&quot;&gt;Akitio Thunder2&lt;/a&gt;. The Thunder2 wasn’t designed for eGPU use, but dozens of eGPU enthusiasts on forums like &lt;a href=&quot;https://www.techinferno.com/index.php?/forums/forum/83-diy-e-gpu-projects/&quot;&gt;TechInferno&lt;/a&gt; demonstrated that it ran stable and performed admirably. (Akitio engineers even popped in on occasion to offer under-the-table eGPU advice — off-warranty, of course.) It was also one of the cheapest options on the market at around $200: very fair considering that a barebones development Thunderbolt 2 board cost nearly as much!&lt;/p&gt;

&lt;p&gt;Most eGPU builders buy this case to hack up, not to use as-is. Usually, the front panel is bent back or removed to fit larger cards, and then a desktop PSU is made to turn on with a paperclip and adapted to fit the DC plug. There are also arcane startup rituals to get everything powered and running with the right timing. I really didn’t want to have a PSU octopus and a ragged hunk of metal sitting bare on my table, though it sadly seemed inevitable. Then I discovered an alternate route.&lt;/p&gt;

&lt;p&gt;Most GPUs are power hogs that rely on one or two extra power ports on top of the card, but there are a few designed to pull power straight from the PCI slot. These aren’t super-extreme gaming cards, but these days they more than get the job done. For example, the just-released NVIDIA GeForce GTX 1050 Ti does 60fps/1080p at very high settings in most modern games and currently benchmarks as the ~40th best video card on the market! Better yet, many of these single-slot offerings are short and half as long as the monster enthusiast cards, easily fitting into Akitio’s compact case without any modifications. Using this type of card, I’d be able to keep my Thunder2 in one piece and avoid using a PSU entirely. No hacks required!&lt;/p&gt;

&lt;p&gt;At peak, these slot-powered cards can draw 75W from the PCI Express slot. Unfortunately, the Akitio Thunder2 only comes with a 60W adaptor, 30W of which is allocated to the circuitry. A dead-end? Not so fast: &lt;a href=&quot;https://www.akitio.com/faq/270-thunder2-pcie-box-what-s-the-maximum-power-output-through-the-pcie-slot&quot;&gt;as stated in the official docs&lt;/a&gt; and verified by employees, the Thunder2 can actually pull as much as 120W from a more powerful adaptor. To be compatible, the new power brick needs to sport a 5.5×2.5mm barrel plug, provide 12V output, and have &lt;a href=&quot;https://en.wikipedia.org/wiki/Polarity_symbols&quot;&gt;center positive polarity&lt;/a&gt;. (Practically every power adaptor has these last two items listed on the back.) My hope was to find a laptop power brick with these same specs, but it turned out that most laptops used chargers with an all-too-high output of 20V. Surprisingly, well-reviewed 12V/10A bricks weren’t common at all on Amazon (unless you &lt;a href=&quot;https://www.amazon.de/Netzteil-Laufwerke-Lichtschläuche-LED-Strips-geeignet/dp/B006Z9TQE6&quot;&gt;lived in the UK or Europe&lt;/a&gt;), with most of the listings taken up by rebranded versions of a sketchy-looking adaptor with model number CT-1250. Eventually, I discovered one vendor who was selling bricks with model number CD120100A, which had a more confident label and looked identical to a power brick I saw in another successful closed-case Akitio build. (The Amazon listing was full of typos and the product photos didn’t match the user photos, but it just so happened that the adaptor in the user photos was exactly the one I was hoping to find — and Prime allowed for painless returns in any case.) If the US 12V/10A adaptor market was really dominated by CT-1250 and CD120100A, the latter just seemed like a better bet.&lt;/p&gt;

&lt;p&gt;For the graphics card, I decided to give the &lt;a href=&quot;http://amzn.to/2itNpGC&quot;&gt;EVGA factory-overclocked version of the 1050 Ti&lt;/a&gt; a try, since one eGPU enthusiast mentioned that their EVGA card handled boot timing issues a bit better. (True or not, I’ve also had positive experiences with EVGA warranty and support in the past, so it was an easy decision.) Potentially, the overclock was a problem: the Akitio Thunder2 wouldn’t provide more than 75W of power to the slot, and any excess power pulled by the card could destabilize the system or even fry the circuitry (as reported by one user). But from everything I read, factory-overclocked EVGA cards were designed to never exceed the 75W threshold, and any instability could simply be fixed by underclocking the card slightly using EVGA’s (or possibly NVIDIA’s) own tools. Factor in the fact that the non-overclocked version cost exactly the same as overclocked while probably having lower resale value, and it became clear that the SC model was almost certainly the better buy — even if you dropped the clocks right from the get-go.&lt;/p&gt;

&lt;p&gt;(Note: many reviews will point out that the regular 1050 is a much better deal than the 1050 Ti from a price/performance perspective. Still, the Ti is about 20% faster than the non-Ti for just $20 more, and for the sake of future-proofing as well as TB2 performance loss it just makes sense to wring as much power from the purchase as possible.)&lt;/p&gt;

&lt;p&gt;Trawling eGPU forums for installation instructions was quite frustrating. Most users preferred to write about how they got their eGPUs working with their laptop displays (using Optimus drivers — possible with NVIDIA GTX cards) and/or in OSX. Both tasks involved copious scripts and hacks. I was only interested in the bare minimum — BootCamp on an external display — but most guides simply skipped that “easy” part. Would I need to make a custom build of Windows? Edit drivers? Install a custom bootloader? Nothing was clear, so I decided to just jump into it.&lt;/p&gt;

&lt;p&gt;Once I got all the parts assembled, I plugged the Thunder2 into my laptop and my monitor into the Thunder2, crossed my fingers, and turned on the computer while holding down the Alt key (for the boot menu — I already had BootCamp with the latest Windows 10 installed). At first… nothing. Just a black screen and no chime. I tried unplugging the cable, turning the machine on, waiting for the chime, and &lt;em&gt;then&lt;/em&gt; plugging it in. The boot menu showed up, but froze when I selected Windows. I tried one more time to boot with the cable plugged in and it worked! Or — at least, it booted into Windows. Nothing showed up on the external display, but the Windows Device Manager had a tempting entry named “Microsoft Basic Display Adapter”. Hopeful, I searched for other eGPU users who had gotten to this step, and it became apparent that all I had to do was install the latest NVIDIA drivers. One reboot later (with no issues this time) and I was seeing “NVIDIA GTX 1050 Ti” in my Device Manager. I gave Overwatch a quick run on the highest settings, but performance didn’t seem particularly great; my suspicion was that the laptop defaulted to the discrete 750M instead of the eGPU. I returned to Device Manager and disabled the 750M, restarted Overwatch, and… 60fps! It actually worked! Holy cow!&lt;/p&gt;

&lt;p&gt;eGPU setup can be daunting depending on your hardware, but I seem to have gotten away with a problem-free configuration. The “hardest” part is getting the computer to chime on boot, presumably indicating that POST went correctly. This involves turning the computer off and on again one or two times in the worst case: if it chimes and the boot menu appears, everything is sure to work fine. (Recently, I’ve been getting the boot menu on first try 100% of the time. Maybe I was just impatient before!) Once booted into Windows, I’ve learned that simply changing the display settings to only use the external monitor, or to extend the desktop and use the external monitor as the main monitor, ensures that the eGPU is used over the discrete chip. (And I believe Windows remembers this preference when you launch with the eGPU connected.)&lt;/p&gt;

&lt;p&gt;Now for some benchmarks! The main bottleneck in this setup is the TB2 connection. TB2 doesn’t allow for the full PCIe x16 throughput, potentially crippling graphics card performance. In practice, this isn’t really that big of a deal: users have reported at most a 20% performance loss over native, and usually a bit less. Let’s see how well we do.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;tablecontainer&quot;&gt;
&lt;div class=&quot;tablepadding&quot;&gt;
&lt;table&gt;

&lt;colgroup&gt;
&lt;col class=&quot;ch&quot; /&gt;
&lt;col span=&quot;3&quot; class=&quot;data&quot; /&gt;
&lt;/colgroup&gt;

&lt;tbody&gt;

&lt;tr class=&quot;rh&quot;&gt;
&lt;td class=&quot;corner&quot;&gt;&lt;/td&gt;
&lt;th&gt;GTX 1050 Ti SC&lt;/th&gt;
&lt;th&gt;GT 750M&lt;/th&gt;
&lt;th&gt;Improvement&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;3DMark Fire Strike&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics Score&lt;/th&gt;
&lt;td&gt;6993&lt;/td&gt;
&lt;td&gt;1911&lt;/td&gt;
&lt;td&gt;3.66×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 1&lt;/th&gt;
&lt;td&gt;32.28&lt;/td&gt;
&lt;td&gt;8.74&lt;/td&gt;
&lt;td&gt;3.69×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 2&lt;/th&gt;
&lt;td&gt;28.74&lt;/td&gt;
&lt;td&gt;7.96&lt;/td&gt;
&lt;td&gt;3.61×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;3DMark Time Spy&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics Score&lt;/th&gt;
&lt;td&gt;2040&lt;/td&gt;
&lt;td&gt;450&lt;/td&gt;
&lt;td&gt;4.53×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 1&lt;/th&gt;
&lt;td&gt;13.67&lt;/td&gt;
&lt;td&gt;3.00&lt;/td&gt;
&lt;td&gt;4.56×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 2&lt;/th&gt;
&lt;td&gt;11.43&lt;/td&gt;
&lt;td&gt;2.54&lt;/td&gt;
&lt;td&gt;4.50×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;3DMark Sky Dive&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics Score&lt;/th&gt;
&lt;td&gt;22564&lt;/td&gt;
&lt;td&gt;5602&lt;/td&gt;
&lt;td&gt;4.03×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 1&lt;/th&gt;
&lt;td&gt;102.25&lt;/td&gt;
&lt;td&gt;26.41&lt;/td&gt;
&lt;td&gt;3.87×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 2&lt;/th&gt;
&lt;td&gt;103.83&lt;/td&gt;
&lt;td&gt;24.80&lt;/td&gt;
&lt;td&gt;4.19×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;3DMark11 Free&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics Score&lt;/th&gt;
&lt;td&gt;8802&lt;/td&gt;
&lt;td&gt;2445&lt;/td&gt;
&lt;td&gt;3.60×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 1&lt;/th&gt;
&lt;td&gt;42.83&lt;/td&gt;
&lt;td&gt;11.27&lt;/td&gt;
&lt;td&gt;3.80×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 2&lt;/th&gt;
&lt;td&gt;42.18&lt;/td&gt;
&lt;td&gt;11.40&lt;/td&gt;
&lt;td&gt;3.70×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 3&lt;/th&gt;
&lt;td&gt;54.32&lt;/td&gt;
&lt;td&gt;15.52&lt;/td&gt;
&lt;td&gt;3.50×&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 4&lt;/th&gt;
&lt;td&gt;25.13&lt;/td&gt;
&lt;td&gt;7.39&lt;/td&gt;
&lt;td&gt;3.40×&lt;/td&gt;
&lt;/tr&gt;

&lt;/tbody&gt;

&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Quite an upgrade! According to Passmark and other benchmark listings, a 1050 Ti should, under normal circumstances, be about 4.5× as powerful as a 750M. Factor in 10%-20% performance loss from the TB link and that’s exactly what we see in our results: a 4x boost on average.&lt;/p&gt;

&lt;p&gt;Even without any underclocking, stability has not been an issue. I’ve been playing hours of Crysis 3, Far Cry 4, and Mirror’s Edge Catalyst over the past few days and everything’s still working great. I’m keeping the case closed, but I don’t think there’s any real risk of overheating: the GPU fan is designed to funnel heat right out through the back and there’s an extra font fan build into the case anyway. According to 3DMark, temperature during benchmarking has been stable.&lt;/p&gt;

&lt;p&gt;I’m not interested in running any weird scripts to get Optimus drivers for the internal display working, but I learned something interesting while fiddling with the Windows display settings. If you set the multiple display setting to &lt;a href=&quot;/images/egpu/duplicate.png&quot;&gt;“Duplicate these displays”&lt;/a&gt;, it seems that somehow the eGPU gets used for both the internal and external display! Assuming I’m interpreting this finding correctly, this means that theoretically you could buy something like this &lt;a href=&quot;https://www.amazon.com/CompuLab-fit-Headless-Display-Emulator/dp/B00FLZXGJ6&quot;&gt;HDMI display emulator&lt;/a&gt; and use the eGPU on the internal display without an external monitor and without having to go through the hacky process of getting Optimus up and running. Unfortunately, there’s a performance penalty of about 20%-25% (according to my benchmarks) as well as approximately 0.25 seconds of latency, making this approach untenable for first-person shooters and other twitchy games. (I wonder if this is also the case with the Optimus driver route?)&lt;/p&gt;

&lt;p&gt;Another interesting finding: if you keep the discrete GPU enabled, there’s a setting in the NVIDIA control panel to &lt;a href=&quot;/images/egpu/physx.png&quot;&gt;dedicate one of the GPUs to PhysX&lt;/a&gt;. I’m not sure if this will make a real difference in performance or cause stability issues, but it might be worth investigating in the future.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/egpu/egpu2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To summarize, using only…&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://amzn.to/2itWCP9&quot;&gt;An Akitio Thunder2 PCIe Box&lt;/a&gt; ($220)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://amzn.to/2itNpGC&quot;&gt;An EVGA GeForce GTX 1050 Ti SC&lt;/a&gt; ($140)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://amzn.to/2iQUoWJ&quot;&gt;A 120W 12V/10A power adaptor with a 5.5×2.5mm plug and center positive polarity&lt;/a&gt; ($35 — though buy it from a seller with Prime in case it’s the wrong one! This listing used to have a Prime seller, but I don’t see them anymore.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;…you can assemble a painless, hack-less eGPU build and use it with your late-2013 15” dGPU MacBook as a fairly cheap graphics upgrade. (Cheaper still if you wait for rebates or use an older/weaker X50 card.) &lt;strong&gt;Caveat emptor:&lt;/strong&gt; the same build might not work so well — or at all! — on other MacBook models or even with a different driver version. Remember that eGPU on TB2 is not officially supported and mostly works by accident, though clearly it can work very well.&lt;/p&gt;

&lt;p&gt;In time, I hope somebody releases a Thunderbolt 3 eGPU the size of one of those Square credit card readers — maybe sporting a GTX 980M caliber chip? — that plugs into a USB-C port and works seamlessly with the internal display. But for now, this lovely little eGPU will do just fine. I’m confident that my trusty MacBook can now serve me for another few years, especially if NVIDIA continues to release excellent and inexpensive PCI-powered cards on the regular. &lt;/p&gt;

&lt;p&gt;Let’s hope that the eGPU revolution is just beginning!&lt;/p&gt;

</description>
        <pubDate>Sat, 31 Dec 2016 18:18:54 -0800</pubDate>
        <link>http://beta-blog.archagon.net/2016/12/31/cheap-and-painless-egpu-thrills-on-a-2013-macbook-pro/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/12/31/cheap-and-painless-egpu-thrills-on-a-2013-macbook-pro/</guid>
        
        
        <category>technology</category>
        
      </item>
    
      <item>
        <title>Turning Your macOS Desktop into a Rotating Art Gallery with Backgroundifier</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/title_2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The category of static visual art is in a bit of an awkward phase right now. Entertainment in the 21st century has evolved to actively engage our minds and senses, to the point where movies, music, games, and even audiobooks require little more than putting on a pair of headphones or fixing our vision to the nearest screen. Where does the immense body of work from genres such as fine art, photography, and illustration fit into this world? Museums — physical beasts that they are — can hardly be visited on a whim, and as of yet there’s (sadly) no Spotify for visual art. Meanwhile, hundreds of amazing works are posted daily on Instagram, DeviantArt, and Reddit. How do we find the time to fit them into our content-saturated lives? And how do we return to view the works we’ve already enjoyed?&lt;/p&gt;

&lt;p&gt;For several years, I wanted to create a sort of “digital museum” that would give me random, on-demand access to this very important side of the art world. The constraints weren’t complicated. All I needed was a large amount of art along with a mechanism that would randomly show me new works from this collection every fifteen minutes or so. But while acquiring the art was hardly a problem, there were relatively few areas in my life where I could idly display images. Screensavers? Showed up too infrequently and weren’t easily controllable. Wallpapers? Couldn’t deal with arbitrary aspect ratios. I thought I had my solution when I ran the &lt;a href=&quot;http://www.google.com/culturalinstitute/beta/project/art-camera&quot;&gt;Google Art Project&lt;/a&gt; in a full-screen browser tab on a second monitor, but the selection turned out to be too limited and I could no longer rely on the luxury of having more than one display when I set out on my travels.&lt;/p&gt;

&lt;p&gt;(As an aside, Clay Bavor solved this exact problem in hardware by creating a &lt;a href=&quot;http://www.claybavor.com/?p=407&quot;&gt;digital photo frame that automatically compensated for ambient light&lt;/a&gt;. Amazing solution! But I’m a software guy, so…)&lt;/p&gt;

&lt;p&gt;After discovering Chris Tomkins-Tinch’s &lt;a href=&quot;https://itunes.apple.com/us/app/artful/id940324777?ls=1&amp;amp;mt=12&amp;amp;at=1000lqfI&quot;&gt;Artful app&lt;/a&gt; which turned your desktop wallpaper into a rotating collection of fine art, I realized that I had given the humble desktop too little consideration. With a simple Gaussian blur, a soft drop shadow, and a sprinkle of magic, it was in fact quite simple to create dynamic backgrounds for images at practically any aspect ratio. But Artful was designed to automatically pull images from proprietary sources, whereas I already had a sizable “inspiration” folder of collected art that I wanted to add to the mix. I also wished to keep my system as clean and simple as possible: Artful interfaced directly with your system preferences, but I much preferred to just keep a wallpaper folder that I’d occasionally drop new images into. And so a new app was born: &lt;a href=&quot;https://itunes.apple.com/us/app/backgroundifier/id1040333206?mt=12&amp;amp;at=1000lqfI&quot;&gt;Backgroundifier&lt;/a&gt;, a native converter droplet that let you easily turn arbitrary images into lovely desktop wallpapers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/sample.jpg&quot; width=&quot;900px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Just having this app around increased my consumption of art tremendously. But it wasn’t enough. I wanted to bridge the gap between finding an image on the web and having it appear in my desktop rotation, and I also wanted to be able to show new works of art on a whim. Fortunately, macOS is no slouch! Using Backgroundifier’s command-line mode, Automator, and the native power of Mission Control and Spaces, I’ve finally been able to create the digital museum experience I’ve always wanted.&lt;/p&gt;

&lt;p&gt;Naturally, the process begins with finding the art.&lt;/p&gt;

&lt;h2 id=&quot;wheres-the-art&quot;&gt;Where’s the Art?&lt;/h2&gt;

&lt;p&gt;Some people want their art carefully curated, and there are a number of existing apps and services for that. (See the aforementioned &lt;a href=&quot;https://itunes.apple.com/us/app/artful/id940324777?ls=1&amp;amp;mt=12&amp;amp;at=1000lqfI&quot;&gt;Artful&lt;/a&gt; and the &lt;a href=&quot;http://www.google.com/culturalinstitute/beta/project/art-camera&quot;&gt;Google Art Project&lt;/a&gt;.) Not me, though! I want everything in my wallpaper shuffle: the “great artists” of the past; modern digital and concept art; Russian textbook illustrations; architectural photography. Much of my daily discoveries come from Reddit, and though the site &lt;em&gt;is&lt;/em&gt; an awful cesspool in many respects, subs like &lt;a href=&quot;https://www.reddit.com/r/ImaginaryLandscapes/top/&quot;&gt;r/imaginarylandscapes&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/CozyPlaces/top/&quot;&gt;r/cozyplaces&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/SpecArt/top/&quot;&gt;r/specart&lt;/a&gt; — and even plain old &lt;a href=&quot;https://www.reddit.com/r/Art/top/&quot;&gt;/r/art&lt;/a&gt; and &lt;a href=&quot;https://www.reddit.com/r/photographs/top/&quot;&gt;/r/photographs&lt;/a&gt; — make it all worthwhile. Whenever I run into an interesting new sub specializing in visual art, I immediately sort by the top posts of all time and pull my favorite images from that list. (Fun tip: if you ever run into an Imgur gallery that you particularly like, you can find a link at the bottom to download the entire collection as a zip! I’ve done this with things like Miyazaki backgrounds.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/download.jpg&quot; width=&quot;849px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you’re interested in scouring some of the &lt;em&gt;less savory&lt;/em&gt; parts of the web, there are Russian torrent sites featuring comprehensive collections of art from practically any famous artist or museum you could think of. There’s nothing particularly unethical about this approach — a lot of older art is at this point public domain, after all — and it’s quite an experience to drop “The Best of the Louvre” into your background rotation for a week.&lt;/p&gt;

&lt;p&gt;Running every single file through Backgroundifier and plonking it in your wallpaper folder is bound to be a chore. Fortunately, this can be entirely automated using Backgroundifier’s command-line mode and macOS’s native Automator.&lt;/p&gt;

&lt;h2 id=&quot;harnessing-the-command-line&quot;&gt;Harnessing the Command Line&lt;/h2&gt;

&lt;p&gt;Although Backgroundifier presents a user-friendly GUI, it can also be accessed through the command line. (To see how one can make such a dual-mode app in Swift, you can examine my code &lt;a href=&quot;https://github.com/archagon/backgroundifier-public/blob/master/Backgroundifier/main.swift&quot;&gt;here&lt;/a&gt;.) One way to do this is to navigate to your &lt;code&gt;Backgroundifier.app&lt;/code&gt; bundle in Terminal and run the Backgroundifier executable found in the &lt;code&gt;Contents/MacOS&lt;/code&gt; subdirectory. With the standard &lt;code&gt;--usage&lt;/code&gt; flag, you can view all the options available to you. (Some of these aren’t even accessible through the GUI!)&lt;/p&gt;

&lt;p&gt;The simplest way to process a file is to run &lt;code&gt;Backgroundifier -i /path/to/input_image.jpg -o /path/to/output_image.jpg -w 1920 -h 1080&lt;/code&gt;. Unfortunately, due to the fact that Backgroundifier is a sandboxed app, you can’t just do this for any random directory. Whereas a sandboxed GUI app can expand its sandbox to include any directories opened through the file picker or dropped directly onto it, command line apps (to my knowledge) have no such ability. You can therefore only process files located in your &lt;code&gt;~/Pictures&lt;/code&gt; directory.&lt;/p&gt;

&lt;p&gt;Fortunately, there’s another way. In the Resources directory of &lt;code&gt;Backgroundifier.app&lt;/code&gt; bundle, there’s a zip file containing a non-sandboxed, Developer ID signed version of the command line tool. Extract it and you can use it in any directory you please.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/bgify.png&quot; width=&quot;885px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;magic-folders-with-automator&quot;&gt;Magic Folders with Automator&lt;/h2&gt;

&lt;p&gt;Automator, macOS’s powerful visual scripting tool, can be used to create so-called “Folder Actions”, or workflows that run whenever the contents of a predetermined directory are changed. As you might expect, this is ideal for file conversion. Below is my Folder Action workflow for automatically “backgroundifying” images into a separate output directory:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/workflow.png&quot; width=&quot;629px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Item 2 contains the path to the output directory and item 3 contains the path to the Backgroundifier command line utility. (They exist as separate items to make the paths easy to modify without having to resort to scripting.) Here’s the full text for the script in item 3:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# assign paths
bgify=$1
output=$2

# remove path arguments
shift 2

# process images
for var in &quot;$@&quot;
do
    filename=$(basename &quot;$var&quot;)
    full_output=&quot;$output/$filename&quot;
    echo &quot;Processing $full_output ...&quot;
    &quot;$bgify&quot; -i &quot;$var&quot; -o &quot;$full_output&quot; -w 2560 -h 1600
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nothing too complicated! You can find the workflow file &lt;a href=&quot;/images/backgroundifier-gallery/Backgroundify.workflow.zip&quot;&gt;here&lt;/a&gt;, and I assume you can just drop it into your &lt;code&gt;~/Library/Workflows/Applications/Folder Actions&lt;/code&gt; directory. You can also pretty easily recreate it from scratch: just make a new Automator workflow with a Folder Action document type and copy the items.&lt;/p&gt;

&lt;p&gt;Whenever I find an interesting new image on Reddit, all I now have to do is drag-and-drop it straight from my browser into the designated Input directory on my desktop. macOS and Backgroundifier automatically take care of the rest.&lt;/p&gt;

&lt;h2 id=&quot;dealing-with-the-desktop&quot;&gt;Dealing with the Desktop&lt;/h2&gt;

&lt;p&gt;macOS’s desktop background settings allow us to pick a source directory and change the background to a random image at a set time interval (with 30 minutes being the default). All we really need to do here is drag the output directory from the previous step into our list, select it, check “Change picture” and “Random order”, and set our desired time interval.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/wallpaper.jpg&quot; width=&quot;668px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It’s no fun to manually move every window out of the way whenever you want to peek at your wallpaper. Fortunately, there are several macOS-native shortcuts for showing the desktop. One is to use a four-finger trackpad pinch, selectable under &lt;code&gt;Trackpad → More Gestures → Show Desktop&lt;/code&gt; in System Preferences. Personally, I prefer binding the action to a keyboard shortcut: &lt;code&gt;Command-Option-down&lt;/code&gt;, to go with my assigned &lt;code&gt;Command-Option-left&lt;/code&gt; and &lt;code&gt;right&lt;/code&gt; shortcuts for switching spaces. You can do this under &lt;code&gt;Keyboard → Shortcuts&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Some of us are… more messy than others. The desktop can acquire quite a bit of cruft over time, blocking view of the beautiful art below. But why bother cleaning it up when you can just sweep the mess under a rug? If you’re lazy like me, you can toggle visibility for the icons on your desktop by running &lt;a href=&quot;/images/backgroundifier-gallery/toggle_desktop.command.zip&quot;&gt;this simple script&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh
# Toggles desktop icons.

if [[ $(defaults read com.apple.finder CreateDesktop) = false ]]; then
    echo &quot;Showing desktop icons.&quot;
    defaults write com.apple.finder CreateDesktop true
else
    echo &quot;Hiding desktop icons.&quot;
    defaults write com.apple.finder CreateDesktop false
fi

killall Finder
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And voilà! Clutter-free art with hardly a fuss.&lt;/p&gt;

&lt;h2 id=&quot;spaces--showing-new-art&quot;&gt;Spaces &amp;amp; Showing New Art&lt;/h2&gt;

&lt;p&gt;Here’s where it all comes together. One my favorite macOS features is Spaces, or virtual desktops. Spaces have an extra hidden benefit for our use case: whenever a new Space is created, its desktop background settings are taken from the previous space. This means that any new Space created in our configuration will automatically arrive with a fresh work of art in tow!&lt;/p&gt;

&lt;p&gt;Whenever you wish to see a new work of art, just pop open Mission Control (in my case, bound to &lt;code&gt;Command-Option-up&lt;/code&gt;), create a few new Spaces, and keep switching Spaces to the right. It’s just like leafing through an art book!&lt;/p&gt;

&lt;video controls=&quot;&quot; width=&quot;800px&quot; poster=&quot;/images/backgroundifier-gallery/demo.jpg&quot;&gt;
	&lt;source src=&quot;/images/backgroundifier-gallery/demo.mp4&quot; type=&quot;video/mp4&quot; /&gt;
	Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;And that’s all it takes to create your own personal art gallery using &lt;a href=&quot;https://itunes.apple.com/us/app/backgroundifier/id1040333206?mt=12&amp;amp;at=1000lqfI&quot;&gt;Backgroundifier&lt;/a&gt;. No mysterious system overrides or hacks. No 3rd party tools of unknown provenance. Just a Unix-y converter, an Automator script, and a couple of native macOS features to tie it all together. &lt;/p&gt;

&lt;p&gt;It’s quite a thing knowing that a new, enriching artistic discovery — be it a Picasso, a Van Gogh, or even a Mike From Around The Web — is only a quick peek away!&lt;/p&gt;

</description>
        <pubDate>Mon, 19 Sep 2016 16:10:16 -0700</pubDate>
        <link>http://beta-blog.archagon.net/2016/09/19/backgroundifier-turning-your-macos-desktop-into-a-rotating-art-gallery/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/09/19/backgroundifier-turning-your-macos-desktop-into-a-rotating-art-gallery/</guid>
        
        
        <category>releases</category>
        
      </item>
    
      <item>
        <title>GoodNotes &amp; The Joys of Digital Note-Taking</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/header.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I have to admit: I’m an analog kind of fellow. Much as I benefit from our growing roster of digital tools, I’m always on the lookout for software that reminds me of reality’s imperfect grit. Fake mechanical clock faces. &lt;a href=&quot;http://fffff.at/noisy-typer-a-typewriter-for-your-laptop/&quot;&gt;Typewriter sounds&lt;/a&gt;. &lt;a href=&quot;http://www.secretgeometry.com/apps/cathode/&quot;&gt;Simulated CRT monitors&lt;/a&gt;! Some might call them skeumorphic, clunky, or even fraudulent; but in a world increasingly bent on making things shiny and pristine, I enjoy having a reminder of which side of the screen is the more important one.&lt;/p&gt;

&lt;p&gt;The same even applies to my work notes. No doubt, there are immense benefits to limiting your note-taking to professional software like OneNote or Google Docs, starting with obvious features like copy &amp;amp; paste and text search that we all rely on while taking completely for granted. But whenever I undertake a major project, any spare pieces of paper lying around (including napkins, envelopes, and candy wrappers) will inevitably become conscripted as scratch paper, despite the vast universe of affordances on the digital side of the divide. As much as I’ve tried to adopt my thinking to software, the cold, hard truth of digital type just doesn’t represent my thoughts very well. On paper, my ideas becomes non-linear: sometimes visually grouped with related bits of info, sometimes crawling up the sides, sometimes accompanied by quick sketches and diagrams.&lt;/p&gt;

&lt;p&gt;One day, after failing yet again to trace my line of thought in Evernote, I decided to just give in and buy myself a nice paper notebook. Despite my initial concerns about all the features I was giving up, the switch turned out to be remarkably liberating. I loved to dig around in my backpack for my latest set of notes; feel the ever-growing creases in the covers; flip past all the dog-eared pages. And of course, no app in the world could replicate the joy of jotting down a rickety diagram with ink flowing in its wake! It felt significant that I could hold in my hands a tangible artifact representing the course of my project, and I looked forward to the days when I would exhaust my current notebook and have to go shopping for a new one. The tactile pleasures of this simple thing couldn’t be reproduced by any computer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/notebook.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The digital world still beckoned, slightly. Largely spurred by my light-packing travels, most of my other media had become digital at this point. My work notes usually served the role of scratch paper, so I didn’t miss the search feature in Evernote too much. Still, it was a terrible shame that once a project was over, all these notebooks had to be thrown in a closet to gather dust in obscurity. I tried scanning bits of them in, but it was too much of a hassle.&lt;/p&gt;

&lt;p&gt;In September 2015, Apple announced the new iPad Pro along with their brand new stylus, the Apple Pencil. This was a necessary purchase for my work anyway, and so a new hope crossed my mind: could I finally reconcile the analog and digital worlds with this tech? Here was a tablet that could finally act like a digital pad of paper, sporting a glass-welded, ambient-light-adapting screen and a digitizer running at 120Hz with barely any latency. Just a few years before, you needed an enormous desk-sized piece of hardware to do the same thing — and people still complained about the lag. With the Apple Pencil, seemingly everyone (artists and reviewers alike) agreed that it was the closest thing to paper they’d ever tried.&lt;/p&gt;

&lt;p&gt;After receiving my new iPad, I started to search for a very specific kind of software. Plenty of great drawing apps were out already, but I wanted more than that. I wanted an app that would let me collect a roster of virtual notebooks, all sporting different shapes and covers. I wanted each notebook to have a variety of pages, customizable with their own type and texture. Most importantly, I wanted every notebook to exist as an open-format file on my Dropbox. Instead of relying on a proprietary app to access my notebooks, it was critical that I be able to leaf through them — and maybe even edit them! — using other software. It seemed that PDF might be suited for the task; I’d routinely used it for book scans to great effect, and I also knew that the underlying rendering technology — PostScript — was more than capable of displaying any manner of graphic. Perhaps there was an app that fused PDF creation and annotation with just the right amount of magic make it work?&lt;/p&gt;

&lt;p&gt;There were a good handful of contenders, but three names kept coming up: &lt;a href=&quot;https://itunes.apple.com/us/app/notability/id360593530?mt=8&amp;amp;at=1000lqfI&quot;&gt;Notability&lt;/a&gt;, &lt;a href=&quot;https://itunes.apple.com/us/app/noteshelf/id392188745?mt=8&amp;amp;at=1000lqfI&quot;&gt;Noteshelf&lt;/a&gt;, and &lt;a href=&quot;https://itunes.apple.com/us/app/goodnotes-4-notes-pdf/id778658393?mt=8&amp;amp;at=1000lqfI&quot;&gt;GoodNotes&lt;/a&gt;. None were perfect. Notability had many bells and whistles and was clearly the audience favorite, coming up in any thread where people were talking notes. Noteshelf was beautifully designed and seemed to be directly targeting my digital notebook use case, sporting flippable pages and an iBooks-like shelf for your notebooks. Unfortunately, both options felt fairly proprietary. If PDF export was even a feature, it was clearly treated in a throw-it-over-the-fence kind of way: the pristine copies of your notebooks only lived inside their respective app silos. Then there was GoodNotes. This was a subtle app without too much pizzaz and not overflowing with features. It almost resembled an Office-style product more than any of its hipper competitors. But the features it did offer were incredible.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/note.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First, GoodNotes stored your drawings as vectors instead of rasterizing them out. Every line, shape, and highlight you drew was retained as a pristine geometric shape, preserving your work for the ages and offering 100% clarity at any zoom level. Any text that you wrote would automatically get OCR-ed, allowing you to actually search through your notes if your handwriting was legible enough. Covers and pages could be swapped with ease to any image of your choosing, even in the middle of an existing notebook. (Templates such as graph paper and even musical staff paper were included.) The UI and gestures were bog-standard iOS, and accordingly intuitive: it took little effort to figure out how to manage your documents and create new content. You still got all the “parity features” offered by other note-taking apps such as typing, shapes, image support, and more, which weren’t particularly relevant to me but still felt like they could be useful on occasion. Then there was the kicker. Even though your notebooks weren’t stored &lt;em&gt;directly&lt;/em&gt; as PDF, you could opt to encode them into Dropbox right as you were working. The implementation here was simply remarkable. Each PDF produced was, functionally, a lossless copy of your notebook, harnessing the full power of PDF to reproduce every GoodNotes feature in full. Digging around in the generated file internals, I saw that everything was layered just as it was in the app. The background texture of each page was its own asset. Your writing was stored in its original vector form. &lt;em&gt;Even the OCR text was there&lt;/em&gt;, hidden from view but layered on top of the original text and searchable using most PDF software. This was as close to a perfect copy of your notebook as you could get, and I felt confident that my data would be perfectly safe were GoodNotes to ever go out of business.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/pages.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(It should be noted that there’s one downside to GoodNotes’ vector drawing approach: performance is proportional to the amount of content on the page. In most cases, this isn’t a problem: loading takes no time at all and drawing is lag-free. But if one of your pages is especially dense with translucent lines and complex shapes, it might take a second for everything to tile in. In practice, the tradeoff of having a lossless copy of your data versus fixed performance is well worth it. I can wait a second if it means that my writing will look as crisp 100 years from now as it does today.)&lt;/p&gt;

&lt;p&gt;It’s hard to deny that you lose something in moving away from the physical world. No amount of code will give back the glide of an ink pen across cream-colored paper or  the crinkle of a bound old set of pages. But you only trade one kind of magic for another. I can now switch colors and brush strokes in a snap. Mistakes can be erased and even undone with barely a thought. If I need to make a graph or draw some musical notes, I can switch out the “paper” I’m using to almost any other format — or even provide my own. And covers! Whereas in my paper notebook days, I could spend hours window-shopping for a cover with just the right look and feel, the joy of discovering the perfect vector image for the cover of my digital notebook comes very close indeed. Best of all, I now have a digital archive of all my notes without any extra work on my part. On finishing my work for the day, I can peek inside my Dropbox and leaf through a remarkable document featuring every paragraph, graph, and schematic I’d scribbled.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/preview.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Today, all my work-related notes are made directly on my iPad using &lt;a href=&quot;https://itunes.apple.com/us/app/goodnotes-4-notes-pdf/id778658393?mt=8&amp;amp;at=1000lqfI&quot;&gt;GoodNotes&lt;/a&gt;. And it’s just wonderful!&lt;/p&gt;

</description>
        <pubDate>Tue, 30 Aug 2016 13:26:53 -0700</pubDate>
        <link>http://beta-blog.archagon.net/2016/08/30/on-the-wonders-of-digital-journaling/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/08/30/on-the-wonders-of-digital-journaling/</guid>
        
        
        <category>technology</category>
        
      </item>
    
      <item>
        <title>Indie App Reliance</title>
        <description>&lt;p&gt;Today, &lt;a href=&quot;https://twitter.com/brentsimmons/status/767461318538383360&quot;&gt;with a single tweet&lt;/a&gt;, the note-taking app &lt;a href=&quot;http://vesperapp.co&quot;&gt;Vesper&lt;/a&gt; has officially been shuttered. At its release, Vesper was &lt;a href=&quot;https://marco.org/2013/06/06/vesper&quot;&gt;widely promoted&lt;/a&gt; by the &lt;a href=&quot;https://www.macstories.net/reviews/vesper-review-collect-your-thoughts/&quot;&gt;Apple indie developer communtiy&lt;/a&gt; as the hot new thing to try. More than anything else, it had an excellent pedigree, with influential blogger John Gruber of &lt;a href=&quot;http://daringfireball.net&quot;&gt;Daring Fireball&lt;/a&gt; at the helm. Many hopeful users switched to it for their primary note-taking needs, expecting that features like Mac support would arrive in short order. If any app from this circle was destined to be a breakaway hit, it was this one. And now, with barely a mention, it’s all but swept away, years after langishing with barely an update.&lt;/p&gt;

&lt;p&gt;This is not a post about why Vesper ultimately failed. There are plenty of others who will happily chat about the rusty economics of the App Store. Instead, I want to focus on the other end of this unfortunate feedback loop: the effect that these highly visible app shutdowns might have on App Store customers.&lt;/p&gt;

&lt;p&gt;Several bloggers have expressed curiosity as to why public interest in the App Store has waned so much. I can’t answer for everyone, but at least within myself, I’ve noticed an increasing and persistant reluctance to try new apps. It’s just that I’ve seen same pattern crop up over and over again. Somebody releases an interesting new app, touting fantastic design and improved productivity. The app gains some (but not overwhelming) traction. The app gets a few updates. The app lingers for a few years. And finally, the app untriumphantly rides off into the sunset, taking entire years of not just developer time, but thousands of users’ ingrained habits with it. The case is clear: most apps — and especially indie apps — cannot be reliably expected to continue operating.&lt;/p&gt;

&lt;p&gt;After being burned so many times by products that have been pulled out from under me, I’ve unconsciously adopted a worrying philosophy for trying new apps: unless the app I’m using is backed by a large corporation or is outright open-source, I’m not going to use it for anything particularly important in my life.  (And even then, certain corporations — ahem, Google — are put under further scrutiny.) I hate having to do this because many amazing UX advancements can be found in apps produced by smaller developers. (Apple folks love to talk about how certain categories of apps are &lt;a href=&quot;https://daringfireball.net/2009/04/twitter_clients_playground&quot;&gt;design playgrounds&lt;/a&gt;.) But at the same time, I know that with these apps, there is an inevitable sunset e-mail waiting for me in the not-too-distant future. It’s gotten so bad that I’m starting to seriously consider switching most of the (snappy, beautiful, well-designed) productivity apps on my phone over to their (ugly, clunky) open-source alternatives, just because I know that OpenWhatever will long outlive the current App Store darling for that category. (1Password is one hot spot that immediately comes to mind. Losing them would be a disaster.) I don’t want to worry every day about whether these proprietary silos will suddenly go up in flames with all my carefully-constructed workflows and data in tow.&lt;/p&gt;

&lt;p&gt;Despite the low prices on the App Store, I now get decision fatigue whenever I go to purchase an app. How long is this product going to be around? How reliable is this developer? How easy is it to export the data? How open are all the underlying formats and APIs? The price might be insignificant, but the commitment implied by my purchase is not trivial at all! Unfortunately, developers don’t seem to care much about the mental toll that pulling an app might cause, even when they were the ones touting life-changing productivity and workflow improvements in the first place. It’s one thing I miss about Windows utility software: so much of it is terribly designed, but at least I know it’ll run more or less forever. (Both on account of the open platform and Windows’ amazing legacy support.)&lt;/p&gt;

&lt;p&gt;It’s understandable why developers shut down their apps, but I wish there was another way out of this dead-end. Maybe apps could certify that all their back-end services are provided by external vendors and can be swapped out if necessary. (This is why I’m not too worried about apps like Reeder and Pocket Casts: I know that if they go away, I can take my precious data and switch right over to another app.) Maybe developers could pledge — even with legal backing! — to open-source their software if they ever decide to stop supporting it. Or going even further into this mythical socialist utopia, how about we finally figure out a way to fund open-source software from the get-go without having to beg for donations? With services like CloudKit, it’s no longer even necessary to spend a single cent of your money on servers. What’s the point of bringing something wonderful into the world if it only lasts for as long as people are willing to buy it? I can’t help but see that as hopelessly cynical.&lt;/p&gt;

&lt;p&gt;To be clear: I’m &lt;em&gt;not&lt;/em&gt; saying that developers should be expected to support and add features to their apps indefinitely. That would be a very extreme stance. But on the other end, adopting a scorched earth policy for your app once you tire of it is also pretty extreme and poisons the market to boot.&lt;/p&gt;

&lt;p&gt;Apps — products that encapsulate &lt;em&gt;years&lt;/em&gt; of people’s lives — should never outright disappear just because a developer can’t be bothered to support them anymore. If we don’t have that assurance, and if we can’t rely on our tools, all we’re doing is playing with toys.&lt;/p&gt;
</description>
        <pubDate>Sun, 21 Aug 2016 17:01:19 -0700</pubDate>
        <link>http://beta-blog.archagon.net/2016/08/21/tool-reliance/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/08/21/tool-reliance/</guid>
        
        
        <category>technology</category>
        
      </item>
    
      <item>
        <title>Composer&#39;s Sketchpad: Adventures in Icon Design</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/composers-sketchpad-icon/banner.png&quot; /&gt;&lt;/p&gt;

&lt;!-- TODO: move most of this to one of the global scss files --&gt;

&lt;style&gt;
.toc {
  margin-top: 2em;
  margin-bottom: 2em;
  padding: 1em;
  margin-left: auto;
  margin-right: auto;
  border-style: solid;
  border-width: 0.2em;
  border-color: #93d7ff;
  border-radius: 2em;
  width: 80%;
  background-color: #c6eaff; }

.toc_header {
  display: -webkit-box;
  display: -webkit-flex;
  display: -ms-flexbox;
  display: flex;
  -webkit-box-pack: center;
  -webkit-justify-content: center;
  -ms-flex-pack: center;
  justify-content: center;
  -webkit-box-align: center;
  -webkit-align-items: center;
  -ms-flex-align: center;
  align-items: center;
  -webkit-flex-direction: row;
  -ms-flex-direction: row;
  flex-direction: row; }

.toc_header {
  text-align: left;
  margin-bottom: 0.75em !important; }

.toc_header &gt; * {
  margin-top: 0 !important;
  margin-bottom: 0 !important;
  margin-left: 0.5em !important;
  margin-right: 0.5em !important;
  padding: 0; }

.toc_header :first-child {
  margin-left: 0 !important; }

.toc_header :last-child {
  margin-right: 0 !important; }

.toc_header &gt; p {
  font-family: &#39;Avenir Next&#39;, &#39;Helvetica&#39;, &#39;Arial&#39;, sans-serif;
  font-size: 1.1em;
  color: #444;
  font-weight: 500;
  /*line-height: 140%;*/ }

.toc_header &gt; a {
  min-width: 5em;
  max-width: 5em; }

.toc_links {
  /*text-align: center;*/ }

.toc_links &gt; ol {
  font-family: &#39;Avenir Next&#39;, &#39;Helvetica&#39;, &#39;Arial&#39;, sans-serif;
  font-size: 1.1em;
  font-weight: 500; }

.toc_links &gt; ol {
  margin: 0;
  list-style-position: inside;
  counter-reset: i 0; }

.toc_links li {
  padding: 0.15em 0.5em 0.15em 0.5em; }

.toc a {
  text-decoration: underline; }

&lt;/style&gt;

&lt;style&gt;
.toc_links &gt; ol li:nth-child(4) {
/*color: darkgreen;*/
color: green;
border-radius: 0.5em;
background-color: lightgreen;
/*border: 1px dashed green;*/
}
.toc_links &gt; ol li:nth-child(4) a {
text-decoration: none;
pointer-events: none;
cursor: default;
color: inherit;
text-decoration: inherit;
}
&lt;/style&gt;

&lt;p&gt;
&lt;div class=&quot;toc&quot;&gt;
    &lt;div class=&quot;toc_header&quot;&gt;
        &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;&lt;img src=&quot;/images/composers_sketchpad_icon.png&quot; /&gt;&lt;/a&gt;
        &lt;p&gt;This blog post is part of a series on the development of &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;Composer&#39;s Sketchpad&lt;/a&gt;, a new iPad app for making musical rough drafts and doodles.&lt;/p&gt;
    &lt;/div&gt;

    &lt;div class=&quot;toc_links&quot;&gt;
        &lt;ol&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/02/05/composers-sketchpad&quot;&gt;Rethinking Musical Notation with Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/02/27/path-rendering-in-composers-sketchpad&quot;&gt;Path Rendering in Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/03/24/liberating-pitch-and-taming-midi-in-composers-sketchpad/&quot;&gt;Liberating Pitch and Taming MIDI in Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/07/16/composers-sketchpad-adventures-in-icon-design/&quot;&gt;Composer&#39;s Sketchpad: Adventures in Icon Design&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://itunes.apple.com/us/app/composers-sketchpad/id978563657?mt=8&quot;&gt;Composer’s Sketchpad 1.2 is out&lt;/a&gt;! This is a major update with several new features, including audio export (via AAC), a new tool for shifting notes along the time axis, and a one-finger drawing mode. I figured this might be a good opportunity to write about something a bit more on the creative side: icon design!&lt;/p&gt;

&lt;p&gt;Having no practical design experience, I am very proud of the icon I created for Composer’s Sketchpad. A good icon is absolutely essential for marketing, so most app developers would recommend contracting out this delicate task to a real designer. But I’m stubborn: one of my higher-level goals in creating Composer’s Sketchpad was to get better at art and design, and I wanted the icon in particular — the thesis of my app! — to be my own invention.&lt;/p&gt;

&lt;p&gt;Going along with the idea that creativity flourishes under harsh constraints, these were the requirements I laid out for the icon:&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;important_list&quot;&gt;
    &lt;ul&gt;
      &lt;li&gt;It had to feature a reference to music.&lt;/li&gt;
      &lt;li&gt;It had to hint at the functionality, aesthetics, and interface of the app.&lt;/li&gt;
      &lt;li&gt;It had to roughly align within the iOS 7 icon grid while somehow subverting it.&lt;/li&gt;
      &lt;li&gt;It had to exhibit some dimensionality and flow. I didn’t want it to look flat or overly vectory.&lt;/li&gt;
      &lt;li&gt;It had to be logo-like: symbolic, bold, and simple.&lt;/li&gt;
      &lt;li&gt;But most importantly, &lt;strong&gt;it had to immediately catch the eye&lt;/strong&gt;. As a frequent App Store customer, I knew well enough that even a slightly uninteresting app icon would warrant a pass, while an interesting icon might make people peek at the app description without even knowing anything about it. The icon was &lt;em&gt;absolutely critical&lt;/em&gt; to my passive marketing. It was my calling card — the entirety of my app wrapped up in 512×512 pixels. No pressure!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Weeks before starting work on the icon, I began to keep tabs on other app icons that I found interesting. I was already following &lt;a href=&quot;http://www.musicappblog.com&quot;&gt;musicappblog.com&lt;/a&gt; religiously for music app news, so I scoured their archives for inspiration. I also carefully looked through all my home screens as well as the App Store top charts for non-music influences. In truth, even among the cream of the crop, there weren’t many icons that I outright loved. Most of the ones that caught my eye kept things relatively simple — outlines, primary colors, subtle gradients — while preserving the circular motif of the iOS 7 icon grid. (Many of these happened to be Apple icons.) There were also plenty of icons that failed at either extreme, either by cramming too much color and detail into the tiny square, or by not providing nearly enough detail to make a minimalist design stand out.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-icon/icon_inspiration.png&quot; width=&quot;498px&quot; /&gt;
&lt;p&gt;A few app icons I would consider eye-catching.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Inspiration in hand, I first made a number of rough pencil sketches, most of which depicted a prominent musical note with some embellishment. Quality was not a concern at this point: I wanted to jot down as many ideas as possible even if they didn’t seem to hold much promise. In the midst of this process, I found myself feeling fairly ambivalent towards most of the designs I came up with, though I knew they could probably be moulded into something that followed my rules. Something about them just didn’t feel right.&lt;/p&gt;

&lt;p&gt;I still didn’t have much of a sense how far my nascent design sensibilities could take me, and part of me started to give up hope of finding the perfect design. But when I came up with the sketch for the final swirly-tail icon (after running a few ideas by my folks — спасибо, мама!), everything suddenly clicked. I knew right then that this particular design would perfectly slot into the narrow niche defined by my requirements. For the first time, I thought that maybe I could pull this off!&lt;/p&gt;

&lt;p&gt;After making a few passes at the basic shape in pencil, I moved to the computer. My first attempts at a colored draft were very static. Doodling in Pixelmator with my Wacom tablet got me effectively nowhere, so I decided to just work in Illustrator directly — my first real stint with the software. As was typical with Adobe, the UI felt like a sprawling, bloated mess, but also allowed me to do some surprisingly powerful things. The most important discovery were the non-destructive transforms — particularly for the Pathfinder — in the inconspicuous “fx” menu at the bottom of the Appearance tab. With these tools, I gained the ability to perform boolean operations on sets of shapes, turn strokes into paths, and create complex gradients while still having full control over the constituent parts. Doing this across complex groups of layers wasn’t pretty, but it allowed me to freely experiment with new shapes without having to “bake” a final result and start all over again for minor adjustments.&lt;/p&gt;

&lt;p&gt;I’m sure experienced vector artists can use Illustrator to draft their ideas directly, but my process, as a beginner, was much more methodical. I started with the standard iOS 7 grid and drew a simple circle over the outer part. I typed an 8th note symbol in the center and looked through many fonts to find a pleasing shape for the flag. I rendered the note as a shape, added a scan of my freehand sketch in the background, and started dissecting the circle; it was split into several sections to make joining with the note flag a bit easier. After placing a connecting Bézier curve between the flag and the circle, fiddling with the control points to match my sketch, and adjusting the width to smoothly blend the circle and the flag, I had an outline that roughly matched my paper drawing. For this first pass, the rest of my time involved zooming out and adjusting the widths and tangents to make sure that everything looked smooth and contiguous.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-icon/early_icons.png&quot; width=&quot;594px&quot; /&gt;
&lt;p&gt;Some early experiments.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Designing the colorful swish at the tail end of the circle came next, and it turned out to be the trickiest part of the process. I knew that this segment of the icon had to have flow, levity, and dimensionality without looking too realistic or skeuomorphic — and yet I couldn’t picture it in my head. I started with a simple 3-color gradient at the end of the circle that widened towards the bottom. This looked merely OK, but it felt too static. Adding more colors to the gradient and moving the left side of the tail into the circle helped, but it wasn’t enough.&lt;/p&gt;

&lt;p&gt;The first problem was nailing the outer curve of the tail. I tried many different shapes. Some looked like paintbrushes; some evoked waves; some resembled sand dunes. But none felt perfectly right. My “aha” moment was when I realized that I was subconsciously creating an Archimedean spiral with its origin at the note flag. I borrowed a spiral from Google Images and adjusted my curves to fit it. The shape finally came together.&lt;/p&gt;

&lt;p&gt;Next came the colors. I learned that I could add more control points to the bottom of the gradient envelope, allowing me to roughly specify the curve of each vertical slice of the gradient. The next few iterations involved creating an almost cloth-like shape out of the envelope and fiddling with the blur between the gradient colors. Still, the distribution of the gradient stripes was unsatisfactory. No matter how much I adjusted the gradient distribution or the control points of the envelope, the swirls felt too busy at the origin and too lopsided further towards the bottom.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-icon/later_icons.png&quot; width=&quot;428px&quot; /&gt;
&lt;p&gt;Rough drafts closer to the final icon.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;I realized that what I wanted was precise control over the “density” of the gradient envelope, top to bottom. Hoping that Illustrator contained within its multitudes the solution to my problem, I Googled around and was elated to discover that I was correct. The Gradient Mesh tool, though a bit tricky to set up, allowed you to apply a gradient to a flexible rectangle with an inner Bézier-based grid. I could now adjust the precise distribution of color throughout the entire length of my tail!&lt;/p&gt;

&lt;p&gt;There were still some shape-related questions to answer, the most important being: how do I maintain the legibility of the note and circle? The tail was supposed to be in the background; above all else, I didn’t want the shape or colors of the tail to interfere with the appearance of the note. Initially, I assumed that the left edge of the tail (touching the blue stripe) should avoid the note head entirely by going under or above it. However, both options made the tail look misshapen and unattractive, ruining the wave effect. On a whim, I tried intersecting the note head with the edge and it worked! Instead of disrupting the legibility of the note, the line drew the eye to it. I also had concerns that the gradient would make the lower part of the circle hard to see, but this was easy to fix by simply following the shape of the circle with the red stripe.&lt;/p&gt;

&lt;p&gt;Finally, I wanted to make sure that each curve in the tail — the left edge as well as each dividing color line in the gradient — “rhymed” with the overall shape of the icon. The final curves were mostly determined by trial and error. Just as with my initial sketch, I “knew” as soon as I saw the winning arrangement that I had found an inflection point for my design. There was a strong sense of motion originating from the note flag, carrying through the circle, and spiraling back around into a colorful background wave. Even though I couldn’t picture it at the time, it was exactly the effect I was hoping for when I originally came up with the design!&lt;/p&gt;

&lt;p&gt;(I wish there was more to say about color selection, but in truth, it was done quickly and somewhat haphazardly. The background blue was derived from the primary color of my app, while the gradient colors were basically chosen on a whim.)&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-icon/wave.png&quot; width=&quot;400px&quot; /&gt;
&lt;p&gt;The final curves of the gradient mesh.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;For the Lite version, I once again wanted to stick to App Store conventions while defying them just a bit. Most Lite icons have an ugly banner over the default icon that feels out of place with the rest of the design. I still wanted to have the banner for consistency, but I wanted it to work with my diffuse pastel aesthetic.&lt;/p&gt;

&lt;p&gt;First, I had to determine banner placement. I tried several of the usual positions and then quickly rejected them; they blocked off too much of the underlying icon. I then decided to give the diagonals a shot and discovered that the upper-right corner had several benefits: not only did it preserve visibility for the key parts of the icon, but it also complemented the motion of the circle while allowing some interesting colors to peek through. (Assuming some translucency, which felt likely.)&lt;/p&gt;

&lt;p&gt;Next, I had to find a good look for the banner. (This iteration was done in Photoshop, since its raster effects were far better than Illustrator’s.) A simple color fill felt too out-of-place, so I decided to try for an iOS-7-ish Gaussian blur; ideally, I wanted a bit of the white outline and some of the tail colors to show through without compromising legibility. To make it easier to pick the final position, I masked the banner onto a blurred render of the underlying icon, which allowed me to treat the banner as if it were simply a blurry window and move it around freely. It didn’t take long until I found a satisfying result.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-icon/lite_icons.png&quot; width=&quot;345px&quot; /&gt;
&lt;p&gt;Drafts for the Lite version of the icon. The final icon is on the right.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;That’s about it! Against all my expectations when I started on this journey, I’m still pleased by my icon whenever I catch it on the home screen even half a year later. There are certainly changes I could still make — there’s not enough contrast, the colors aren’t perceptually balanced, the gradient divisions are still a bit lopsided and the origin of the swirl needs some work — but I would consider these nitpicks. The gestalt of the design is right.&lt;/p&gt;

&lt;p&gt;(And as an unforeseen bonus, the icon easily converted into a black-and-white stencil for the promo poster a few months later!)&lt;/p&gt;

&lt;p&gt;If there’s a foremost design lesson I took a way from all this, it’s how many moments of inspiration occurred whenever I deviated from incremental adjustments and tried something more extreme. Adding a bit more curvature to a line didn’t yield any new insights; but turning it into a semi-circle gave me a completely new perspective on the shape. Changing the brightness slightly didn’t result in a satisfactory color palate; while ramping the slider completely made me rethink my initial assumptions about the chromatic balance. It seems that if you’re stuck in a design rut, it can be a good idea to vastly overshoot and then dial down instead of trying to inch towards an optimal design with minor, conservative changes.&lt;/p&gt;

&lt;p&gt;Ultimately, it felt wonderful over the course of this project to engage with my creative side — a part of myself that I still consider a mystery. Every time a design decision “clicked”, it felt like a little miracle. No doubt this will only reinforce my stubborn desire to do all my own art in future projects!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/composers-sketchpad-icon/promo_poster.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 16 Jul 2016 07:00:00 -0700</pubDate>
        <link>http://beta-blog.archagon.net/2016/07/16/composers-sketchpad-adventures-in-icon-design/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/07/16/composers-sketchpad-adventures-in-icon-design/</guid>
        
        
        <category>design</category>
        
      </item>
    
      <item>
        <title>Headphone Jacks Are the New Power Plugs</title>
        <description>&lt;p&gt;Blog comments are out, blog responses are in — and so I thought I’d respond to John Gruber’s recent article titled &lt;a href=&quot;http://daringfireball.net/2016/06/headphone_jacks_are_the_new_floppy_drives&quot;&gt;“Headphone Jacks Are the New Floppy Drives”&lt;/a&gt;. Here’s why I think removing the headphone jack would be a bad idea at this moment in time:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Poor wireless options and standards. I use Bluetooth headphones and I love them, but they’re a world of compromises. Audio quality is far from lossless, and not just because of the codecs: with the sound off, you are likely to hear noise and static from the radio right next to your ear. (This does not bother me, but would drive many people crazy.) Switching between devices is a pain. Pairing is a pain. You have to remember to charge them. There is unbearable latency for games and occasionally even movies. Few audiophile-level headphone makers bother with Bluetooth headphones, leaving us with just the consumer brands. They can only be as powerful as the battery-powered driver. Might Apple introduce a new wireless codec that tackles all of these pain points? Sure. But then we get:&lt;/li&gt;
  &lt;li&gt;Vendor lock-in. Apple Wireless or Lighning headphones wouldn’t be compatible with much else. Not a problem for cheap earbuds, but definitely a big deal for high-quality, $400+ headphones. After years of freedom, audio would be siloed. As Gruber mentions, this is in Apple’s best interests; but among all our gadgets, headphones have always been among the most universal and independent. They are a true analog path between our disparate electronics — an intuitive and surprisingly error-free technology in a world where devices routinely refuse to talk to each other. You wouldn’t find yourself spending an hour helping your mom troubleshoot the headphone jack. This change would be a major pain point, especially when it comes to:&lt;/li&gt;
  &lt;li&gt;Loss of plug-and-play. I constantly plug my headphones from my phone to my laptop and back. Bluetooth can &lt;em&gt;sort of&lt;/em&gt; do this, but it always takes me about a minute with my wireless headphones. With Lightning headphones, it wouldn’t even be a possibility. (Barring Lightning-endowed Macbooks, which would be utterly bizzarre. What else would that port be used for? How would it be differentiated from USB-C?) A once-flexible workflow would be completely subverted.&lt;/li&gt;
  &lt;li&gt;Needless complication. Headphones are a very simple thing: just a wire leading to drivers. Very few things can go wrong in this arrangement, as evidenced by the proven durability and versatility of headphones over the past few decades. Headphone makers have gotten really good at working with these few parameters to create truly world-class audio devices. Indeed, some of the most esteemed headphones in the low-end audiophile space (I’m thinking of Grados) are basically glued together by hand in a workshop. If we start shoving more electronics — Lightning circuitry or a DAC, most obviously — into headphones, we make this proven system far more brittle than it needs to be. Headphones will malfunction in frustrating ways. Noise will be introduced. Designs will become more bloated to accommodate the extra circuitry. Every headphone having its own DAC is like every monitor having its own video card: clearly putting technology on the wrong side of the divide.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What is all this for? What do we gain in return?&lt;/p&gt;

&lt;p&gt;In the past, every time a prominent piece of technology was removed from my Apple hardware — most recently the CD drive and the Ethernet port — my response was ambivalent because I had already been happily using the alternative for a while. Wi-Fi, despite its flaws, offered countless advantages over Ethernet, leading to rapid adoption. Steam, iTunes, and Netflix had made me almost forget that CDs were still a thing by the time I got my Retina Macbook Pro. It almost goes without saying that these technologies were standard and universal — nobody would have accepted them otherwise. But there’s no Next Best Thing in headphones. This is an entirely artificial change.&lt;/p&gt;

&lt;p&gt;Were there an existing high-quality wireless standard for headphones, I’d be somewhat on board, especially if the phone could be waterproofed in exchange. But we’re not there yet, and I fear that in this instance, Apple is looking out for their corporate interests instead of their users. When Apple removes features, I can usually envision the “better tomorrow” they’re striving for. Here, what future can we look forward to if we’re all using bloated, proprietary, and fragile headphones that sound like garbage?&lt;/p&gt;

&lt;p&gt;I can already hear the cry that “the average consumer won’t care”. Sure, maybe not. But their listening experience wouldn’t really be improved by the change, their options for audio hardware would become a lot more limited, and their lives would become riddled with new minor frustrations. The “average consumer” doesn’t care about typography, True Tone displays, or Retina graphics, either. But it all adds up. I respect Apple because they’re internally motivated to strive for quality, and a move towards pointless proprietary standards — towards profit-driven mediocrity with the “average consumer” as a scapegoat — would be a sad blow to that image.&lt;/p&gt;

&lt;p&gt;There’s a good chance I’ll keep buying iPhones without a headphone jack, but also a 100% chance I’ll end up carrying a 3.5mm adaptor wherever I go. One more thing to lose. A permanent ugly tail sticking out of Ive’s immaculately-designed round rect.&lt;/p&gt;

&lt;p&gt;Good work, team?&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Jun 2016 18:49:04 -0700</pubDate>
        <link>http://beta-blog.archagon.net/2016/06/21/headphones/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/06/21/headphones/</guid>
        
        
        <category>technology</category>
        
      </item>
    
      <item>
        <title>Liberating Pitch and Taming MIDI in Composer&#39;s Sketchpad</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/composers-sketchpad-absolute-pitch/banner.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;!-- TODO: move most of this to one of the global scss files --&gt;

&lt;style&gt;
.toc {
  margin-top: 2em;
  margin-bottom: 2em;
  padding: 1em;
  margin-left: auto;
  margin-right: auto;
  border-style: solid;
  border-width: 0.2em;
  border-color: #93d7ff;
  border-radius: 2em;
  width: 80%;
  background-color: #c6eaff; }

.toc_header {
  display: -webkit-box;
  display: -webkit-flex;
  display: -ms-flexbox;
  display: flex;
  -webkit-box-pack: center;
  -webkit-justify-content: center;
  -ms-flex-pack: center;
  justify-content: center;
  -webkit-box-align: center;
  -webkit-align-items: center;
  -ms-flex-align: center;
  align-items: center;
  -webkit-flex-direction: row;
  -ms-flex-direction: row;
  flex-direction: row; }

.toc_header {
  text-align: left;
  margin-bottom: 0.75em !important; }

.toc_header &gt; * {
  margin-top: 0 !important;
  margin-bottom: 0 !important;
  margin-left: 0.5em !important;
  margin-right: 0.5em !important;
  padding: 0; }

.toc_header :first-child {
  margin-left: 0 !important; }

.toc_header :last-child {
  margin-right: 0 !important; }

.toc_header &gt; p {
  font-family: &#39;Avenir Next&#39;, &#39;Helvetica&#39;, &#39;Arial&#39;, sans-serif;
  font-size: 1.1em;
  color: #444;
  font-weight: 500;
  /*line-height: 140%;*/ }

.toc_header &gt; a {
  min-width: 5em;
  max-width: 5em; }

.toc_links {
  /*text-align: center;*/ }

.toc_links &gt; ol {
  font-family: &#39;Avenir Next&#39;, &#39;Helvetica&#39;, &#39;Arial&#39;, sans-serif;
  font-size: 1.1em;
  font-weight: 500; }

.toc_links &gt; ol {
  margin: 0;
  list-style-position: inside;
  counter-reset: i 0; }

.toc_links li {
  padding: 0.15em 0.5em 0.15em 0.5em; }

.toc a {
  text-decoration: underline; }

&lt;/style&gt;

&lt;style&gt;
.toc_links &gt; ol li:nth-child(3) {
/*color: darkgreen;*/
color: green;
border-radius: 0.5em;
background-color: lightgreen;
/*border: 1px dashed green;*/
}
.toc_links &gt; ol li:nth-child(3) a {
text-decoration: none;
pointer-events: none;
cursor: default;
color: inherit;
text-decoration: inherit;
}
&lt;/style&gt;

&lt;p&gt;
&lt;div class=&quot;toc&quot;&gt;
    &lt;div class=&quot;toc_header&quot;&gt;
        &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;&lt;img src=&quot;/images/composers_sketchpad_icon.png&quot; /&gt;&lt;/a&gt;
        &lt;p&gt;This blog post is part of a series on the development of &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;Composer&#39;s Sketchpad&lt;/a&gt;, a new iPad app for making musical rough drafts and doodles.&lt;/p&gt;
    &lt;/div&gt;

    &lt;div class=&quot;toc_links&quot;&gt;
        &lt;ol&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/02/05/composers-sketchpad&quot;&gt;Rethinking Musical Notation with Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/02/27/path-rendering-in-composers-sketchpad&quot;&gt;Path Rendering in Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/03/24/liberating-pitch-and-taming-midi-in-composers-sketchpad/&quot;&gt;Liberating Pitch and Taming MIDI in Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/07/16/composers-sketchpad-adventures-in-icon-design/&quot;&gt;Composer&#39;s Sketchpad: Adventures in Icon Design&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;I wanted Composer’s Sketchpad to have the ability to represent musical notes at any pitch. In order to do this, I needed to solve two problems: representing arbitrary pitches internally and making them compatible with MIDI.&lt;/p&gt;

&lt;p&gt;Human perception of pitch follows a logarithmic curve, meaning that a frequency will sound an octave higher when multiplied by two. However, we tend to think of notes in a linear fashion: C4 is a fixed distance from C3 on the piano, just as C3 is from C2.&lt;/p&gt;

&lt;p&gt;The naive approach to representing pitch would be to simply store the frequency in hertz and be done with it. But this didn’t sit right with me: since my canvas depicted pitches linearly like on a piano keyboard, I’d have to be constantly taking the logarithm of my points and subsequently introducing possible floating point errors as we went up the ladder. The pitches would also have to be stored as irrational floating point numbers, making it impossible to tell whether a point is sitting precisely on a pitch gridline.&lt;/p&gt;

&lt;p&gt;So I decided to represent my pitches as &lt;a href=&quot;https://en.wikipedia.org/wiki/Cent_(music)&quot;&gt;cents&lt;/a&gt;. Cents are the linear unit counterpart to frequency: C4 is 1200 cents from C3, and C3 is 1200 cents from C2. (Per equal temperament tuning, each piano key is 100 cents apart from the next.) This means that cents aren’t an absolute unit like pitch, but rather the function of two frequencies: in order to get the expected 1200 cents from C4 (261.6Hz) to C3 (130.8Hz) we take the base-2 logarithm of C4 divided by C3 and multiply by 1200. As convenient as these units were, I still needed to represent my points in an absolute way, and so I created an internal unit of “absolute cents”: simply the number of cents a pitch is from A440. If you peek inside a Composer’s Sketchpad JSON file, you’ll see that C4 has a value of -900, B4 a value of -1000, etc. Mathemtacially convenient and human-readable!&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-absolute-pitch/cents.png&quot; /&gt;
&lt;p&gt;Different representations of pitch for the inflection points on a single note.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;The second problem was a little trickier. Internally, the app was using the built-in MIDI functionality found on iOS, in the form of &lt;a href=&quot;https://developer.apple.com/library/ios/documentation/AudioToolbox/Reference/MusicPlayerServices_Reference/index.html&quot;&gt;MusicPlayer&lt;/a&gt; and AUMIDISynth. Unfortunately, traditional MIDI — having been designed in the stone age of computing — didn’t support arbitrary pitch values. Instead, you were given a measly 128 MIDI notes, each corresponding to a note on a standard, equally-tempered (and slightly extended) piano. This was great for interfacing with hardware MIDI keyboards, but hardly appropriate for playing back arbitrary pitches.&lt;/p&gt;

&lt;p&gt;(To be clear: MIDI is simply a standard for sending instructions to a synthesizer. While the standard is very limited and fiddly, it does have the advantage of being supported ubiquitously. You can also save your MIDI packets to a file and use it with a wide variety of software. However, synthesizers themselves are usually much more robust. When interfacing with them directly, you may well be able to play arbitrary pitches and use other custom functionality. The thing you’d lose by going this route is compatibility with existing technology, which is frankly a very big hurdle.)&lt;/p&gt;

&lt;p&gt;There are several ways to alter the pitch of a MIDI note, some more widely supported than others. The most common is using the pitch-bend wheel. Another is using the &lt;a href=&quot;https://en.wikipedia.org/wiki/MIDI_Tuning_Standard&quot;&gt;MIDI Tuning “Standard”&lt;/a&gt; (which is in fact hardly supported anywhere). Yet another is using polyphonic aftertouch, but only after setting up your synthesizer to correctly parse the signals. For its ubiquity and semantic correctness, I decided to go with the pitch-bending approach. To play back an arbitrary pitch, I’d simply play the closest MIDI note and then bend it up or down to the desired frequency. However, there were two issues with this approach. First, the pitch-bend wheel applied bending to the entire keyboard range, not just individual notes. This meant that with the naive implementation, you could only play a single arbitrary pitch at a time! Second, the default range for the entire pitch-bend wheel was a measly whole tone up or down, which was simply insufficient for arbitrary bends. (For wider bends, one might consider getting around this problem by bending to a note, stopping the first note, playing the second note, and continuing the bend. However, this sounds pretty poor due to the fact that most instruments have a distinctive-sounding “attack” that appears as soon as you play a note. This makes the bend sound discontinuous at MIDI note boundaries.)&lt;/p&gt;

&lt;p&gt;I’ll get into the specifics of my MIDI architecture in a later article, but in brief, I solved the first problem using MIDI channels and multiple MIDI instruments. A MIDI instrument can often have 16 so-called channels, which are sort of like presets. Each channel has its own setting for instrument, volume, vibrato, and — conveniently — pitch bend, among many other properties. Whenever you play a MIDI note, you assign it to a channel and it plays with the corresponding properties for that channel. For my use case, this meant that if I used each MIDI channel for playing just a single note at a time (as opposed to the usual approach of playing multiple notes per channel and assigning each channel to a unique instrument), I could have 16 notes simultaneously pitch-bending at once! I wanted more polyphonic notes than that, however, so I decided to simply create a new virtual MIDI synth for each instrumental layer in my app: 16 channels per instrument, with 10 maximum instruments at once (for now). Surprisingly, even 10 maxed-out MIDI synths playing simultaneously didn’t peg my iPad 3’s CPU too hard. Kudos to a great audio architecture!&lt;/p&gt;

&lt;p&gt;The second problem — limited pitch-bend range — was solved using a so-called &lt;a href=&quot;http://www.blitter.com/~russtopia/MIDI/~jglatt/tech/midispec/rpn.htm&quot;&gt;MIDI RPN&lt;/a&gt;, or registered parameter number. These are special, widely-supported MIDI commands that let you configure certain properties of your synth, with one of the primary ones being the range of your pitch-bend wheel. (Note that I say &lt;em&gt;widely&lt;/em&gt; supported, not universally. Only about half the software I’ve tried seems to understand the pitch-bend range RPN. Fortunately, Apple’s built-in synth does just fine.) Rather than having each tick on my virtual pitch-bend wheel correspond to 0.024 cents (as is the default), I sent an RPN command at the start of playback to make each tick equal to one cent. Completely impractical for a physical weel, but quite conveinent for our use case! (Incidentally, this makes the new pitch-bend range +/- almost 7 octaves. Except for the most esoteric use cases, it’s totally unnecessary to go any further than that, since even a pitch-bend of a single octave sounds pretty terrible on most synths.)&lt;/p&gt;

&lt;p&gt;All in all, it’s a messy, imperfect system, but it gets the job done. I can take a bunch of pitches stored as “absolute cents” in my JSON file, push them through a few conversion functions, retrieve a set of MIDI packets on the other end, send them to a bunch of virtual MIDI synths, and have them sound as the correct, precise audio frequencies through my speakers. Maybe someday a more modern standard like OSC will reign supreme and allow this sort of architecture to be radically simplified, but for now, we’re unfortunately a bit stuck in the 80’s.&lt;/p&gt;

</description>
        <pubDate>Thu, 24 Mar 2016 01:18:04 -0700</pubDate>
        <link>http://beta-blog.archagon.net/2016/03/24/liberating-pitch-and-taming-midi-in-composers-sketchpad/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/03/24/liberating-pitch-and-taming-midi-in-composers-sketchpad/</guid>
        
        
      </item>
    
      <item>
        <title>Path Rendering in Composer&#39;s Sketchpad</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/composers-sketchpad-rendering/rendering.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;!-- TODO: move most of this to one of the global scss files --&gt;

&lt;style&gt;
.toc {
  margin-top: 2em;
  margin-bottom: 2em;
  padding: 1em;
  margin-left: auto;
  margin-right: auto;
  border-style: solid;
  border-width: 0.2em;
  border-color: #93d7ff;
  border-radius: 2em;
  width: 80%;
  background-color: #c6eaff; }

.toc_header {
  display: -webkit-box;
  display: -webkit-flex;
  display: -ms-flexbox;
  display: flex;
  -webkit-box-pack: center;
  -webkit-justify-content: center;
  -ms-flex-pack: center;
  justify-content: center;
  -webkit-box-align: center;
  -webkit-align-items: center;
  -ms-flex-align: center;
  align-items: center;
  -webkit-flex-direction: row;
  -ms-flex-direction: row;
  flex-direction: row; }

.toc_header {
  text-align: left;
  margin-bottom: 0.75em !important; }

.toc_header &gt; * {
  margin-top: 0 !important;
  margin-bottom: 0 !important;
  margin-left: 0.5em !important;
  margin-right: 0.5em !important;
  padding: 0; }

.toc_header :first-child {
  margin-left: 0 !important; }

.toc_header :last-child {
  margin-right: 0 !important; }

.toc_header &gt; p {
  font-family: &#39;Avenir Next&#39;, &#39;Helvetica&#39;, &#39;Arial&#39;, sans-serif;
  font-size: 1.1em;
  color: #444;
  font-weight: 500;
  /*line-height: 140%;*/ }

.toc_header &gt; a {
  min-width: 5em;
  max-width: 5em; }

.toc_links {
  /*text-align: center;*/ }

.toc_links &gt; ol {
  font-family: &#39;Avenir Next&#39;, &#39;Helvetica&#39;, &#39;Arial&#39;, sans-serif;
  font-size: 1.1em;
  font-weight: 500; }

.toc_links &gt; ol {
  margin: 0;
  list-style-position: inside;
  counter-reset: i 0; }

.toc_links li {
  padding: 0.15em 0.5em 0.15em 0.5em; }

.toc a {
  text-decoration: underline; }

&lt;/style&gt;

&lt;style&gt;
.toc_links &gt; ol li:nth-child(2) {
/*color: darkgreen;*/
color: green;
border-radius: 0.5em;
background-color: lightgreen;
/*border: 1px dashed green;*/
}
.toc_links &gt; ol li:nth-child(2) a {
text-decoration: none;
pointer-events: none;
cursor: default;
color: inherit;
text-decoration: inherit;
}
&lt;/style&gt;

&lt;p&gt;
&lt;div class=&quot;toc&quot;&gt;
    &lt;div class=&quot;toc_header&quot;&gt;
        &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;&lt;img src=&quot;/images/composers_sketchpad_icon.png&quot; /&gt;&lt;/a&gt;
        &lt;p&gt;This blog post is part of a series on the development of &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;Composer&#39;s Sketchpad&lt;/a&gt;, a new iPad app for making musical rough drafts and doodles.&lt;/p&gt;
    &lt;/div&gt;

    &lt;div class=&quot;toc_links&quot;&gt;
        &lt;ol&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/02/05/composers-sketchpad&quot;&gt;Rethinking Musical Notation with Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/02/27/path-rendering-in-composers-sketchpad&quot;&gt;Path Rendering in Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/03/24/liberating-pitch-and-taming-midi-in-composers-sketchpad/&quot;&gt;Liberating Pitch and Taming MIDI in Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/07/16/composers-sketchpad-adventures-in-icon-design/&quot;&gt;Composer&#39;s Sketchpad: Adventures in Icon Design&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Before starting any work on Composer’s Sketchpad, I had to ask myself: was the app as I envisioned it even possible to make? My initial goals were as follows:&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;important_list&quot;&gt;
    &lt;ol&gt;
      &lt;li&gt;Have an (effectively) infinite canvas with a large number of notes visible at once.&lt;/li&gt;
      &lt;li&gt;Allow the canvas to zoom and pan with without any lag.&lt;/li&gt;
      &lt;li&gt;Allow the canvas to zoom without the notes losing any sharpness.&lt;/li&gt;
      &lt;li&gt;Have notes belonging to the current layer blur or fade when the layer switches.&lt;/li&gt;
      &lt;li&gt;Allow the notes to stretch and skew when the grid scale changes without distorting their appearance. (I ended up dropping this for the release version.)&lt;/li&gt;
      &lt;li&gt;Have the whole thing run at 60fps on my iPad 3.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;I had barely done any graphics programming up to this point, so I had to feel out the limits of OpenGL as I blindly barged ahead — always a painful way to develop a project.&lt;/p&gt;

&lt;p&gt;At first, I briefly considered implementing drawing using Photoshop-like brushes: that is to say, directly toggling pixels on a bitmap as the user moved their fingers around the screen. This seemed appropriate for something that behaved so much like a drawing application. However, I quickly realized that the representation of my notes should really be separate from their rendering (as with any good MVC design), which meant that I couldn’t just save the bitmap and be done with it. Furthermore, the finite resolution of the bitmap presented a number of problems. How could I implement high-quality zoom without having to re-render everything? How would it be possible to have an infinite canvas without having to implement a complex tiled rendering system? (I was aiming for maximum possible simplicity in my architecture at this point.) How could I switch layers seamlessly without storing a bitmap for each layer? It just wasn’t a good fit given the dynamic features of my app.&lt;/p&gt;

&lt;p&gt;So I decided try for a &lt;a href=&quot;https://developer.nvidia.com/nv-path-rendering&quot;&gt;path rendering&lt;/a&gt; approach instead. My musical notes would be stored as points in time/pitch space, and then the renderer would convert them into pleasing, smooth curves to draw on the screen.&lt;/p&gt;

&lt;p&gt;There were two obvious techniques that came to mind. The first was to use the CoreGraphics path renderer in the form of &lt;code&gt;UIBezierCurve&lt;/code&gt;. This approach was compelling because CoreGraphics’ path drawing support was very robust, to the point of being the foundation of heavyweight applications like &lt;a href=&quot;http://www.pixelmator.com/&quot;&gt;Pixelmator&lt;/a&gt;. Strokes, fills, and complex shapes were incredibly simple to define and draw, and it was all built-in and battle-tested by thousands of developers.&lt;/p&gt;

&lt;p&gt;The second approach that I immediately considered was to convert each curve into polygons and draw them using the GPU. My experience with hardware-accelerated vector graphics, though minor, was very positive: performance seemed smooth and stutterless compared to software rendering in the apps that used it, and the artifacts that occurred while waiting for data to load (jagged lines turning into smooth lines) felt a lot more pleasing than those in software renderers (blurry lines turning into crisp lines). Intuitively, even though I didn’t know any of the details at this point, the idea of manipulating groups of polygons on the GPU rather than plotting out curves pixel-by-pixel seemed like a very efficient approach. In addition, I knew that with polygons, scales and other translations would be effectively free.&lt;/p&gt;

&lt;p&gt;Unfortunately, there weren’t any built-in iOS frameworks that allowed me to do this. (Or — so I thought. I later learned that &lt;a href=&quot;https://developer.apple.com/library/prerelease/ios/documentation/SceneKit/Reference/SCNShape_Class/index.html&quot;&gt;SceneKit had support for path rendering&lt;/a&gt;, but it turned out to be fairly ugly, slow, and not particularly configurable.) I didn’t really feel up to the task of rolling my own solution, so I decided to hunt around for a framework. With high high-DPI displays ruling the roost and minimalist UIs being all the rage, surely somebody had a stable framework for hardware-accelerated path rendering on iOS?&lt;/p&gt;

&lt;p&gt;During my search, I learned of &lt;a href=&quot;https://en.wikipedia.org/wiki/OpenVG&quot;&gt;OpenVG&lt;/a&gt;, the Khronos Group’s standard for hardware-accelerated path rendering. It seemed to be exactly what I was looking for! Unfortunately, the standard appeared to be all but abandoned&lt;sup id=&quot;fnref:why_no_hw_vectors&quot;&gt;&lt;a href=&quot;#fn:why_no_hw_vectors&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, with Nvidia’s &lt;a href=&quot;https://developer.nvidia.com/nv-path-rendering&quot;&gt;NV_path_rendering&lt;/a&gt; being the only other standard trying to take up the mantle. (Naturally, this was not an extension that iOS OpenGL ES supported.) However, I did manage to find an OpenGL ES framework called &lt;a href=&quot;https://github.com/micahpearlman/MonkVG&quot;&gt;MonkVG&lt;/a&gt; that incorporated a subset of OpenVG suitable for my project. Looking at the terrifying, twisted, OpenGL-ES-2-wrapping-OpenGL-ES-1-code, I feared that I might have great difficulty using the framework on iOS. Fortunately, it turned out that MonkVG only handled shaders and polygon drawing, not setting up the context or any other platform-specific technical details. After creating my GL &lt;code&gt;UIView&lt;/code&gt; and fixing a couple of minor errors, I was good to go.&lt;/p&gt;

&lt;p&gt;(Quick aside: over the course of my research, I learned that there were several ways to hardware-accelerate path rendering. MonkVG’s tessellation approach worked fairly efficiently, but it was also imprecise on account of the fact that you ended up with polygon strips in the end. It also required the actual tessellation step to be done on the CPU. In contrast, there are newer approaches that can render the paths directly using shaders. These tend to have high accuracy and detail, and they only require a single bounding-box polygon for the entire shape. Unfortunately, in my limited testing, I found the performance of this approach to be lacking on my iPad 3. Additionally, as I further discuss below, the polygon strip approach turned out to be ideal in the case where shapes needed to be generated once and then cached for future reuse and transformation. From what I can tell, it’s far more difficult to cache rendered curves using the shader approach.)&lt;/p&gt;

&lt;p&gt;Having figured out how to use both frameworks, I made a quick performance prototype: a simple draw loop at 60fps with a set of full-screen, randomly generated Bézier curves in each frame. (I considered this my worst-case scenario, as in the case of changing the width or height scales of my grid.) There were two rendering paths: one for CoreGraphics and one for MonkVG.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-rendering/stresstest.png&quot; /&gt;
&lt;p&gt;A randomly-generated scene from the stress test. CoreGraphics couldn&#39;t handle it while MonkVG passed with flying colors.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Sadly, as much as I wanted to stick with the battle-hardened CoreGraphics approach, it wasn’t even able to draw a single animating curve at a solid 60fps on my iPad 3. MonkVG, on the other hand, tore through 10+ curves without breaking a sweat. Graphically, the results of both approaches looked quite similar to me — or at least good enough for the app I was trying to make.&lt;/p&gt;

&lt;p&gt;After closely examining the technical underpinnings of both technologies, I learned that CoreGraphics was doing all of its work on the CPU, while MonkVG was tessellating its curves into polygon strips CPU-side and then sending them to VBOs on the GPU — one per curve. Interestingly, the performance difference still applied even when accounting for the tessellation step. Presumably, this is because drawing multiple polygons is a very fast and parallelizable operation on the GPU, even if they number in the thousands, while generating a Retina-sized Bézier curve on the CPU requires you to touch tens of thousands of pixels by “hand”. (But don’t quote me on that — I am definitely still a novice in this area.) It also helps that MonkVG is much less precise than CoreGraphics in its tessellation.&lt;/p&gt;

&lt;p&gt;Despite these finds, I really wanted to work with CoreGraphics, and so I attempted to return to the technology a number of times during my project. (Perhaps I missed something that would account for the massive performance difference?) Notably, I tried using it together with &lt;code&gt;CATiledLayer&lt;/code&gt;, hoping that this particular optimization would offset the inefficiencies of the software render. But even though I could now pan and zoom at 60fps, the chunks loaded far, &lt;em&gt;far&lt;/em&gt; too slowly for realtime use — I’m talking on the order of several seconds whenever you zoomed in. So that was that.&lt;/p&gt;

&lt;p&gt;For much of the project, owing to my inexperience, I was burdened with the question of the framerate cap. If everything was done perfectly, how high could I go? After getting caching and draw call batching working correctly, my MonkVG implementation yielded an acceptable framerate of 30-60fps in the general case, but I still wondered if I was an order of magnitude off on account of my incompetence. How did Apple Maps manage to work so smoothly with so many shapes on screen? How did web browsers manage to display thousands of character paths — possibly with transforms! — and still attain smooth performance? In truth, the geometry I was showing on screen was fairly complex: each quarter-measure note had about 300 triangles once you included the outline and endcaps, leading to an upper bound of almost 400,000 triangles on screen for a dense piece (12 notes, or 4 chords, per measure per layer, with 10 full layers and 10 measures on screen). Surely a breeze for modern machines, but quite a lot to handle for an old iPad! It’s always important to be able to answer the question, “where is all that performance going?”, and in my case it was going towards the multitude of dynamic features in my app.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-rendering/curves.png&quot; /&gt;
&lt;p&gt;The mesh structure of a note. Each blue dot is a recorded time/pitch sample. Having a screen full of these can be surprisingly performance-intensive!&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;In retrospect, it was quite fortunate that I just happened to fall into the optimal rendering implementation for my project. My path rendering requirements were a little different from the norm: after eliminating point #5 from my initial goal list, I no longer needed most of my curves to be dynamic. The only curves that actually changed their structure from frame to frame were those belonging to the notes currently being drawn or erased — and even those were localized to the point of editing, since my notes were comprised of multiple tiny Bézier segments chained together. (I’ll talk details in a later article.) Instead, my highest priority was to translate and scale my notes at a constant 60fps while still preserving their sharpness, and polygons happened to be uniquely qualified for this task. At the expense of jaggedness on close zoom — fine by me — polygon tessellation effectively gave me infinite resolution along with free transforms. They were also perfectly suited for caching: once tessellated, I could store the vertices of the generated polygons for all my note objects without wasting too much space, wheareas doing the same with textures would have quickly filled up my memory. (To say nothing of looking terribly ugly when scaled.) Better yet, I eventually learned from profiling that it was the tessellation step — not drawing — that was the biggest roadblock in my path rendering implementation, so caching was absolutely critical to getting the performance I needed! Had I used a shader-based approach, I would have had to write a ton of additional code to enable caching, and it &lt;em&gt;still&lt;/em&gt; probably wouldn’t have gotten close to my 60fps benchmark for large scenes.&lt;/p&gt;

&lt;p&gt;For convenience, I decided to use &lt;a href=&quot;http://cocos2d.spritebuilder.com&quot;&gt;Cocos2d&lt;/a&gt; as the graphical core of my project, so I had to figure out a way to wedge MonkVG in there somehow. 
Fortunately, it was fairly simple to write a Cocos2d &lt;code&gt;CCNode&lt;/code&gt; wrapper around MonkVG’s rendering functions, since each &lt;code&gt;CCNode&lt;/code&gt; in Cocos2d had a lovely overridable &lt;code&gt;draw&lt;/code&gt; method that allowed you to call OpenGL functions directly. (One reason why you might want to use it over SpriteKit!) Still, especially as the project moved forward, the framework was becoming a massive cognitive burden. MonkVG had a fairly old and creaky codebase, and as the hacks I made to enable unsupported features such as real-time color changes piled on, I realized that it would take me forever to actually fix everything up and integrate it into my project in a sensible and modern way. Additionally, the one-VBO-per-curve approach was quickly becoming unwieldily. Already I had to synchronize a ton of state between MonkVG and the rest of my app in order to cache previously-tessellated curves for performance reasons; far more daunting was the idea of cycling VBOs in and out of GPU memory while retaining the underlying geometry client-side, which I wasn’t doing yet. Unfortunately, this was going to be necessary to enable my potentially-infinite canvas, and MonkVG didn’t natively support it.&lt;/p&gt;

&lt;p&gt;At this point, I realized that even though writing my own hardware-accelerated path renderer was probably too much work, my path rendering needs were actually very simple. I didn’t need to create unions of shapes, arbitrary curves, or even strokes! All my note shapes were simple Bézier “tubes” with round endcaps and outlines, and so creating a super-simple note renderer for direct use in Cocos2d would require minimal effort. Better yet, most of the work was done already: for the purpose of creating better outlines, I was already interpolating all of my Bézier curves myself and only using MonkVG to draw and tessellate the final polygon tubes from the perimeter vertices. The only thing I needed to do was to create polygon strips from my points and send them through Cocos2d’s native rendering system, as well as to write a bit of code for the round endcaps. Sure, it bummed me out that this would preclude me from creating more complex and dynamic shapes in the future, but I was on a deadline and the project needed to be shipped. Despite my initial trepidation, the process was extremely quick and only took a couple of days of work.&lt;/p&gt;

&lt;p&gt;As I dove deeper into Cocos2d’s architecture, I was struck by the beauty of its rendering pipeline. Unlike MonkVG, there was no VBO juggling here at all: the geometry for each object in the entire scene graph was sent to the GPU anew in every frame. (I soon learned that this was called “geometry streaming”.) This approach completely eliminated the need to track the mapping between tessellated curves and their corresponding VBOs, eliminating hundreds, if not thousands, of lines of brittle complexity in my app. What’s more, Cocos2d batched draw calls automatically, meaning that all your geometry would automatically coalesce into just a couple of draw calls without having to do any extra work, even if it resided in completely separate &lt;code&gt;CCNode&lt;/code&gt;s. This was a massive benefit I was not expecting!&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad-rendering/pipeline.png&quot; /&gt;
&lt;p&gt;The final path rendering pipeline.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;There was a new problem, though. With the new path rendering system (now using geometry streaming), my performance hovered at around 50%-70% of what I was getting in MonkVG. Intuitively, I feared that a fix was impossible: wouldn’t uploading thousands of polygons in every frame be naturally more resource-intensive than storing polygons in VBOs for later reuse? But after some digging, I learned something very interesting: OpenGL ES actually allowed you to map GPU memory directly into a shared application-space buffer, eliminating the need to “upload” your geometry at all! I did a sanity check and realized that there was &lt;em&gt;no way&lt;/em&gt; that copying even hundreds of thousands of polygons to a buffer could be the roadblock. But Cocos2d was already using memory mapping in its renderer! So what was the problem?&lt;/p&gt;

&lt;p&gt;There was another issue with the Cocos2d renderer. If I opened a project with lots of notes, my performance was usually 60fps at the default zoom level. But if I zoomed out (getting lots of notes on screen) and then zoomed back in, the performance dropped to 30fps or lower and then never actually recovered, no matter how closely I zoomed! This didn’t make any sense since my notes were always culled to the current viewport, meaning that performance should have always been identical for any given view. This also never happened in MonkVG.&lt;/p&gt;

&lt;p&gt;I decided to dig even deeper. After several hours of Googling keywords related to geometry streaming versus VBO performance, I zeroed in on a fantastic thread in the OpenGL forums. In this thread, &lt;a href=&quot;https://www.opengl.org/discussion_boards/showthread.php/170118-VBOs-strangely-slow?p=1197780#post1197780&quot;&gt;Rob Barris provided a very clear rundown&lt;/a&gt; of exactly how OpenGL managed memory in streaming situations. As it turned out, there was a certain art to managing your geometry buffers in a way that avoided stalls in the pipeline.&lt;/p&gt;

&lt;p&gt;Digging around in Cocos2d’s renderer, it seemed that the streaming architecture had some inefficiencies and bugs. There was a single memory-mapped buffer that was used for all the geometry, but it got “orphaned” and subsequently re-allocated in every frame. This caused a continuous allocation of up to several megabytes per frame — a significant performance consideration. What’s more, if a given scene was big enough to fill up the buffer, it expanded in place, but then never actually shrank back to its original size once the extra space was no longer needed. This meant that if you happened to render a giant scene — say, requiring a 9MB buffer — you would get an allocation of 9MB in every single frame after that, regardless of its complexity!&lt;/p&gt;

&lt;p&gt;At this point, I had a solid intuition for my next course of action. Rob Barris’s advice, as well as some other references, indicated that it was possible to use the &lt;em&gt;same&lt;/em&gt; buffer over the course of several frames without having to reallocate it. You could simply keep a pointer to the last filled slot in the array and start from there for your next frame. Once you ran out of memory, you could orphan your buffer and have OpenGL allocate you a new one. If you set your sizes correctly, you’d have one large allocation every few frames instead of an allocation in every single frame. In the end, I opted for a slightly simpler (architecturally-speaking) double-buffer solution: two large buffers side-by-side, with one buffer always serving as the main buffer. Once the main buffer ran out of space (over the course of several frames), the other would become the main buffer and allow the first buffer to orphan and reallocate.&lt;/p&gt;

&lt;p&gt;Fixing the renderer required a number of very low-level changes, but it was somewhat easier than expected, largely on account of Cocos2d’s excellent code organization. After making my changes and fixing a couple of Cocos2d bugs along the way, I fired up the app and was delighted to see my old MonkVG framerate — maybe even a little better! Not only did I have my original performance back, but I also gained an immense amount of architectural simplicity along the way.&lt;/p&gt;

&lt;p&gt;In the end, all the goals I set for myself were successfully met. The app does run at 60fps much of the time on my iPad 3, though it’s naturally far more prone to dropping frames than newer devices. (An iPad Air 1 and my iPhone 5s barely dipped below 60fps even in complex scenes.) Real-time tessellation is still something I want to implement for grid scale changes; I doubt I’d be able to truly do it in real-time for a full screen of notes, but I can think of several ways to fake-transform existing tessellated notes while waiting for the correct tessellation to load.&lt;/p&gt;

&lt;p&gt;Finally, I do hope that somebody releases a stable, hardware-accelerated path rendering framework for iOS. It’s sorely needed for vector-based apps with dynamic content!&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:why_no_hw_vectors&quot;&gt;
      &lt;p&gt;Curious, I asked programmers.stackexchange.com about this issue and &lt;a href=&quot;http://programmers.stackexchange.com/questions/191472/why-have-hardware-accelerated-vector-graphics-not-taken-off&quot;&gt;got some interesting answers&lt;/a&gt;. &lt;a href=&quot;#fnref:why_no_hw_vectors&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 27 Feb 2016 15:33:37 -0800</pubDate>
        <link>http://beta-blog.archagon.net/2016/02/27/path-rendering-in-composers-sketchpad/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/02/27/path-rendering-in-composers-sketchpad/</guid>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Rethinking Musical Notation with Composer&#39;s Sketchpad</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/composers-sketchpad/icon.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;!-- TODO: move most of this to one of the global scss files --&gt;

&lt;style&gt;
.toc {
  margin-top: 2em;
  margin-bottom: 2em;
  padding: 1em;
  margin-left: auto;
  margin-right: auto;
  border-style: solid;
  border-width: 0.2em;
  border-color: #93d7ff;
  border-radius: 2em;
  width: 80%;
  background-color: #c6eaff; }

.toc_header {
  display: -webkit-box;
  display: -webkit-flex;
  display: -ms-flexbox;
  display: flex;
  -webkit-box-pack: center;
  -webkit-justify-content: center;
  -ms-flex-pack: center;
  justify-content: center;
  -webkit-box-align: center;
  -webkit-align-items: center;
  -ms-flex-align: center;
  align-items: center;
  -webkit-flex-direction: row;
  -ms-flex-direction: row;
  flex-direction: row; }

.toc_header {
  text-align: left;
  margin-bottom: 0.75em !important; }

.toc_header &gt; * {
  margin-top: 0 !important;
  margin-bottom: 0 !important;
  margin-left: 0.5em !important;
  margin-right: 0.5em !important;
  padding: 0; }

.toc_header :first-child {
  margin-left: 0 !important; }

.toc_header :last-child {
  margin-right: 0 !important; }

.toc_header &gt; p {
  font-family: &#39;Avenir Next&#39;, &#39;Helvetica&#39;, &#39;Arial&#39;, sans-serif;
  font-size: 1.1em;
  color: #444;
  font-weight: 500;
  /*line-height: 140%;*/ }

.toc_header &gt; a {
  min-width: 5em;
  max-width: 5em; }

.toc_links {
  /*text-align: center;*/ }

.toc_links &gt; ol {
  font-family: &#39;Avenir Next&#39;, &#39;Helvetica&#39;, &#39;Arial&#39;, sans-serif;
  font-size: 1.1em;
  font-weight: 500; }

.toc_links &gt; ol {
  margin: 0;
  list-style-position: inside;
  counter-reset: i 0; }

.toc_links li {
  padding: 0.15em 0.5em 0.15em 0.5em; }

.toc a {
  text-decoration: underline; }

&lt;/style&gt;

&lt;style&gt;
.toc_links &gt; ol li:nth-child(1) {
/*color: darkgreen;*/
color: green;
border-radius: 0.5em;
background-color: lightgreen;
/*border: 1px dashed green;*/
}
.toc_links &gt; ol li:nth-child(1) a {
text-decoration: none;
pointer-events: none;
cursor: default;
color: inherit;
text-decoration: inherit;
}
&lt;/style&gt;

&lt;p&gt;
&lt;div class=&quot;toc&quot;&gt;
    &lt;div class=&quot;toc_header&quot;&gt;
        &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;&lt;img src=&quot;/images/composers_sketchpad_icon.png&quot; /&gt;&lt;/a&gt;
        &lt;p&gt;This blog post is part of a series on the development of &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;Composer&#39;s Sketchpad&lt;/a&gt;, a new iPad app for making musical rough drafts and doodles.&lt;/p&gt;
    &lt;/div&gt;

    &lt;div class=&quot;toc_links&quot;&gt;
        &lt;ol&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/02/05/composers-sketchpad&quot;&gt;Rethinking Musical Notation with Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/02/27/path-rendering-in-composers-sketchpad&quot;&gt;Path Rendering in Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/03/24/liberating-pitch-and-taming-midi-in-composers-sketchpad/&quot;&gt;Liberating Pitch and Taming MIDI in Composer&#39;s Sketchpad&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&quot;/2016/07/16/composers-sketchpad-adventures-in-icon-design/&quot;&gt;Composer&#39;s Sketchpad: Adventures in Icon Design&lt;/a&gt;&lt;/li&gt;
        &lt;/ol&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Just last month, I released my first major project for the iPad: &lt;a href=&quot;http://www.composerssketchpad.com&quot;&gt;Composer’s Sketchpad&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;Composer’s Sketchpad is an interactive, “doodle-y” take on music sequencing and notation. When you launch the app, you’re presented with a giant canvas that can be panned around with your finger. The canvas is covered with a grid, indicating time on the horizontal axis and pitch on the vertical. To draw musical notes, you hold down the canvas with one finger and draw with another. (You can also zoom using a similar gesture.) Unlike most sequencers, the app lets you start your notes at any time and bend them to any pitch, giving you the ability to sketch out twisted solos and complex rhythms with no extra effort. You can also snap to the gridlines if you wish.&lt;/p&gt;

&lt;center&gt;
&lt;p&gt;
&lt;div class=&quot;videoWrapper&quot;&gt;
&lt;iframe width=&quot;600rem&quot; height=&quot;450rem&quot; src=&quot;https://www.youtube.com/embed/ypsLgTY8NXs&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;/center&gt;

&lt;p&gt;In the coming months, I’m going to (try to) post a series of articles concerning the technical, design, and marketing aspects of the project. But for now, I’d like to write about the genesis of the idea.&lt;/p&gt;

&lt;p&gt;I made Composer’s Sketchpad for two reasons.&lt;/p&gt;

&lt;p&gt;The first was my inability to compose music using the tools I had at hand. Today, with the help of computers, creativity in practically all artistic mediums is blooming. Everything is digital, iterable, undoable: instead of having to buy messy paints or develop your film after every 30 shots, you can open your favorite graphics editor, grab your tablet, and tear through hundreds of sketches at a time. This reduction in creative friction must be an astounding source of growth for the arts!&lt;/p&gt;

&lt;p&gt;Unfortunately, I feel composition has not quite made the same magnitude of leap forward. While the studios of the past can now be entirely replaced by powerful tools running on our computers, most of them are dreadnoughts aimed at heavy production or performance use. The rhetorical art of composition — the process of taking musical notes and putting them in an order that sounds good and meaningful to our ears — has yet to see the equivalent of a Word or a Photoshop. To put it another way, there’s very little music software out there with a tight creative feedback loop specifically tuned to plonking down a few notes, playing them back, and repeating the process until you get something that sounds good. You could certainly use a DAW sequencer, Finale, or even a tracker for that purpose — many composers successfully do! — but I’ve found that the delay between editing and playback is still too high in those applications, to say nothing of the often immense UX hurdles. Worse yet, barely any of these tools are optimized for touch or stylus input — surely an ideal interface for composing at the piano (or under a tree)!&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad/flstudio.jpg&quot; /&gt;
&lt;p&gt;DAW interfaces tend to be aimed at production, not freehand composition.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Tooling aside, many musicians write music by simply improvising on their instrument and recording the results. Sadly, this is not a tenable approach for amateurs. Whenever I’m sitting at the piano and get the flicker of an interesting idea, I always lose the thread by the time I get around to actually playing or writing it down. I’d need many more years of practice to actually be able to compose anything interesting using this approach.&lt;/p&gt;

&lt;p&gt;It was clear that my musical life was missing a tool that allowed for the rapid entry and immediate playback of notes — a kind of interactive, audible sheet music. Whenever inspiration struck, I wanted the ability to pull out my tablet or phone and jot down my musical thoughts in a matter of seconds.&lt;/p&gt;

&lt;p&gt;Composer’s Sketchpad fulfills this demand by heavily prioritizing navigation and note entry above all else. There’s no mode for moving around the canvas: you simply swipe like in a mapping app. To make a note, you hold down the canvas with one finger and draw with another, as if applying pressure to a particularly slippery piece of paper. Undo/redo and erase are right there in the corners, and the playback controls are within easy reach at the bottom of the screen. (Your current viewport is also your playback position.) A piece is divided into several layers of notes — each with their own instrument or percussion set — and the active layer can be changed with a simple swipe of the instrument box at the top of the screen. Doing this brightens the active layer and dims any background layers, allowing you to edit the current layer exclusively while still having a sense of what all the other instruments are doing. In short, there’s barely any cognitive overhead: every tool you need to rapidly sketch out music is right there in front of you.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad/ui.png&quot; /&gt;
&lt;p&gt;The UI in Composer&#39;s Sketchpad is carefully tuned to enable a tight creative feedback loop.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;The other problem I wanted to tackle was the antiquated nature of sheet music.&lt;/p&gt;

&lt;p&gt;I love classical and popular music alike. Unfortunately, popular music differs enough from classical to make traditional notation simply the wrong tool for the job. For one, practically every piece of popular music uses syncopated rhythm. Most classical music is fairly on-the-beat, and notation is designed with that in mind. With syncopated music, you usually end up with a mess of rests, ties, and dotted notes that is hard to read and write. Modern music is also irreverent when it comes to duration and pitch. Solos are a great example: they’re fluid and expressive, and each note only lasts and remains on pitch as long as the performer wishes. Once again, notating them is an incredible pain.&lt;/p&gt;

&lt;p&gt;What about music from other cultures? The scales for many musical traditions differ vastly from our own. Simply put, their notes fit between our notes! Composers shouldn’t have to switch their system of notation just to play around with different kinds of music.&lt;/p&gt;

&lt;p&gt;What about our own (Western) myriad of different scales and tunings? We’re so used to Equal Temperament that we’ve completely forgotten the incredible polyculture of tunings in early music, to say nothing of the microtonal experimentation of the 20th century. Indeed, the &lt;a href=&quot;http://www.huygens-fokker.org/scala/&quot;&gt;Scala microtonal tuning archive&lt;/a&gt; has over 4000 scales! All impossible to convey with traditional notation.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad/solo.png&quot; /&gt;
&lt;p&gt;An excerpt from &quot;Comfortably Numb&quot;. Solos are cumbersome to write out using traditional notation.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Instead of trying to shoehorn all music into a Western style of notation invented several centuries ago, it occurred to me that maybe an entirely new approach was needed. In fact, why encode the music at all? The barest, most obvious form of notation is a graph of time and pitch. This system would have been too difficult for musicians to read from and write to back in the day, but that’s not really an issue when the music can play itself and your musical canvas is tactile and effectively infinite. It seemed like the best shot at covering all bases.&lt;/p&gt;

&lt;p&gt;In Composer’s Sketchpad, each “note” is a simple array of times and pitches. Note names, measures, and time signatures still exist, but only as a grid or stencil over the absolute time/pitch graph — a feature of the tooling, not an intrinsic part of the piece. You use the current scale and meter grid to align and snap your notes, but you can also change them up for use in later sections without having to worry about your existing music. Under the hood, it’s all the same: scattered little point clouds of absolute time and pitch.&lt;/p&gt;

&lt;p&gt;As a result, writing out complicated and expressive sections of music in Composer’s Section no longer feels like caging a canary. The grid is your friend, not an oppressive bureaucrat. If you want to write more conventional music, snapping to time or pitch works just as it did with traditional notation. But turn snapping off and you can bend your notes or extend them out to the exact length of time needed. Because the shape of your notes corresponds exactly to their time and pitch, a quick glance at your music tells you exactly how it’s going to sound without having to decode a mess of symbols in your head. And you can edit any part of any section or overlap as many notes as you like without having to worry about fulfilling the “note quota” of a measure, as you constantly have to do in sheet music apps like Finale.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad/melody.png&quot; /&gt;
&lt;p&gt;&quot;Comfortably Numb&quot; again in Composer&#39;s Sketchpad, transcribed by ear. This style of notation is great for conveying expressive melodic lines.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;And now, a bit of a pretentious digression, as well as a few words about the future of the project!&lt;/p&gt;

&lt;p&gt;Most programmers today are very excited about building for the web. Each day, the front page of Hacker News is filled with stories of up-and-coming web-based startups as well as new Javascript frameworks and libraries. There’s also a lot of related talk about how pay-to-own software is going away, and about how subscriptions, in-app purchases, and advertising are going to replace them.&lt;/p&gt;

&lt;p&gt;Speaking strictly for myself, I can’t stand the idea of my software residing permanently on other people’s servers or relying on money from other people’s products. For every new and exciting startup that I read about, there’s a related story of yet another acquisition or shutdown flushing years of work down the drain. What were all those man-hours, well-intentioned ideas, and midnight flashes of inspiration good for in the end? No, that style of development is not for me. I don’t want to create services, networks, or support organizations; I want to create beautiful &lt;em&gt;objects&lt;/em&gt;, little bits of clockwork that are both lovely and useful in their whole. Once they’re made, I want to be able to take my hands off them and let them live without my further involvement. I’m not interested in running servers or providing exciting new content patches week after week. You pay once — you get the object. There is certainly room for updates, but only in the interest of making the object better.&lt;/p&gt;

&lt;p&gt;I’m still far from that ideal — for example, in-app purchases might be tempting down the line — but that’s the direction I want to head with my current and future projects.&lt;/p&gt;

&lt;p&gt;Composer’s Sketchpad isn’t a profit-driven venture looking for a market or buyer. It’s one of those objects that didn’t exist in the world before I made it, and its reason for being is to help me be creative. I plan to add many new features over the years as my compositional needs develop, and I hope that eventually I’ll be able to port it to other platforms and release the source code for everyone to use. It’s a tool from my own personal toolbox that I’m happy to put out into the world.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;caption&quot;&gt;
&lt;img src=&quot;/images/composers-sketchpad/sketches.jpg&quot; /&gt;
&lt;p&gt;Some of the many design sketches made during development.&lt;/p&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Using &lt;code&gt;cloc&lt;/code&gt;, the project comes in at around 20,000 lines of code. This is a massive leap for me, and I’m incredibly excited to get started on the next 20,000!&lt;/p&gt;

</description>
        <pubDate>Fri, 05 Feb 2016 23:35:12 -0800</pubDate>
        <link>http://beta-blog.archagon.net/2016/02/05/composers-sketchpad/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2016/02/05/composers-sketchpad/</guid>
        
        
      </item>
    
      <item>
        <title>The Perfect Travel Gaiwan</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/mug_portrait.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Loose-leaf tea is a bit of a finicky hobby. Unlike the boring old teabag, you can’t just dump a bunch of tea leaves in a cup of boiling water and expect good results. At the very least, you need a way to strain your tea leaves quickly and without burning yourself. Many tea geeks enjoy the use of gaiwans for this purpose — small, lidded cups whose shape and thermal properties make them useful as single-serving teapots.&lt;/p&gt;

&lt;p&gt;But what do you do when you travel?&lt;/p&gt;

&lt;p&gt;Gaiwans tend to be made of porcelain or clay, so they’re very fragile. Until recently, I assumed I’d just have to make do with makeshift mug-plus-strainer brews when on the road. But a few months ago, I discovered a wonderful product that effectively fixed this problem, as well as several I didn’t even know I had: the &lt;a href=&quot;http://amzn.to/1ShqqsP&quot;&gt;Asobu Imperial Beverage Insulated Cup&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mug_items.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Although not marketed as a travel gaiwan, this product is suited almost perfectly to this role. The lid attaches loosely with a rubber seal, allowing for quick removal and keeping the temperature stable. There’s a hook on the back of the lid that can be used as a handy stopper when tilting it back for straining. The mug is vacuum insulated, allowing you to hold it normally even with boiling hot water inside; there’s no need to perform the crazy hand gymnastics you have to use with an ordinary gaiwan.  The insulation also ensures that the temperature inside the mug remains very hot throughout the steeping process — hotter, I would imagine, than any other material, as barely any heat radiates out! Because the mug is made from steel, you can throw it in your backpack without worrying about it breaking. And brewing aside, it’s great for public transit: if you have a thermos full of hot tea or coffee, you can slowly sip from this mug without burning your hands.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mug_pour.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sure, it’s a bit ugly, while my porcelain gaiwan is beautiful. But in all honesty, I’ve been reaching for this mug every time I brew my loose-leaf tea. The practical benefits far outweigh the aesthetic concerns.&lt;/p&gt;

&lt;p&gt;There are a few issues worth mentioning. The shape is far blobbier than it looks in the marketing photos. The paint is of poor quality and has chipped away from the bottom even with fairly light use; I’d recommend getting the stainless steel model and avoiding the colors. But overall, this mug is an incredibly functional and unique product that, to my knowledge, has no rival on Amazon.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/mug_result.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 26 Dec 2015 02:18:44 -0800</pubDate>
        <link>http://beta-blog.archagon.net/2015/12/26/the-perfect-travel-gaiwan/</link>
        <guid isPermaLink="true">http://beta-blog.archagon.net/2015/12/26/the-perfect-travel-gaiwan/</guid>
        
        
      </item>
    
  </channel>
</rss>
