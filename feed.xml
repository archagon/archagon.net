<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Archagon Was Here</title>
    <description>Alexei's pile o'stuff, featuring writing on software development, travel, photography, and more.
</description>
    <link>http://archagon.net/</link>
    <atom:link href="http://archagon.net/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 29 Mar 2018 13:56:19 -0700</pubDate>
    <lastBuildDate>Thu, 29 Mar 2018 13:56:19 -0700</lastBuildDate>
    <generator>Jekyll v3.5.1</generator>
    
      <item>
        <title>Data Laced with History: Causal Trees &amp; Operational CRDTs</title>
        <description>&lt;div class=&quot;full-width&quot;&gt;&lt;img src=&quot;/images/blog/causal-trees/header.jpg&quot; /&gt;&lt;/div&gt;

&lt;div class=&quot;donations notification&quot;&gt;Hello! This article took a while to cobble together. If you find it useful, please consider leaving a donation via &lt;a class=&quot;about-icon-container&quot; href=&quot;https://donorbox.org/crdt-article&quot;&gt;&lt;img class=&quot;about-social-icon&quot; src=&quot;/images/donation-icons/donorbox.png&quot; /&gt; &lt;span class=&quot;about-social-service&quot;&gt;DonorBox&lt;/span&gt;&lt;/a&gt;, &lt;a class=&quot;about-icon-container&quot; href=&quot;https://www.buymeacoffee.com/archagon&quot;&gt;&lt;img class=&quot;about-social-icon&quot; src=&quot;/images/donation-icons/bmac.svg&quot; /&gt; &lt;span class=&quot;about-social-service&quot;&gt;BuyMeACoffee&lt;/span&gt;&lt;/a&gt;, or &lt;a class=&quot;about-icon-container&quot; href=&quot;ethereum:0x0d5dd8a8Cca8Bf7d0122F7A1Cc76c6b0666fCC56&quot;&gt;&lt;img class=&quot;about-social-icon&quot; src=&quot;/images/donation-icons/ether.png&quot; /&gt; &lt;span class=&quot;about-social-service&quot;&gt;Ethereum&lt;/span&gt;&lt;/a&gt;. (Thought I'd try something new!) Or, just buy yourself a nice Roost through my &lt;a class=&quot;about-icon-container&quot; href=&quot;http://amzn.to/2D7uYxz&quot;&gt;&lt;img class=&quot;about-social-icon&quot; src=&quot;/images/donation-icons/amaz.png&quot; /&gt; &lt;span class=&quot;about-social-service&quot;&gt;Amazon affiliate link&lt;/span&gt;&lt;/a&gt;. Donation or not, thank you for reading! üòä&lt;/div&gt;

&lt;p&gt;(Sorry about the length! At some point in the distant past, this was supposed to be a short blog post. If you like, you can skip straight to the &lt;a href=&quot;#demo-concurrent-editing-in-macos-and-ios&quot;&gt;demo section&lt;/a&gt; which will get to the point faster than anything else.)&lt;/p&gt;

&lt;p&gt;Embarrassingly, most of my app development to date has been confined to local devices. Programmers like to gloat about the stupendous mental castles they build of their circuitous, multi-level architectures, but not me. In truth, networks leave me quite perplexed. I start thinking about data serializing to bits, servers performing secret handshakes and negotiating history, merge conflicts pushing into app-space and starting the whole process over again‚Äîand it all just turns to mush in my head. For peace of mind, my code needs to be &lt;em&gt;locally provable&lt;/em&gt;, and this means things like idempotent functions, immediate mode rendering, contiguous data structures, immutable objects. Networks, unfortunately, throw a giant wrench in the works.&lt;/p&gt;

&lt;p&gt;Sometime last year, after realizing that most of my ideas for document-based apps would probably require CloudKit for sync and collaboration, I decided to finally take a stab at the problem. Granted, there were tons of frameworks that promised to do the hard work of data model replication for me, but I didn‚Äôt want to black-box the most important part of my code. My gut told me that there had to be some arcane bit of foundational knowledge that would allow me to network my documents in a more refined and functional way, without the stateful spaghetti of conventional network architectures. Instead of downloading a Github framework and &lt;a href=&quot;http://amzn.to/2iigBOI&quot;&gt;smacking the build button&lt;/a&gt;, I wanted to develop a base set of skills that would allow me to easily network &lt;em&gt;any&lt;/em&gt; document-based app in the future, even if I was starting from scratch.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;The first order of business was to devise a wishlist for my fantastical system:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Most obviously, users should be able to edit their documents immediately, without even touching the network. (In other words, the system should only require &lt;em&gt;optimistic concurrency&lt;/em&gt;.)&lt;/li&gt;
  &lt;li&gt;Sync should happen in the background, entirely separate from the main application code, and any remote changes should be seamlessly integrated in real-time. (Put another way, sync should be treated as a kind of progressive enhancement.)&lt;/li&gt;
  &lt;li&gt;Merge should always be automatic, even for concurrent edits. The user should never be faced with a ‚Äúpick the correct revision‚Äù dialog box.&lt;/li&gt;
  &lt;li&gt;A user should be able to work on their document offline for an indefinite period of time without accruing ‚Äúsync debt‚Äù. (Meaning that if, for example, sync is accomplished by way of an operation log, performance should not suffer even if the user spends a month offline and then sends all their hundreds of changes at once.)&lt;/li&gt;
  &lt;li&gt;Secondary data structures and state should be minimized. Most of the extra information required for sync should be stored in the same place as the document, and moving the document to a new device should not break sync. (No out-of-band metadata or caches!)&lt;/li&gt;
  &lt;li&gt;Network back-and-forth should be condensed to a bare minimum, and rollbacks and re-syncs should practically never happen. To the greatest possible degree, network communication should be stateless and dumb.&lt;/li&gt;
  &lt;li&gt;To top it all off, my chosen technique had to pass the ‚ÄúPhD Test‚Äù. That is to say, one shouldn‚Äôt need a PhD to understand and implement the chosen approach for custom data models!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After musing over my bullet points, it occurred to me that the network problems I was dealing with‚Äîcloud sync, editing across multiple devices, real-time collaboration, offline support, and reconciliation of distant or conflicting revisions‚Äîwere all really different facets the same problem. Namely: how do we design a system such that any two revisions of the same document could always be merged deterministically and sensibly without requiring user intervention? Was such a thing even possible?&lt;/p&gt;

&lt;p&gt;To start with, a document could be viewed as a collection of basic data fields: registers, sequences, dictionaries, and so forth. From the perspective of something like a distributed database, it was actually quite trivial to resolve conflicts across the network in this kind of row: just keep overwriting each field with the version sporting the highest &lt;a href=&quot;https://en.wikipedia.org/wiki/Lamport_timestamps&quot;&gt;logical timestamp&lt;/a&gt;. Of course, for anything other than basic registers, this was a terrible approach. Sequences and dictionaries weren‚Äôt blobs of homogeneous data, but complex, mutable structures that users were directly manipulating, not just overwriting with every change. On merge, whether using databases or plain files, the common solution was to simply punt any conflicts to app-space so that a human could deal with them. But if these mutations were defined in terms of lower-level operations specific to each data type, could this perhaps be leveraged to implement automatic conflict resolution?&lt;/p&gt;

&lt;p&gt;In hope of uncovering some prior art, I started by looking at the proven leader in the field, Google Docs. Venturing down the deep rabbit hole of &lt;a href=&quot;https://en.wikipedia.org/wiki/Collaborative_real-time_editor&quot;&gt;real-time collaborative editing&lt;/a&gt; techniques, I discovered that many of the problems I faced fell under the umbrella of &lt;a href=&quot;https://en.wikipedia.org/wiki/Eventual_consistency&quot;&gt;strong eventual consistency&lt;/a&gt;. Unlike the more conventional &lt;a href=&quot;https://en.wikipedia.org/wiki/Strong_consistency&quot;&gt;strong consistency&lt;/a&gt; model, where all clients receive changes in identical order and rely on locking to some degree, strong &lt;em&gt;eventual&lt;/em&gt; consistency allows clients to individually diverge and then arrive at a final, consistent result once each update has been received. (Or, in a word, when the network is &lt;em&gt;quiescent&lt;/em&gt;.)&lt;/p&gt;

&lt;p&gt;There were a number of tantalizing techniques to investigate, and I kept several questions in mind while doing my analysis. Could a given technique be generalized to arbitrary document formats and data types? Did the technique pass the PhD Test? And was it possible to use the technique in an architecture with smart clients and dumb servers?&lt;/p&gt;

&lt;p&gt;The reason for that last question was CloudKit Sharing, a framework introduced in iOS 10. For the most part, this framework functioned as a superset of regular CloudKit, requiring only minor code changes to enable document sharing in an app. A developer didn‚Äôt even have to worry about connecting users or dealing with UI: Apple did most of the hard work in the background while leveraging standard system dialogs. But almost two years later, &lt;a href=&quot;https://github.com/search?l=Swift&amp;amp;q=UICloudSharingController&amp;amp;type=Code&amp;amp;utf8=‚úì&quot;&gt;on the order of no one&lt;/a&gt; seemed to be using it. Why was this? Most other Apple APIs tended to be readily adopted, especially when they allowed the developer to expand into system areas which were normally out of bounds.&lt;/p&gt;

&lt;p&gt;My hunch was that CloudKit Sharing forced the issue of real-time collaboration over a relatively dumb channel, which was a task outside the purview of conventional sync approaches. CloudKit allowed developers to easily store, retrieve, and listen for new data, but not much else besides. Unlike in the single-user, multi-device case, you couldn‚Äôt just pop up a merge dialog every time somebody made a concurrent change to your open document. But you also couldn‚Äôt resolve conflicts on the server side, since CloudKit did not permit developers to run custom code on their end. The only remaining options seemed to be some sort of ugly, heuristic auto-merge or data-dropping last-write-wins, neither of which was palatable by modern standards. Real-time collaboration along the lines of Google Docs appeared to be impossible using this system! But was it really?&lt;/p&gt;

&lt;p&gt;I realized that this was my prize to be won. If I could figure out a way to develop auto-merging documents, I‚Äôd be able to implement sync and collaboration in my apps over CloudKit while using Apple‚Äôs first-party sharing UI‚Äîall without having to pay for or manage my own servers. So this became my ultimate research goal: a collaborative iPhone text editing demo that synced entirely over CloudKit. (And here‚Äôs a spoiler: &lt;a href=&quot;#demo-concurrent-editing-in-macos-and-ios&quot;&gt;it worked!&lt;/a&gt;)&lt;/p&gt;

&lt;div class=&quot;toc-wrapper&quot;&gt;
&lt;div class=&quot;toc&quot;&gt;
&lt;div class=&quot;toc-header&quot;&gt;
&lt;h1&gt;Table of Contents&lt;/h1&gt;
&lt;/div&gt;
&lt;div class=&quot;toc-links&quot;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#convergence-techniques-a-high-level-overview&quot;&gt;Convergence Techniques: A High-Level Overview&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#operational-transformation&quot;&gt;Operational Transformation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#conflict-free-replicated-data-types&quot;&gt;Conflict-Free Replicated Data Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#differential-synchronization&quot;&gt;Differential Synchronization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#finding-the-best-approach&quot;&gt;Finding the Best Approach&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#causal-trees&quot;&gt;Causal Trees&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#demo-concurrent-editing-in-macos-and-ios&quot;&gt;Demo: Concurrent Editing in macOS and iOS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#operational-replicated-data-types&quot;&gt;Operational Replicated Data Types&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#what-is-an-ordt&quot;&gt;What Is an ORDT?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#the-ordt-pipeline&quot;&gt;The ORDT Pipeline&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#garbage-collection&quot;&gt;Garbage Collection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#ordt-design--implementation&quot;&gt;ORDT Design &amp;amp; Implementation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#causal-trees-in-depth&quot;&gt;Causal Trees In Depth&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#implementation-details&quot;&gt;Implementation Details&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#representing-non-string-objects&quot;&gt;Representing Non-String Objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#performance&quot;&gt;Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#missing-features--future-improvements&quot;&gt;Missing Features &amp;amp; Future Improvements&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#references&quot;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h1 id=&quot;convergence-techniques-a-high-level-overview&quot;&gt;Convergence Techniques: A High-Level Overview&lt;/h1&gt;

&lt;p&gt;There are a few basic terms critical to understanding eventual consistency. The first is &lt;strong&gt;causality&lt;/strong&gt;. An operation is &lt;em&gt;caused&lt;/em&gt; by another operation when it directly modifies or otherwise involves the results of that operation, and determining causality is critical to reconstructing a sensible timeline (or &lt;strong&gt;linearization&lt;/strong&gt;) of operations across the network. (An operation that &lt;em&gt;causes&lt;/em&gt; another operation must always be ordered first.) However, we can‚Äôt always determine direct causality in a general way, so algorithms often assume that an operation is causally ahead of another one if the site generating the newer operation has already seen the older operation at the time of its creation. (In other words, every operation already seen by a site at the time a new operation is created is in that operation‚Äôs &lt;em&gt;causal past&lt;/em&gt;.) This ‚Äúsoft‚Äù causality can be determined using a variety of schemes. The simplest is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Lamport_timestamps&quot;&gt;Lamport timestamp&lt;/a&gt;, which requires that every new operation have a higher timestamp than every other known operation, including any remote operations previously received. In other words, a new operation‚Äôs Lamport timestamp is always the max of every known Lamport timestamp plus 1 or higher. (Note that this approach is stateless: as long as each operation retains its Lamport timestamp, you don‚Äôt need any running state in the system to determine causality.) Although there are eventual consistency schemes that can receive operations in any order, most algorithms rely on operations arriving at each site in their &lt;strong&gt;causal order&lt;/strong&gt; (e.g. &lt;code class=&quot;highlighter-rouge&quot;&gt;insert A&lt;/code&gt; necessarily arriving before &lt;code class=&quot;highlighter-rouge&quot;&gt;delete A&lt;/code&gt;). When discussing convergence schemes, we can often assume causal order since it can be implemented fairly mechanically on the transport layer. If two operations don‚Äôt have a causal relationship‚Äîif they were created simultaneously on different sites without knowledge of each other‚Äîthey are said to be &lt;strong&gt;concurrent&lt;/strong&gt;. A Lamport timestamp can‚Äôt be used to isolate runs of concurrent operations, or to even determine with certainty whether two operations are concurrent. For that, you need a &lt;a href=&quot;https://en.wikipedia.org/wiki/Version_vector&quot;&gt;version vector&lt;/a&gt; or a &lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_clock&quot;&gt;more advanced timestamp&lt;/a&gt;. An event log in causal order can be described as having a &lt;strong&gt;partial order&lt;/strong&gt;, since concurrent operations in this log might have different positions on different devices, depending on their order of arrival. If the log is guaranteed to be identical on all devices, it has a &lt;strong&gt;total order&lt;/strong&gt;. Most of the hard work in eventual consistency involves reconciling and ordering concurrent operations. Generally speaking, concurrent operations have to be made to &lt;strong&gt;commute&lt;/strong&gt;, or have the same effect on the data regardless of their order of arrival. This can be done in a variety of ways&lt;sup id=&quot;fnref:commutes&quot;&gt;&lt;a href=&quot;#fn:commutes&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Now, there are two competing approaches in strong eventual consistency state-of-the-art, both tagged with rather unappetizing initialisms: &lt;a href=&quot;https://en.wikipedia.org/wiki/Operational_transformation&quot;&gt;Operational Transformation&lt;/a&gt; (OT) and &lt;a href=&quot;https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type&quot;&gt;Conflict-Free Replicated Data Types&lt;/a&gt; (CRDTs). Fundamentally, these approaches tackle the same problem: given an object that has been mutated by an arbitrary number of connected devices, how do we coalesce and apply their changes in a consistent way, even when those changes might be concurrent or arrive out of order? And, moreover, what do we do if a user goes offline for a long time, or if the network is unstable, or even if we‚Äôre in a peer-to-peer environment with no single source of truth?&lt;/p&gt;

&lt;h2 id=&quot;operational-transformation&quot;&gt;Operational Transformation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Operational_transformation&quot;&gt;Operational Transformation&lt;/a&gt; is the proven leader in the field, notably used by Google Docs and (now Apache) Wave as well as Etherpad and ShareJS. Unfortunately, it is only ‚Äúproven‚Äù insofar as you have a company with billions of dollars and hundreds of PhDs at hand, as the problem is &lt;em&gt;hard&lt;/em&gt;. With OT, each user has their own copy of the data, and each atomic mutation is called an &lt;strong&gt;operation&lt;/strong&gt;. (For example, &lt;code class=&quot;highlighter-rouge&quot;&gt;insert A at index 2&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;delete index 3&lt;/code&gt;.) Whenever a user mutates their data, they send their new operation to all their peers, often in practice through a central server. OT generally makes the assumption that the data is a black box and that incoming operations will be applied directly on top without the possibility of a rebase. Consequently, the only way to ensure that concurrent operations commute in their effect is to &lt;strong&gt;transform&lt;/strong&gt; them depending on their order.&lt;/p&gt;

&lt;p&gt;Let‚Äôs say Peer A inserts a character in a string at position 3, while Peer B simultaneously deletes a character at position 2. If Peer C, who has the original state of the string, receives A‚Äôs edit before B‚Äôs, everything is peachy keen. However, if B‚Äôs edit arrives first, A‚Äôs insertion will be in the wrong spot. A‚Äôs insertion position will therefore have to be transformed by subtracting the length of B‚Äôs edit. This is fine for the simple case of two switched edits, but it gets a whole lot more complicated when you start dealing with more than a single pair of concurrent changes. (An algorithm that deals with this case‚Äîand thus, &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.933&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;provably&lt;/a&gt;, with any conceivable case‚Äîis said to be have the ‚ÄúCP2/TP2‚Äù property rather than the pairwise ‚ÄúCP1/TP1‚Äù property. Yikes, where‚Äôs the naming committee when you need it?) In fact, the majority of published algorithms for string OT actually have subtle bugs in certain edge cases (such as the so-called ‚Äú&lt;a href=&quot;http://www3.ntu.edu.sg/home/czsun/projects/otfaq/#_Toc321146192&quot;&gt;dOPT puzzle&lt;/a&gt;‚Äù), meaning that they aren‚Äôt strictly convergent without occasional futzing and re-syncing by way of a central server. And while the idea that you can treat your model objects strictly in terms of operations is elegant in its premise, the fact that adding a new operation to the schema requires figuring out its interactions with &lt;em&gt;every existing operation&lt;/em&gt; is nearly impossible to grapple with.&lt;/p&gt;

&lt;h2 id=&quot;conflict-free-replicated-data-types&quot;&gt;Conflict-Free Replicated Data Types&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type&quot;&gt;Conflict-Free Replicated Data Types&lt;/a&gt; are the new hotness in the field. In contrast to OT, the CRDT approach considers sync in terms of the underlying data structure, not the sequence of operations. A¬†CRDT, at a high level, is a type of object that can be merged with any objects of the same type, in arbitrary order, to produce an identical union object. CRDT merge must be associative, commutative, and idempotent, and the resulting CRDT of each mutation or merge must be ‚Äúgreater‚Äù than than all its inputs. (Mathematically, this flow is said to form a &lt;em&gt;monotonic semilattice&lt;/em&gt;.) As long as each connected peer eventually receives the updates of every other peer, the results will provably converge‚Äîeven if one peer happens to be a month behind. This might sound like a tall order, but you‚Äôre already aware of several simple CRDTs. For example, no matter how you permute the merge order of any number of insert-only sets, you‚Äôll still end up with the same union set in the end. Really, the concept is quite intuitive!&lt;/p&gt;

&lt;p&gt;Of course, simple sets aren‚Äôt enough to represent arbitrary data, and much of CRDT research is dedicated to finding new and improved ways of implementing sequence CRDTs, often under the guise of string editing. Algorithms vary, but this is generally accomplished by giving each individual letter its own unique identifier, then giving each letter a reference to its intended neighbor instead of dealing with indices. On deletion, letters are usually replaced with &lt;strong&gt;tombstones&lt;/strong&gt; (placeholders), allowing two sites to concurrently reference and delete a character at the same time while still being able to merge correctly. This does tend to mean that sequence CRDTs perpetually grow in proportion to the number of deleted characters in a document, though there are various ways of dealing with this accumulated garbage.&lt;/p&gt;

&lt;p&gt;One last thing to note is that there are actually two kinds of CRDTs: CmRDTs and CvRDTs. (Seriously, there‚Äôs got to be a better way to name these things‚Ä¶) CmRDTs, or operation-based CRDTs, only require peers to exchange mutation events&lt;sup id=&quot;fnref:op-crdt&quot;&gt;&lt;a href=&quot;#fn:op-crdt&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, but place some constraints on the transport layer. (For instance, exactly-once and/or causal delivery, depending on the CmRDT in question.) With CvRDTs, or state-based CRDTs, peers must exchange their full data structures and then merge them locally, placing no constraints on the transport layer but taking up far more bandwidth and possibly CPU time. Both types of CRDT are equivalent and can be converted to either form. However, for the use case of designing convergent document formats, CvRDTs are the way to go.&lt;/p&gt;

&lt;h2 id=&quot;differential-synchronization&quot;&gt;Differential Synchronization&lt;/h2&gt;

&lt;p&gt;There‚Äôs actually one more technique that‚Äôs worth discussing, and it‚Äôs a bit of an outlier. This is Neil Fraser‚Äôs &lt;a href=&quot;https://neil.fraser.name/writing/sync/&quot;&gt;Differential Synchronization&lt;/a&gt;. Used in an earlier version of Google Docs before their flavor of OT was implemented, Differential Sync uses &lt;a href=&quot;https://neil.fraser.name/writing/diff/&quot;&gt;contextual diffing&lt;/a&gt; between local revisions of documents to generate streams of frequent, tiny edits between peers. If there‚Äôs a conflict, the receiving peer uses &lt;a href=&quot;https://neil.fraser.name/writing/patch/&quot;&gt;fuzzy patching&lt;/a&gt; to apply the incoming changes as best as possible, then contextually diffs the resulting document with a reproduced copy of the sender‚Äôs document (using a cached ‚Äúshadow copy‚Äù of the last seen version) and sends the new changes back. This establishes a sort of incremental sync loop. Eventually, all peers converge on a final, stable document state. Unlike with OT and CRDTs, the end result is not mathematically defined, but instead relies on the organic behavior of the fuzzy patching algorithm when faced with diffs of varying contexts and sizes.&lt;/p&gt;

&lt;h2 id=&quot;finding-the-best-approach&quot;&gt;Finding the Best Approach&lt;/h2&gt;

&lt;p&gt;Going into this problem, my first urge was to adopt Differential Sync. One might complain that this algorithm has too many subjective bits for production use, but that‚Äôs exactly what appealed to me about it. Merge is a complicated process that often relies on heuristics entirely separate from the data format. A human would merge two list documents and two prose documents very differently, even though they might both be represented as text. With Differential Sync, all this complex logic is encapsulated in the diff and patch functions. Like git, the system is content-centric in the sense that the patches work directly with the output data and don‚Äôt have any hooks into the data structure or code. The implementation of the data format could be refactored as needed, and the diff and patch functions could be tweaked and improved over time, and neither system would have to know about changes to the other. It also meant that the documents in their original form could be preserved in their entirety server-side, synergizing nicely with Dropbox-style cloud backup. It felt like the perfect dividing line of abstraction.&lt;/p&gt;

&lt;p&gt;But studying Differential Sync further, I realized that a number of details made it a non-starter. First, though the approach seems simple on the surface, its true complexity is concealed by the implementation of diff and patch. This class of functions works well for strings, but you basically need to be a seasoned algorithms expert to design a set for a new data type. (Worse: the inherent fuzziness depends on non-objective metrics, so you‚Äôd only be able to figure out the effectiveness of your algorithms after prolonged use and testing instead of formal analysis.) Second, diff and patch as they currently exist are really meant for loosely-structured data such as strings and images. Barring conversion to text-based intermediary formats, tightly structured objects would be very difficult to diff and patch while maintaining consistency. Next, there are some issues with using Differential Sync in an offline-first environment. Clients have to store their entire diff history while offline, and then, on reconnection, send the whole batch to their peers for a very expensive merge. Assuming that other sites had been editing away in the meantime, distantly-divergent versions would very likely fail to merge on account of out-of-date context info and lose much of the data for the reconnected peer. Finally, Differential Sync only allows one packet at a time to be in flight between two peers. If there are network issues, the whole thing grinds to a halt.&lt;/p&gt;

&lt;p&gt;Begrudgingly, I had to abandon the elegance of Differential Sync and decide between the two deterministic approaches. CRDTs raised some troubling questions, including the impact of per-letter metadata and the necessity of tombstones in most sequence CRDTs. You could end up with a file that looked tiny (or even empty) but was in fact enormous under the hood. However, OT was a no-go right from the start. One, the event-based system would have been untenable to build on top of a simple database like CloudKit. You really needed active servers or peer-to-peer connections for that. And two, I discovered that the few known sequence OT algorithms guaranteed to converge in all cases‚Äîthe ones with the coveted CP2/TP2 property‚Äîended up relying on tombstones anyway! (If you‚Äôre interested, Raph Levien touches on this curious overlap &lt;a href=&quot;https://medium.com/@raphlinus/towards-a-unified-theory-of-operational-transformation-and-crdt-70485876f72f&quot;&gt;in this article&lt;/a&gt;.) So it didn‚Äôt really matter which choice I made. If I wanted the resiliency of a provably convergent system, I had to deal with metadata-laden data structures that left some trace of their deleted elements.&lt;/p&gt;

&lt;p&gt;And with their focus on data over process, CRDTs pointed to a paradigm shift in networked computing. A document format based on CRDTs‚Äîa voraciously-mergeable ‚Äúgolden file‚Äù‚Äîwould push network issues completely of the way. The system would be completely functional, even in communication with remote devices. You‚Äôd be able to throw different versions of the same file together in any order to obtain the same merge result, never once having to ask anything of the user. Everything would work without quirks in offline mode regardless of how much time had passed. Instead of dealing with the endless headaches of coordination, data could be promiscuously streamed to any device listening for changes. The document would be topology-agnostic to such a degree that you could use it in a peer-to-peer environment, send it between phone and laptop via Bluetooth, share it with multiple local applications, and sync it through a traditional centralized database. All at the same time!&lt;/p&gt;

&lt;p&gt;I admit that a wily political thought crossed my mind at this point. Could this be the chance to finally break free from the shackles of the cloud? It always felt like such an affront that my data had to snake through a tangle of corporate servers in order to reach the device next to me. We used to happily share files across applications and even operating systems, and now everything was funneled through these monolithic black boxes. What happened? How did we let computing become so darn &lt;em&gt;undemocratic&lt;/em&gt;? Heck, it had gotten so bad that we actually &lt;em&gt;expected&lt;/em&gt; our content and workflows to regularly vanish as companies folded or got themselves acquired!&lt;/p&gt;

&lt;p&gt;The CRDT approach offered documents the power to personally manage their own sync and collaboration, transforming servers from gatekeepers into dumb, hot-swappable conduits and returning control over data to its users. But the road here was fresh and unpaved, and I needed to figure out if I could use these structures in a performant and space-efficient way for non-trivial applications.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/semilattice.svg&quot; style=&quot;width:27rem&quot; /&gt;
&lt;figcaption&gt;The mythical, eminently-mergeable golden file in its adventures through the semilattice.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The next step was to read through the academic literature on CRDTs. There was a group of usual suspects for the hard case of sequence (text) CRDTs: &lt;a href=&quot;https://hal.archives-ouvertes.fr/inria-00108523/document&quot;&gt;WOOT&lt;/a&gt;, &lt;a href=&quot;https://hal.inria.fr/inria-00397981/document&quot;&gt;Treedoc&lt;/a&gt;, &lt;a href=&quot;https://hal.inria.fr/inria-00336191/document&quot;&gt;Logoot&lt;/a&gt;/&lt;a href=&quot;https://hal.archives-ouvertes.fr/hal-00921633/document&quot;&gt;LSEQ&lt;/a&gt;, and &lt;a href=&quot;https://pdfs.semanticscholar.org/8470/ae40470235604f40382aea4747275a6f6eef.pdf&quot;&gt;RGA&lt;/a&gt;. WOOT is the progenitor of the genre and gives each character in a string a reference its adjacent neighbors on both sides. Recent analysis has shown it to be inefficient compared to newer approaches. Treedoc has a similar early adopter performance penalty. Logoot (which is optimized further by LSEQ) curiously avoids tombstones by treating each element as a unique point along a dense (infinitely-divisible) number line, adopting bignum-like identifiers with unbounded growth for ordering. Unfortunately, it has a problem with &lt;a href=&quot;https://stackoverflow.com/questions/45722742/logoot-crdt-interleaving-of-data-on-concurrent-edits-to-the-same-spot&quot;&gt;interleaved text on concurrent edits&lt;/a&gt;. RGA makes each character implicitly reference its leftmost neighbor and uses a hash table to make character lookups efficient. It also features an update operation alongside the usual insert and delete. The paper is annoyingly dense with theory, but the approach often comes out ahead in benchmark comparisons. I also found a couple of recent, non-academic CRDT designs such as &lt;a href=&quot;https://github.com/y-js/yjs&quot;&gt;Y.js&lt;/a&gt; and &lt;a href=&quot;http://google.github.io/xi-editor/docs/crdt-details.html&quot;&gt;xi&lt;/a&gt;, all of which brought something new to the table but felt rather convoluted in comparison to the good-enough RGA. In almost all cases, conflicts between concurrent changes were resolved by way of a unique origin ID plus a logical timestamp per character. Sometimes, they were discarded when an operation was applied; other times, they persisted even after merge.&lt;/p&gt;

&lt;p&gt;Reading through the literature was highly educational, and I now had a good intuition about the behavior of sequence CRDTs. But I just couldn‚Äôt find very much in common between the disparate approaches. Each one brought its own operations, proofs, optimizations, conflict resolution methods, and garbage collection schemes to the table. Many of the papers blurred the line between theory and implementation, making it even harder to suss out any underlying principles. I felt confident using these algorithms for convergent arrays, but I wasn‚Äôt quite sure how to build my own replicated data structures using the same principles.&lt;/p&gt;

&lt;p&gt;Finally, I discovered the one key CRDT that made things click for me.&lt;/p&gt;

&lt;h1 id=&quot;causal-trees&quot;&gt;Causal Trees&lt;/h1&gt;

&lt;p&gt;A a state-based CvRDT, on a high level, can be viewed as a data blob along with a commutative, associative, and idempotent merge function that can always generate a monotonically further-ahead blob from any two. An operation-based CmRDT, meanwhile, can be viewed as a data blob that is mutated and pushed monotonically forward by a stream of commutative-in-effect (and maybe causally-ordered and deduplicated) events. If the CvRDT data blob were defined to simply be an ordered collection of operations, could these two techniques be combined? We‚Äôd then have the best of both worlds: an eminently-mergeable data structure, plus the ability to define our data model in terms of domain-specific actions!&lt;/p&gt;

&lt;p&gt;Let‚Äôs build a sequence CvRDT with this in mind. To have some data to work with, here‚Äôs an example of a concurrent string mutation.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/network-chart.svg&quot; style=&quot;width:40rem&quot; /&gt;
&lt;figcaption&gt;&lt;span&gt;The small numbers over the letters are &lt;a href=&quot;https://en.wikipedia.org/wiki/Lamport_timestamps&quot;&gt;Lamport timestamps&lt;/a&gt;.&lt;/span&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Site 1 types ‚ÄúCMD‚Äù, sends its changes to Site 2 and Site 3, then resumes its editing. Site 2 and 3 then make their own changes and send them back to Site 1 for the final merge. The result, ‚ÄúCTRLALTDEL‚Äù, is the most intuitive merge we could expect: insertions and deletions all persist, runs of characters don‚Äôt split up, and most recent changes come first.&lt;/p&gt;

&lt;p&gt;First idea: just take the standard set of array operations (&lt;code class=&quot;highlighter-rouge&quot;&gt;insert A at index 0&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;delete index 3&lt;/code&gt;, etc.), turn each operation into an immutable struct, stick the structs into a new array in their creation order, and read them back to reconstruct the original array as needed. (In other words, the CvRDT would simply function as an event log.) This won‚Äôt be convergent by default since these operations don‚Äôt have an inherent total order, but it‚Äôs easy to fix this by giving each operation a globally-unique ID in the form of an owner UUID&lt;sup id=&quot;fnref:uuid&quot;&gt;&lt;a href=&quot;#fn:uuid&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; along with a Lamport timestamp. With this scheme, no two operations can have the same ID: operations from the same owner will have different timestamps, while operations from different owners will have different UUIDs. The Lamport timestamps will put the operations in causal order with the UUIDs used for tiebreaking when concurrent operations happen to have the same timestamp. Now, when a new operational array arrives from a remote peer, the merge is as simple as iterating through both arrays and shifting any new operations to their proper spots: an elementary merge sort.&lt;/p&gt;

&lt;div class=&quot;mostly-full-width&quot;&gt;&lt;img src=&quot;/images/blog/causal-trees/indexed.svg&quot; /&gt;&lt;/div&gt;

&lt;p&gt;Success: it‚Äôs an operation-based, fully-convergent CvRDT! Well, sort of. There are two major issues here. First, reconstructing the original array by processing the full operational array has &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;) complexity&lt;sup id=&quot;fnref:complexity&quot;&gt;&lt;a href=&quot;#fn:complexity&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, and it has to happen on every key press to boot. Second, intent is completely clobbered. Reading the operations back, we get something along the lines of ‚ÄúCTRLDATLEL‚Äù (with a bit of handwaving when it comes to inserts past the array bounds). Just because a data structure converges doesn‚Äôt mean it makes a lick of sense! In the earlier OT section, we saw that concurrent index-based operations can be made to miss their intended characters depending on the order. (Recall that this is the problem OT solves by transforming operations, but here our operations are immutable.) In a sense, this is because the operations are specified incorrectly. They make an assumption that doesn‚Äôt get encoded in the operations themselves‚Äîthat an index can always uniquely identify a character‚Äîand thus lose the commutativity of their intent when this turns out not to be the case.&lt;/p&gt;

&lt;p&gt;OK, so the first step is to fix the intent problem. To do that, we have to strip our operations of any implicit context and define them in absolute terms. Fundamentally, &lt;code class=&quot;highlighter-rouge&quot;&gt;insert A at index 0&lt;/code&gt; isn‚Äôt &lt;em&gt;really&lt;/em&gt; what the user wants to do. People don‚Äôt think in terms of indices. They want to insert a character at the cursor position, which is perceived as being between two letters‚Äîor more simply, to the immediate right of a single letter. We can encode this by switching our operations to the format &lt;code&gt;insert A&lt;sup&gt;id&lt;/sup&gt; after B&lt;sup&gt;id&lt;/sup&gt;&lt;/code&gt;, where each letter in the array is uniquely identified. Given causal order, and assuming that deleted characters persist until any operations that reference them are processed, the intent of these operations is now commutative: there will only ever be that one specific ‚ÄòB‚Äô in the array, allowing us to always position ‚ÄòA‚Äô just as the user intended.&lt;/p&gt;

&lt;p&gt;So how do we identify a particular letter? Just ‚ÄòA‚Äô and ‚ÄòB‚Äô are ambiguous, after all. We could generate a new ID for each inserted letter, but this isn‚Äôt necessary: we already have unique timestamp+UUID identifiers for all our operations. Why not just use the operation identifiers as proxies for their output? In other words, an &lt;code class=&quot;highlighter-rouge&quot;&gt;insert A&lt;/code&gt; operation could stand for that particular letter ‚ÄòA‚Äô when referenced by other operations. Now, no extra data is required, and everything is still defined in terms of our original atomic and immutable operations.&lt;/p&gt;

&lt;div class=&quot;mostly-full-width&quot;&gt;&lt;img src=&quot;/images/blog/causal-trees/causal.svg&quot; /&gt;&lt;/div&gt;

&lt;p&gt;This is significantly better than before! We now get ‚ÄúCTRLALTDEL‚Äù after processing this operational array, correctly-ordered and even preserving character runs as desired. But performance is still an issue. As it stands, the output array would still take &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;) to reconstruct. The main roadblock is that array insertions and deletions tend to be &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) operations, and we need to replay our entire &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) history whenever remote changes come in or when we‚Äôre recreating the output array from scratch. Array &lt;em&gt;push&lt;/em&gt; and &lt;em&gt;pop&lt;/em&gt;, on the other hand, are only &lt;em&gt;O&lt;/em&gt;(1) amortized. What if instead of sorting our entire operational array by timestamp+UUID, we positioned operations in the order of their output? This could be done by placing each operation to the right of its causal operation (parent), then sorting it in reverse timestamp+UUID order among the remaining operations&lt;sup id=&quot;fnref:rga&quot;&gt;&lt;a href=&quot;#fn:rga&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. In effect, this would cause the operational array to mirror the structure of the output array. The result would be identical to the previous approach, but the speed of execution would be substantially improved.&lt;/p&gt;

&lt;div class=&quot;mostly-full-width&quot;&gt;&lt;img src=&quot;/images/blog/causal-trees/causal-ordered.svg&quot; /&gt;&lt;/div&gt;

&lt;p&gt;With this new order, local operations require a bit of extra processing when they get inserted into the operational array. Instead of simply appending to the back, they have to first locate their parent, then find their spot among the remaining operations‚Äî&lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) instead of &lt;em&gt;O&lt;/em&gt;(1). In return, producing the output array is now only &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;), since we can read the operations in order and (mostly) push/pop elements in the output array as we go along&lt;sup id=&quot;fnref:deleteref&quot;&gt;&lt;a href=&quot;#fn:deleteref&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;. In fact, we can almost treat this operational array &lt;em&gt;as if it were the string itself&lt;/em&gt;, even going as far as using it as a backing store for a fully-functional &lt;code class=&quot;highlighter-rouge&quot;&gt;NSMutableString&lt;/code&gt; subclass (with some performance caveats). The operations are no longer just instructions: they have &lt;em&gt;become&lt;/em&gt; the data!&lt;/p&gt;

&lt;p&gt;(Observe that throughout this process, we have not added any extra data to our operation structs. We have simply arranged them in a more precise causal order than the default timestamp+UUID sort allows, which is possible based on our knowledge of the unique causal characteristics of the data model. For example, no matter how high a timestamp an insert operation might have, we know that the final position of its output in the string is solely determined by its parent, as well as any concurrent runs of inserts that have a higher timestamp+UUID. Every other operation in timestamp+UUID order between that operation and its parent is irrelevant, even if the Lamport timestamps might conservatively imply otherwise. In other words: the Lamport timestamp serves as a sort of brute force upper bound on causality, but we can arrange the operations much more accurately by using domain knowledge.)&lt;/p&gt;

&lt;p&gt;Pulled out of its containing array, we can see that what we‚Äôve designed is, in fact, an operational &lt;em&gt;tree&lt;/em&gt;‚Äîone which happens to be implicitly stored as a depth-first, in-order traversal in contiguous memory. Concurrent edits are sibling branches. Subtrees are runs of characters. By the nature of reverse timestamp+UUID sort, sibling subtrees are sorted in the order of their head operations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/causal-trees/tree.svg&quot; style=&quot;width:40rem&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is the underlying premise of the Causal Tree.&lt;/p&gt;

&lt;p&gt;In contrast to all the other CRDTs I‚Äôd been looking into, the design presented in Victor Grishchenko‚Äôs &lt;a href=&quot;http://www.ds.ewi.tudelft.nl/~victor/articles/ctre.pdf&quot;&gt;brilliant paper&lt;/a&gt; was simultaneously clean, performant, and consequential. Instead of dense layers of theory and labyrinthine data structures, everything was centered around the idea of atomic, immutable, metadata-tagged, and causally-linked operations, stored in low-level data structures and directly usable as the data they represented. From these attributes, entire classes of features followed.&lt;/p&gt;

&lt;p&gt;(The rest of the paper will be describing &lt;a href=&quot;https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTFramework&quot;&gt;my own CT implementation in Swift&lt;/a&gt;, incorporating most of the concepts in the original paper but sporting tweaks based on further research.)&lt;/p&gt;

&lt;p&gt;In CT parlance, the operation structs that make up the tree are called &lt;strong&gt;atoms&lt;/strong&gt;. Each atom has a unique &lt;strong&gt;identifier&lt;/strong&gt; comprised of a &lt;strong&gt;site&lt;/strong&gt; UUID, &lt;strong&gt;index&lt;/strong&gt;, and Lamport &lt;strong&gt;timestamp&lt;/strong&gt;&lt;sup id=&quot;fnref:awareness&quot;&gt;&lt;a href=&quot;#fn:awareness&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;. The index and timestamp serve the same role of logical clock, and the data structure could be made to work with one or the other in isolation. (The reason to have both is to enable certain optimizations: the index for &lt;em&gt;O&lt;/em&gt;(1) atom lookups by identifier, and the timestamp for &lt;em&gt;O&lt;/em&gt;(1) causality queries between atoms.) The heart of an atom is its &lt;strong&gt;value&lt;/strong&gt;, which defines the behavior of the operation and stores any relevant data. (Insert operations store the new character to place, while delete operations contain no extra data.) An atom also stores the identifier of its &lt;strong&gt;cause&lt;/strong&gt;, or parent, atom. Generally speaking, this is an atom whose effect on the data structure is a prerequisite for the proper functioning of its child atom. (As explained earlier, in a string CT, this causal link simply represents the character to the left of an insertion or the target of a deletion.)&lt;/p&gt;

&lt;p&gt;In Swift code, an atom might look something like this:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Codable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Hashable&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UInt16&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UInt32&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UInt32&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Atom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Codable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Codable&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Id&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;cause&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Id&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;While a string value might look like this:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;enum&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StringValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Codable&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;null&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UInt16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delete&lt;/span&gt;
  
    &lt;span class=&quot;c1&quot;&gt;// insert Codable boilerplate here&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;typealias&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StringAtom&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Atom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;StringValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;What‚Äôs great about this representation is that Swift automatically compresses enums with associated values to their smallest possible byte size, i.e. the size of the largest associated value plus a byte for the case, or even less if Swift can determine that a value type has some extra bits available. Here, the size would be 3 bytes. In case you‚Äôre wondering about the 16-bit ‚ÄúUUID‚Äù for the site, I‚Äôve devised a mapping scheme from 16-bit IDs to full 128-bit UUIDs that I‚Äôll explain in a later section.&lt;/p&gt;

&lt;p&gt;For convenience, a CT begins with a ‚Äúzero‚Äù root atom, and the ancestry of each subsequent atom can ultimately be traced back to it. The depth-first, in-order traversal of our operational tree is called a &lt;strong&gt;weave&lt;/strong&gt;, equivalent to the operational array discussed earlier. Instead of representing the tree as an inefficient tangle of pointers, we store it in memory as this weave array. Additionally, since we know the creation order of each atom on every site by way of its timestamp (and since a CT is not allowed to contain any causal gaps), we can always derive a particular site‚Äôs exact sequence of operations from the beginning of time. This sequence of site-specific atoms in creation order is called a &lt;strong&gt;yarn&lt;/strong&gt;. Yarns are more of a cache than a primary data structure in a CT, but I keep them around together with the weave to enable &lt;em&gt;O&lt;/em&gt;(1) atom lookups. To pull up an atom based on its identifier, all you have to do is grab its site‚Äôs yarn array and read out the atom at the identifier‚Äôs index.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/yarns.svg&quot; style=&quot;width:53rem&quot; /&gt;
&lt;figcaption&gt;Each row, called a yarn, represents the full, contiguous sequence of operations for a given site.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Storing the tree as an array means we have to be careful while modifying it, or our invariants will be invalidated and the whole thing will fall apart. When a local atom is created and parented to another atom, it is inserted immediately to the right of its parent in the weave. It‚Äôs easy to show that this logic preserves the sort order: since the new atom necessarily has a higher Lamport timestamp than any other atom in the weave, it always belongs in the spot closest to its parent. On merge, we have to be a bit more clever if we want to keep things &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;). The naive solution‚Äîiterating through the incoming weave and individually sorting each new atom into our local weave‚Äîwould be &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;). If we had an easy way to compare any two atoms, we could perform a simple and efficient merge sort. Unfortunately, the order of two atoms is a non-binary relation since it involves ancestry information in addition to the timestamp and UUID. In other words, you can‚Äôt write a simple comparator for two atoms in isolation without also referencing the full CT.&lt;/p&gt;

&lt;p&gt;Fortunately, we can use our knowledge of the underlying tree structure to keep things simple. (The following algorithm assumes that both weaves are correctly ordered and preserve all their invariants.) Going forward, it‚Äôs useful to think of each atom as the head of a subtree in the larger CT. On account of the DFS ordering used for the weave, all of an atom‚Äôs descendants are contained in a contiguous range immediately to its right called a &lt;strong&gt;causal block&lt;/strong&gt;. To merge, we compare both weaves atom-by-atom until we find a mismatch. There are three possibilities in this situation: the local CT has a subtree missing from the incoming CT, the incoming CT has a new subtree missing from the local CT, or the two CTs have concurrent sibling subtrees. (Proving that the only possible concurrent change to the same spot is that of sibling subtrees is an exercise left to the reader.) The first two cases are easy to discover and deal with: verify that one of the two atoms appears in the other‚Äôs CT and keep inserting or fast-forwarding atoms until the two weaves line up again. For the last case, we have to arrange the two concurrent causal blocks in their correct order. This is pretty simple, too: the end of a causal block can be found based on an algorithm featured in the paper&lt;sup id=&quot;fnref:lemma&quot;&gt;&lt;a href=&quot;#fn:lemma&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;, while the ultimate order of the blocks is determined by the order of their head atoms. Following any change to the weave, any stored yarns must also be updated.&lt;/p&gt;

&lt;p&gt;One more data structure to note is a collection of site+timestamp pairs called a &lt;strong&gt;weft&lt;/strong&gt;, which is simply a fancy name for a &lt;a href=&quot;https://en.wikipedia.org/wiki/Version_vector&quot;&gt;version vector&lt;/a&gt;. You can think of this as a filter on the tree by way of a cut across yarns: one in which only the atoms with a timestamp less than or equal to the timestamp associated with their site in the weft are included. Wefts can uniquely identify and split the CT at any point in its mutation timeline, and are very useful for features such as garbage collection and past revision viewing.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/weft.svg&quot; style=&quot;width:53rem&quot; /&gt;
&lt;figcaption&gt;The dotted line represents weft 1:6‚Äì2:7‚Äì3:7 in Lamport timestamp format, or weft 1:3‚Äì2:1‚Äì3:0 in index format. The two representations are equivalent.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;A weft needs to be &lt;strong&gt;consistent&lt;/strong&gt; in two respects. First, there‚Äôs consistency in the distributed computing sense: causality of operations must be maintained. This is easily enforced by ensuring that the tree is fully-connected under the cut. Second, there‚Äôs the domain-dependent definition: the resulting tree must be able to produce an internally-consistent data structure with no invariants violated. This isn‚Äôt an issue with strings, but there are other kinds of CT-friendly data where the weave might no longer make sense if the cut is in the wrong place. In the given example, the weft describes the string ‚ÄúCDADE‚Äù, providing a hypothetical view of the distributed data structure in the middle of all three edits.&lt;/p&gt;

&lt;h1 id=&quot;demo-concurrent-editing-in-macos-and-ios&quot;&gt;Demo: Concurrent Editing in macOS and iOS&lt;/h1&gt;

&lt;p&gt;Words, words, words! To prove that the Causal Tree is a useful and effective data structure in the real world, &lt;a href=&quot;https://github.com/archagon/crdt-playground&quot;&gt;I‚Äôve implemented a generic version in Swift together with a set of demo apps&lt;/a&gt;. Please note that this is strictly an educational codebase and not a production-quality library! My goal with this project was to dig for knowledge that might aid in app development, not create another framework du jour. It‚Äôs messy, undocumented, a bit slow, and surely broken in some places‚Äîbut it gets the job done.&lt;/p&gt;

&lt;div class=&quot;caption full-width&quot;&gt;
&lt;video controls=&quot;&quot; muted=&quot;&quot; preload=&quot;none&quot; width=&quot;100%&quot; poster=&quot;/images/blog/causal-trees/demo/mac-main.jpg&quot;&gt;
&lt;source src=&quot;/images/blog/causal-trees/demo/mac-main.mp4&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;From 0:00‚Äì0:23, sites 1‚Äì3 are created and connect to each other in a ring. From 0:23‚Äì0:34, Site 4 and 5 are forked from 1, establish a two-way connection to 1 to exchange peer info, then go back offline. At 0:38, Site 4 connects to 5, which is still not sending data to anyone. At 0:42, Site 5 connects to 1 and Site 1 connects to 4, finally completing the network. At 0:48, all the sites go offline, then return online at 1:06.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;The first part of the demo is a macOS mesh network simulator. Each window represents an independent site that has a unique UUID and holds its own copy of the CT. The CTs are edited locally through the type-tailored editing view. New sites must be forked from existing sites, copying over the current state of the CT in the process. Sites can go ‚Äúonline‚Äù and establish one-way connections to one or more known peers, which sends over their CT and known peer list about once a second. On receipt, a site will merge the inbound CT into their own. Not every site knows about every peer, and forked sites will be invisible to the rest of the network until they go online and connect to one of their known peers. All of this is done locally to simulate a partitioned, unreliable network with a high degree of flexibility: practically any kind of topology or partition can be set up using these windows. For string editing, the text view uses the CT directly as its backing store by way of an &lt;code class=&quot;highlighter-rouge&quot;&gt;NSMutableString&lt;/code&gt; &lt;a href=&quot;https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTFramework/StringRepresentation/CausalTreeStringWrapper.swift&quot;&gt;wrapper&lt;/a&gt; plugged into a bare-bones &lt;code class=&quot;highlighter-rouge&quot;&gt;NSTextStorage&lt;/code&gt; &lt;a href=&quot;https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CloudKitRealTimeCollabTest/Model/CausalTreeCloudKitTextStorage.swift&quot;&gt;subclass&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;caption full-width&quot;&gt;
&lt;video controls=&quot;&quot; muted=&quot;&quot; preload=&quot;none&quot; width=&quot;100%&quot; poster=&quot;/images/blog/causal-trees/demo/mac-yarns.jpg&quot;&gt;
&lt;source src=&quot;/images/blog/causal-trees/demo/mac-yarns.mp4&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;You can open up a yarn view that resembles the diagram in the &lt;a href=&quot;http://www.ds.ewi.tudelft.nl/~victor/articles/ctre.pdf&quot;&gt;CT paper&lt;/a&gt;, though this is only really legible for simple cases. In this view, you can scroll around with the left mouse button and select individual atoms to list their details with the right mouse button.&lt;/p&gt;

&lt;div class=&quot;caption full-width&quot;&gt;
&lt;video controls=&quot;&quot; muted=&quot;&quot; preload=&quot;none&quot; width=&quot;100%&quot; poster=&quot;/images/blog/causal-trees/demo/mac-shapes.jpg&quot;&gt;
&lt;source src=&quot;/images/blog/causal-trees/demo/mac-shapes.mp4&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;The three sites are connected in a ring. At 0:43, all sites go offline, then return online at 1:00.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Also included is an example of a CT-backed data type for working with simple vector graphics. Using the editing view, you can create shapes, select and insert points, move points and shapes around, change the colors, and change the contours. Just as before, everything is synchronized with any combination of connected peers, even after numerous concurrent and offline edits. (To get a sense of how to use CTs with non-string data types, read on!)&lt;/p&gt;

&lt;div class=&quot;caption full-width&quot;&gt;
&lt;video controls=&quot;&quot; muted=&quot;&quot; preload=&quot;none&quot; width=&quot;100%&quot; poster=&quot;/images/blog/causal-trees/demo/mac-revisions.jpg&quot;&gt;
&lt;source src=&quot;/images/blog/causal-trees/demo/mac-revisions.mp4&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;/div&gt;

&lt;p&gt;Each site can display a previously-synced, read-only revision of its document via the dropdown list. Because a CT‚Äôs operations are atomic, immutable, and tagged with precise origin metadata, this functionality effectively comes free! And this is only one of many emergent properties of CTs.&lt;/p&gt;

&lt;div class=&quot;caption full-width&quot;&gt;
&lt;video controls=&quot;&quot; muted=&quot;&quot; preload=&quot;none&quot; width=&quot;100%&quot; poster=&quot;/images/blog/causal-trees/demo/iphone.jpg&quot;&gt;
&lt;source src=&quot;/images/blog/causal-trees/demo/iphone.mp4&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;The phone on the left shares an iCloud account with the phone in the middle, while the phone on the right is logged in to a different iCloud account and has to receive a CloudKit Share. At 0:29 and 1:21, remote cursor sync is demonstrated, and 1:30‚Äì2:00 shows offline use. At 2:15, simultaneous predictive typing is used to demo editing under high concurrency. Apologies for the occasional delays: iCloud is slow and my network code is a mess!&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;The second part of the demo is a very simple CloudKit-powered text editing app for iOS. Much of it is wonky and unpolished (since I‚Äôm very much a CloudKit newbie), but the important part is that real-time collaboration (including remote cursors) works correctly and efficiently, whether syncing to the same user account, collaborating with others via CloudKit Sharing, or just working locally for long periods of time. The network layer only deals with binary data blobs and has no insight into the particular structure of the data. Whether local or remote, all conflicts are resolved automatically in the same section of code. Best of all, no extra coordinating servers are required: the dumb CloudKit database works just fine.&lt;/p&gt;

&lt;p&gt;My CT implementation isn‚Äôt quite production ready (though I‚Äôll keep hammering away for use in my commercial projects), but I think it‚Äôs convincing proof that the technique is sound and practical for use with collaborative document-based applications!&lt;/p&gt;

&lt;h1 id=&quot;operational-replicated-data-types&quot;&gt;Operational Replicated Data Types&lt;/h1&gt;

&lt;p&gt;Causal Trees, however, are just the beginning: there‚Äôs a more universal pattern at work here. Recent research projects, including Victor Grishchenko‚Äôs &lt;a href=&quot;https://github.com/gritzko/ron&quot;&gt;Replicated Object Notation&lt;/a&gt; (RON) and the paper &lt;a href=&quot;https://arxiv.org/pdf/1710.04469.pdf&quot;&gt;&lt;em&gt;Pure Operation-Based Replicated Data Types&lt;/em&gt;&lt;/a&gt; (hereafter &lt;em&gt;PORDT&lt;/em&gt;), have extended the operational paradigm to almost any kind of CRDT, giving us a standard set of tools for designing and analyzing these fascinating data structures.&lt;/p&gt;

&lt;p&gt;For the sake of clarity, and since neither of these projects seems terribly concerned with nomenclature, I‚Äôm going to be calling this new breed of CRDTs &lt;strong&gt;operational replicated data types&lt;/strong&gt;‚Äîpartly to avoid confusion with the exiting term ‚Äúoperation-based CRDTs‚Äù (or CmRDTs), and partly because ‚Äúreplicated data type‚Äù (RDT) seems to be gaining popularity over ‚ÄúCRDT‚Äù and the term can be expanded to ‚ÄúORDT‚Äù without impinging on any existing terminology.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PORDT&lt;/em&gt; is missing some features that RON includes&lt;sup id=&quot;fnref:missing&quot;&gt;&lt;a href=&quot;#fn:missing&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;, so ORDTs have the most in common with the RON approach.&lt;/p&gt;

&lt;h2 id=&quot;what-is-an-ordt&quot;&gt;What Is an ORDT?&lt;/h2&gt;

&lt;p&gt;Much like Causal Trees, ORDTs are directly assembled out of atomic, immutable, uniquely-identified and timestamped ‚Äúoperations‚Äù that are arranged in a basic container structure. (For clarity, I‚Äôm going to be referring to this container as the &lt;strong&gt;structured log&lt;/strong&gt; of the ORDT.) Each operation represents an atomic action in the data type while simultaneously functioning as the unit of data resultant from that action. This crucial event‚Äìdata duality means that an ORDT can be understood as either a conventional data structure in which each unit of data is augmented with event metadata, or alternatively as an event log of atomic actions ordered to resemble its output data structure for ease of execution&lt;sup id=&quot;fnref:eventlog&quot;&gt;&lt;a href=&quot;#fn:eventlog&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;. (Refer back to the array explorations in the previous section.) Consequently, an ORDT doesn‚Äôt necessarily need to be evaluated to be useful: many queries can be run on the structured log as-is&lt;sup id=&quot;fnref:ops&quot;&gt;&lt;a href=&quot;#fn:ops&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;. Whether syncing a single operation, applying a longer patch, or performing a full-on merge, every change to an ORDT is integrated through the same kind of low-level ‚Äúrebase‚Äù inside the container. This means that the distinction between op-based (CmRDT) and state-based (CvRDT) usage becomes effectively moot.&lt;/p&gt;

&lt;p&gt;The decomposition of data structures into tagged units of atomic change feels like one of those rare foundational abstractions that could clarify an entire field of study. Indeed, many existing CRDTs (such as RGA) have made passes at this concept without fully embracing it, incorporating authorship and logical timestamps into proto-operational structures that often get consumed during merge. With the ORDT approach, those same CRDTs can be expressed in a general way, unifying their interface and performance characteristics across the board while providing them with a wide variety of standard, useful features. RON has working implementations for LWW (last-writer-wins) registers, Causal Trees (under the RGA moniker), and basic sets, while &lt;em&gt;PORDT&lt;/em&gt; additionally defines MVRegisters, AWSets, and RWSets.&lt;/p&gt;

&lt;figure class=&quot;mostly-full-width&quot;&gt;
&lt;img src=&quot;/images/blog/causal-trees/rdts.svg&quot; /&gt;
&lt;figcaption&gt;Some example ORDTs. Note that each ORDT has its own operation order: counter operations are arranged strictly by their Lamport timestamp (though the order really doesn't matter), LWW operations are sorted first by key and then by Lamport timestamp, and sequence operations are sorted as described in the CT section.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;So what are some advantages to this operational approach? For one, satisfying the CRDT invariants becomes trivial: idempotency and commutativity are inherent in the fact that each ORDT is simply an ordered collection of unique operations, so there‚Äôs never any question of what to do when integrating remote changes. Even gapless causal order, which is critical for convergence in most CmRDTs, becomes only a minor concern here: events missing their causal ancestors could simply be ignored on evaluation of the structured log. (RON treats any causally-separated segments of an ORDT as ‚Äúpatches‚Äù that can be applied to the main ORDT as soon as their causal ancestors arrive.) Actions that require reverting the data structure to a particular timestamp‚Äîgarbage collection, past revision viewing, delta updates‚Äîbecome as simple as taking a version vector and dividing the operations into two sets. Since each operation has a globally-unique identifier, it‚Äôs possible to make deep permalinks from one ORDT into another; for example, by defining the cursor in a text editor as a reference to the atom representing its leftmost letter. (&lt;a href=&quot;https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTFramework/StringRepresentation/CRDTTextEditing.swift&quot;&gt;This is what my iOS demo does&lt;/a&gt;.) On account of their uniformity, and since there‚Äôs no history to replay, rehydrating the data structures from bits into objects becomes a basic &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) or &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;) read. (This is especially great for implementing our zippy ‚Äúgolden file‚Äù!)&lt;/p&gt;

&lt;p&gt;Defining data structures in terms of low-level operations might seem like a needlessly bloated approach; for wouldn‚Äôt it make more sense to keep the data structure pure and to move the convergence and history stuff over to a separate data structure? But I‚Äôd argue that the operational approach is the only one that stays true to nature of the problem. One way or another, every action in a convergent data type needs to be uniquely defined, identified, and timestamped. If that information isn‚Äôt bundled together with its output, then the scheme will require complex coordination between the history parts and the data parts. Some new CRDTs (such as the one used in &lt;a href=&quot;http://google.github.io/xi-editor/docs/crdt-details.html&quot;&gt;xi&lt;/a&gt;) do indeed try to keep the data and history separate; but the result is that the history restoration code has to be painfully tailored to the given data type, that the time complexity of critical algorithms (such as past revision viewing and merge) approaches &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;) with the length of the history log, and that there‚Äôs no standard way to merge or to send operations between sites. Paradoxically, separating out the concerns makes the system far more specialized! Meanwhile, ORDTs can readily perform all these tasks with minimal code while maintaining blazing-fast &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;) performance. I‚Äôd go as far as to say that defining CRDTs operationally is the &lt;em&gt;only&lt;/em&gt; way to make them performant and comprehensible across the board, even though the marriage of state and history might initially seem a bit ugly.&lt;/p&gt;

&lt;h2 id=&quot;the-ordt-pipeline&quot;&gt;The ORDT Pipeline&lt;/h2&gt;

&lt;p&gt;ORDT operations are immutable and globally unique. Each operation is bestowed, at minimum, with an ID in the form of a site UUID and a Lamport timestamp, a location identifier (which is generally the ID of another operation), and a value. An operation is meant to represent an atomic unit of change in the data structure, local in effect and directly dependent on one other operation at most. (In practice, operations can be designed to do pretty much anything with the data, but non-atomic or multi-causal operations will prevent the structured log from being linearly interpretable and may severely affect performance, simplicity, and intent. Think: ‚Äú&lt;a href=&quot;https://en.wikipedia.org/wiki/Bubble_(computing)&quot;&gt;bubbles&lt;/a&gt;‚Äù.) Just as in a CT, the location ID of an operation tends to point to its direct causal prerequisite: the last operation whose output is necessary for the current operation to function. If no such dependency exists, then it could simply point to the newest operation available in the current ORDT, or even to an arbitrary value for sorting purposes. Although each operation only contains a single Lamport timestamp, the location pointer gives us almost as much additional causality and context information as a regular version vector. Thus, it becomes possible to identify and separate concurrent operations without the untenable &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;ns&lt;/em&gt;) space complexity of a version vector per operation, as many distributed systems are required to do.&lt;/p&gt;

&lt;p&gt;New operations (local and remote) are incorporated into the ORDT through a series of functions. The pipeline begins with an incoming stream of operations, packaged depending on the use case. For an ORDT in CvRDT (state) mode, this would be a state snapshot in the form of another structured log; for CmRDT (operation) mode, any set of causally-linked operations, and often just a single one.&lt;/p&gt;

&lt;figure class=&quot;mostly-full-width&quot;&gt;
&lt;img src=&quot;/images/blog/causal-trees/pipeline.svg&quot; /&gt;
&lt;figcaption&gt;The operation pipeline. Both the reducer/effect and mapper/eval steps use pure functions tailored to the given ORDT. Location information has been stripped from each operation to simplify the diagram.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;New operations, together with the current structured log, are fed into a &lt;strong&gt;reducer&lt;/strong&gt; (RON) or &lt;strong&gt;effect&lt;/strong&gt; (&lt;em&gt;PORDT&lt;/em&gt;) step. This takes the form of a function that inserts the operations into their proper spot in the structured log, then removes any redundant operations as needed.&lt;/p&gt;

&lt;p&gt;What are these ‚Äúredundant operations‚Äù, you might ask? Isn‚Äôt history meant to be immutable? Generally, yes‚Äîbut in some ORDTs, new operations might definitively supersede previous operations and make them redundant for convergence. Take a LWW register, for example. In this very basic ORDT, the value of an operation with the highest timestamp+UUID supplants any previous operation‚Äôs value. Since merge only needs to compare a new operation with the previous highest operation, it stands to reason there‚Äôs simply no point in keeping the older operations around. (&lt;em&gt;PORDT&lt;/em&gt; defines these stale operations in terms of &lt;strong&gt;redundancy relations&lt;/strong&gt;, which are unique to each ORDT and are applied as part of the effect step.)&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/cleanup.svg&quot; style=&quot;width:78rem&quot; /&gt;
&lt;figcaption&gt;Cleaning up redundant operations in a simple multi-LWW (dictionary) ORDT. Both produce the same result and still contain enough information to correctly integrate any remote operations.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Here, I have to diverge from my sources. In my opinion, the cleanup portion of the reducer/effect step ought to be separated out and performed separately (if at all). Even though some ORDT operations might be made redundant with new operations, retaining every operation in full allows us to know the exact state of our ORDT at any point in its history. Without this assurance, relatively ‚Äúfree‚Äù features such as garbage collection and past revision viewing become much harder (if not impossible) to implement in a general way. I therefore posit that at this point in the pipeline, there ought to be a simpler &lt;strong&gt;arranger&lt;/strong&gt; step. This function would perform the same sort of merge and integration as the reducer/effect functions, but it wouldn‚Äôt actually remove or modify any of the operations. Instead of happening implicitly, the cleanup step would be explicitly invoked as part of the garbage collection routine, when space actually needs to be reclaimed. The details of this procedure are described in the next section.&lt;/p&gt;

&lt;p&gt;(I should note that RON and &lt;em&gt;PORDT&lt;/em&gt; additionally clean up operations in the reducer/effect step by stripping some of their metadata when it‚Äôs no longer required. For instance, in RON‚Äôs implementation of a sequence ORDT, the location ID of an operation is dropped once that operation is properly positioned in the structured log. In addition to the previous arguments pertaining to history, I‚Äôm generally against this kind of trimming because it ruins the functional purity of the system. The operations become ‚Äúglued‚Äù to their spot in the structured log: you can no longer treat the log and operations as separate and independent elements. In any case, this kind of cleanup also belongs in the garbage collection routine.)&lt;/p&gt;

&lt;p class=&quot;nojustify&quot;&gt;The final bit of the pipeline is the &lt;strong&gt;mapper&lt;/strong&gt; (RON) or &lt;strong&gt;eval&lt;/strong&gt; (&lt;em&gt;PORDT&lt;/em&gt;) step. This is the code that finally makes sense of the structured log. It can either be a function that produces an output data structure by executing the operations in order, or alternatively, a collection of functions that queries the structured log without executing anything. In the case of string ORDTs, the mapper might simply emit a native string object, or it might take the form of an interface that lets you call methods like &lt;code class=&quot;highlighter-rouge&quot;&gt;length&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;characterAtIndex:&lt;/code&gt;, or even &lt;code class=&quot;highlighter-rouge&quot;&gt;replaceCharactersInRange:withString:&lt;/code&gt; directly on the structured log. It‚Äôs absolutely critical that the output of each function in this step is equivalent to calling that same function on the data structure resultant from the linearization and execution of every operation in the ORDT. (So evaluating &lt;code class=&quot;highlighter-rouge&quot;&gt;length&lt;/code&gt; directly on the operations should be the same as executing all the operations in order, then calling &lt;code class=&quot;highlighter-rouge&quot;&gt;length&lt;/code&gt; on the output string.)&lt;/p&gt;

&lt;p&gt;The arranger/reducer/effect and the mapper/eval functions together form the two halves of the ORDT: one dealing with the memory layout of data, the other with its user-facing interpretation. The data half, as manifest in the structured log, needs to be ordered such that queries from the interface half remain performant. If the structured log for an ORDT ends up kind of looking like the abstract data type it‚Äôs meant to represent (e.g. a CT‚Äôs weave ‚áÑ array), then the design is probably on the right track. Effectively, the operations should be able to stand for the data.&lt;/p&gt;

&lt;p&gt;So how is the structured log stored, anyway? &lt;em&gt;PORDT&lt;/em&gt; does not concern itself with the order of operations: all of them are simply stuck in a uniform set. Unfortunately, this is highly inefficient for more complex data types such as sequences, since the set has to be sorted into a CT-like order before each query. RON‚Äôs insight is that the order of operations really matters for mapper performance, and so the operations are arranged in a kind of compressed array called a &lt;strong&gt;frame&lt;/strong&gt;. In both cases, operational storage is generic without any type-specific code. Everything custom about a particular data type is handled in the reducer/effect and mapper/eval functions.&lt;/p&gt;

&lt;p&gt;But this is another spot where I have to disagree with the researchers. Rather than treating the structured log and all its associated functions as independent entities, I prefer to conceptualize the whole thing as a persistent, type-tailored object, distributing operations among various internal data structures and exposing merge and data queries through an OO interface. In other words, the structured log, arranger, and parts of the mapper would combine to form one giant object.&lt;/p&gt;

&lt;figure class=&quot;mostly-full-width&quot;&gt;
&lt;img src=&quot;/images/blog/causal-trees/object-log.svg&quot; /&gt;
&lt;figcaption&gt;An example object-based log for a string ORDT. The first cache is for ranges of visible characters and the second is for &quot;yarns&quot;. With these two caches, we can use the operations as a direct backing store for the native string interface.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The reason is that ORDTs are meant to fill in for ordinary data structures, and sticking operations into a homogeneous container might lead to poor performance depending on the use case. For instance, many text editors now prefer to use the &lt;a href=&quot;https://en.wikipedia.org/wiki/Rope_(data_structure)&quot;&gt;rope data type&lt;/a&gt; instead of simple arrays. With a RON-style frame, this transition would be impossible: you‚Äôre stuck with the container you‚Äôre given. But with an object-based ORDT, you could almost trivially switch out the internal data structure for a rope and be on your merry way. And this is just the beginning: more complex ORDTs might require numerous associated caches for optimal performance, and the OO approach would ensure that these secondary structures stayed together and remained consistent on merge.&lt;/p&gt;

&lt;p&gt;That‚Äôs all there is to the ORDT approach! Operations are piped in from local and remote sources, are arranged in some sort of container, and then get executed or queried directly to produce the output data. At a high level, ORDTs are delightfully simple to work with and reason about.&lt;/p&gt;

&lt;h2 id=&quot;garbage-collection&quot;&gt;Garbage Collection&lt;/h2&gt;

&lt;p&gt;(This section is a bit speculative since I haven‚Äôt implemented any of it yet, but I believe the logic is sound‚Äîif a bit messy.)&lt;/p&gt;

&lt;p&gt;Garbage collection has been a sticking point in CRDT research, and I believe that ORDTs offer an excellent foundation for exploring this problem. A garbage-collected ORDT can be thought of as a data structure in two parts: the ‚Äúlive‚Äù part and the compacted part. Operations in the live part are completely unadulterated, while operations in the compacted part might be modified, removed, compressed, or otherwise altered to reclaim storage. As we saw earlier, a CT can be split into two segments by way of a version vector, or ‚Äúweft‚Äù. The same applies to any ORDT, and this allows us to store a &lt;strong&gt;baseline&lt;/strong&gt; weft alongside the main data structure to serve as the dividing line between live and compacted operations. Assuming causal order&lt;sup id=&quot;fnref:causalorder&quot;&gt;&lt;a href=&quot;#fn:causalorder&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;, any site that receives a new baseline would be obliged to compact all operations falling under that weft in its copy of the ORDT, as well as to drop or orphan any operations that are not included in the weft, but have a causal connection to any removed operations. (These are usually operations that haven‚Äôt been synced in time.)&lt;/p&gt;

&lt;p&gt;In effect, the baseline can be thought of as just another operation in the ORDT: one that requires all included operations to pass through that ORDT‚Äôs particular garbage collection routine. The trick is making this operation commutative.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/baseline.svg&quot; style=&quot;width:53rem&quot; /&gt;
&lt;figcaption&gt;The dotted line represents baseline 1:6‚Äì2:7‚Äì3:7. In practice, S1@T2 may not necessarily be removed in order to preserve S1@T3's ancestral ordering information, but this depends on the compaction scheme.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In ORDTs, garbage collection isn‚Äôt just a matter of removing ‚Äútombstone‚Äù operations or their equivalent. It‚Äôs also an opportunity to drop redundant operations, coalesce operations of the same kind, reduce the amount of excess metadata, and perform other kinds of cleanup that just wouldn‚Äôt be possible in a strictly immutable and operational data structure. Although baseline selection has to be done very carefully to prevent remote sites from losing data, the compaction process itself is quite mechanical once the baseline is known. We can therefore work on these two problems in isolation.&lt;/p&gt;

&lt;p&gt;Given a baseline, there are two kinds of compaction that can be done. First, there‚Äôs ‚Äúlossless‚Äù compaction, which involves dropping operations that no longer do anything and aren‚Äôt required for future convergence. (&lt;em&gt;PORDT&lt;/em&gt; calls this property of operations &lt;strong&gt;causal redundancy&lt;/strong&gt; and removes any such operations in the effect step. Remember, we split this functionality off from our arranger.) In essence, lossless compaction is strictly a local issue, since the only thing it affects is the ability for an ORDT to rewind itself and access past revisions. Nothing else about the behavior of the ORDT has to change. You could even implement this form of compaction without a baseline at all! However, only simpler ORDTs such as LWW registers tend to have operations with this property.&lt;/p&gt;

&lt;p&gt;The second kind of compaction actually requires making changes to existing operations. The behavior of this step will vary from ORDT to ORDT. A counter ORDT could combine multiple add and subtract operations into a single union operation. A sequence ORDT could remove its deleted operations, then modify any descendants of those operations to ensure that they remain correctly sorted even without their parents. Since modifying existing operations can easily cause corruption, it‚Äôs essential to follow two basic rules when figuring out how to apply this kind of ‚Äúlossy‚Äù compaction to an ORDT. First, the compacted portion of the ORDT must be able to produce the same output as its constituent operations. And second, the compacted portion of the ORDT must retain enough metadata to allow future operations to reference it on an atomic level and order themselves correctly. From the outside, a compacted ORDT must continue to behave exactly the same as a non-compacted ORDT.&lt;/p&gt;

&lt;p&gt;There are many possible ways to implement compaction. One approach is to freeze all the operations included in the baseline into an ordered data structure and separate it out from the rest of the structured log. Depending on the ORDT in question, it might be possible to strip some of the operation metadata or even store those compacted operations &lt;a href=&quot;http://haslab.uminho.pt/cbm/files/pmldc-2016-redis-crdts.pdf&quot;&gt;as the output data type itself&lt;/a&gt;. (This is the approach used in &lt;em&gt;PORDT&lt;/em&gt;.) However, there may be performance penalties and headaches from having the data split into two parts like that, especially if spatial locality and random access are required for efficient mapper/eval performance. Merging two garbage-collected ORDTs might also become a problem if neither baseline is a strict superset of the other.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/compact.svg&quot; style=&quot;width:71.5rem&quot; /&gt;
&lt;figcaption&gt;An example of the two-part compaction scheme with baseline 1:6‚Äì2:7‚Äì3:7. The left part is stored as a native string with a bit of metadata. In a basic CT, keeping around location info for the compacted letters is not necessary, since new operations referencing them will always sort ahead of any hypothetical pre-baseline siblings.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;An alternative is to keep the compacted operations mixed in with the live operations, but exceptional care must be taken to ensure that every operation remains in its proper spot following compaction. For example, in a CT, blindly removing a deleted operation that falls under a baseline would orphan any non-deleted child operations that it might have. Naively, one might think that these children could simply be modified to point at the deleted operation‚Äôs parent (i.e. their grandparent), but this would change their sort order with respect to the parent‚Äôs siblings. (In other words, even ‚Äútombstone‚Äù operations in a CT serve an important organizational role.) One solution would be to only allow the removal of operations without any children, making several passes over the baselined operations to ensure that all possible candidates are removed. The first pass would remove just the delete operations (since they‚Äôre childless) and add a delete flag to their target operations. (So in our Swift implementation, the enum type of the &lt;code class=&quot;highlighter-rouge&quot;&gt;StringAtom&lt;/code&gt; might change from &lt;code class=&quot;highlighter-rouge&quot;&gt;insert&lt;/code&gt; to something like &lt;code class=&quot;highlighter-rouge&quot;&gt;deleted-insert&lt;/code&gt;.) The second pass, starting from the back of the deleted range, would remove any marked-as-deleted operations that have no additional children. And as an extra tweak, if a marked-as-deleted operation‚Äôs only child happened to be another marked-as-deleted operation, then the child operation could take the place of its parent, overwriting the parent‚Äôs contents with its own. Using this technique, most deletes under a baseline could be safely removed without changing the behavior or output of the CT.&lt;/p&gt;

&lt;p&gt;Baseline selection is where things get tricky. When picking a baseline, every operation possibly affected by the removal of an operation (such as the children of a deleted operation in a CT) must be included as well. Locally, this is easy to do; but the big risk is that if a removed operation has any unknown descendants on some remote site, then those operations will be orphaned if the baseline fails to include them. With a CT, we can mitigate this by first stipulating that no new operations may be &lt;em&gt;knowingly&lt;/em&gt; parented to deleted characters, and also that no delete operations may have any children or be deleted themselves. (This is the expected behavior anyway since a user can‚Äôt append a character to a deleted character through a text editor interface, but it should be codified programmatically.) With this precondition in place, we know that once a site has received a delete operation, it will never produce any new children for that deleted character. We therefore know that once &lt;em&gt;every&lt;/em&gt; site in the network has seen a particular delete operation and its causal ancestors‚Äîwhen that delete operation is &lt;em&gt;stable&lt;/em&gt;‚Äîthat no new operations affected by that delete will ever appear in the future, and that a baseline could in theory be constructed that avoids orphaning any operations across the network. (&lt;em&gt;PORDT&lt;/em&gt; uses similar logic for its &lt;strong&gt;stable&lt;/strong&gt; step, which comes after the effect step and cleans up any stable operations provably delivered to all other sites.)&lt;/p&gt;

&lt;p&gt;But here‚Äôs where we hit a snag. Generally speaking, CRDT research is tailored to the needs of distributed systems and frequently makes assumptions about coordination between devices. Perhaps the amount of sites is assumed to be known; perhaps there‚Äôs an expected way to determine the causal stability of an operation; or perhaps there are implied mechanisms for querying the state of the network. But in my own exploration of CRDTs, no such assumptions have been made. The objects described in this article are system-agnostic mathematical structures, and it makes no difference to any of the algorithms how data gets from one site to another. Even inter-device communication isn‚Äôt a hard requirement! Someone could leave a copy of their ORDT on an office thumb drive, return a year later, and successfully merge all the new changes back into their copy. Whenever some additional bit of synchronization is mandated or assumed, the possibility space of this design shrinks and generality is lost. The messiness of time and state are injected into an otherwise perfectly functional architecture.&lt;/p&gt;

&lt;p&gt;Unfortunately, baseline selection might be the one component where a bit of coordination is actually required.&lt;/p&gt;

&lt;p&gt;In an &lt;a href=&quot;https://en.wikipedia.org/wiki/CAP_theorem&quot;&gt;available and partition-tolerant system&lt;/a&gt; system, is it possible to devise a selection scheme that always garbage collects without orphaning any operations? Logically speaking, no: if some site copies the ORDT from storage and then works on it in isolation, there‚Äôs no way the other sites will be able to take it into account when picking their baseline. However, if we require our system to only permit forks via request to an existing site, and also that all forked sites ACKs back to their origin site on successful initialization, then we would have enough constraints to make non-orphaning selection work. Each site could hold a map of every site‚Äôs ID to its last known version vector. When a fork happens (and is acknowledged), the origin site would add the new site ID to its own map and seed it with its timestamp. This map would be sent with every operation or state snapshot between sites and merge into the receiver‚Äôs map alongside the ORDT. (In essence, the structure would act as a distributed overview of the network.) Now, any site with enough information about the others would be free to independently set a baseline that a) is causally consistent, b) is consistent by the rules of the ORDT, c) includes only those removable operations that have been received by every site in the network, and d) also includes every operation affected by the removal of those operations. With these preconditions in place, you can prove that even concurrent updates of the baseline across different sites will converge.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/garbage-collection.gif&quot; /&gt;
&lt;figcaption&gt;An example of network knowledge propagation. Site 2 is forked from 1, Site 3 from 2, and Site 4 from 3‚Äîall with state AB. At the start, Site 1's C has been received by Site 2, but not Site 3. Maps are updated on receipt, not on send. In the end, Site 1 knows that every site has at least moved past ABE (or weft 1:2‚Äì2:X‚Äì3:X‚Äì4:9), making it a candidate for the new baseline.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;But questions still remain. For instance: what do we do if a site simply stops editing and never returns to the network? It would at that point be impossible to set the baseline anywhere in the network past the last seen version vector from that site. Now some sort of timeout scheme has to be introduced, and I‚Äôm not sure this is possible to do in a truly partitioned system. There‚Äôs just no way to tell if a site has left forever or if it‚Äôs simply editing away in its own parallel partition. So we‚Äôd have to add some sort of mandated communication between sites, or perhaps some central authority to validate connectivity, and now the system is constrained even further. In addition, as an &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;s&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;) space complexity data structure, the site-to-version-vector map could get unwieldy depending on the number of peers.&lt;/p&gt;

&lt;p&gt;Alternatively, we might relax rules c) and d) and allow the baseline to potentially orphan remote operations. With this scheme, we would retain a sequence of baselines associated with our ORDT. Any site would be free to pick a new baseline that was explicitly higher than the previous highest baseline, taking care to pick one that had the highest chance of preserving operations on other sites&lt;sup id=&quot;fnref:preservation&quot;&gt;&lt;a href=&quot;#fn:preservation&quot; class=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;. Then, any site receiving new baselines in the sequence would be required to apply them in order&lt;sup id=&quot;fnref:baselines&quot;&gt;&lt;a href=&quot;#fn:baselines&quot; class=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;. Upon receiving and executing a baseline, a site that had operations causally dependent on any removed operations but not included in the baseline would be obliged to either drop them or to add them to some sort of secondary ‚Äúorphanage‚Äù ORDT.&lt;/p&gt;

&lt;p&gt;But even here we run into problems with coordination. If this scheme worked as written, we would be a-OK, so long as sites were triggering garbage collection relatively infrequently and only during quiescent moments (as determined to the best of a site‚Äôs ability). But we have a bit of an issue when it comes to picking monotonically higher baselines. What happens if two sites concurrently pick new baselines that orphan each others‚Äô operations?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/causal-trees/garbage.svg&quot; style=&quot;width:26rem&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Assume that at this point in time, Site 2 and Site 3 don‚Äôt know about each other and haven‚Äôt received each other‚Äôs operations yet. The system starts with a blank garbage collection baseline. Site 2 decides to garbage collect with baseline 1:3‚Äì2:6, leaving behind operations ‚ÄúACD‚Äù. Site 3 garbage collects with baseline 1:3‚Äì3:7, leaving operations ‚ÄúABE‚Äù. Meanwhile, Site 1‚Äîwhich has received both Site 2 and 3‚Äôs changes‚Äîdecides to garbage collect with baseline 1:3‚Äì2:6‚Äì3:7, leaving operations ‚ÄúAED‚Äù. So what do we do when Site 2 and 3 exchange messages? How do we merge ‚ÄúACD‚Äù and ‚ÄúABE‚Äù to result in the correct answer of ‚ÄúAED‚Äù? In fact, too much information has been lost: 2 doesn‚Äôt know to delete C and 3 doesn‚Äôt know to delete B. We‚Äôre kind of stuck.&lt;/p&gt;

&lt;p&gt;(I have to stress that baseline operations &lt;em&gt;must&lt;/em&gt; behave like ordinary ORDT operations, in the sense that they have to converge to the same result regardless of their order of arrival. If they don‚Äôt, our CRDT invariants break and eventual consistency falls out of reach!)&lt;/p&gt;

&lt;p&gt;In this toy example, it may still be possible to converge by drawing inferences about the missing operations from the baseline version vector of each site. But that trick won‚Äôt work with more devious examples featuring multiple sites deleting each others‚Äô operations and deletions spanning multiple adjacent operations. &lt;em&gt;Maybe&lt;/em&gt; there exists some clever scheme which can bring us back to the correct state with any combination of partial compactions, but my hunch is that this situation is provably impossible to resolve in a local way without accruing ancestry metadata‚Äîat which point you‚Äôre left with the same space complexity as the non-compacted case anyway.&lt;/p&gt;

&lt;p&gt;Therefore‚Äîjust as with the non-orphaning baseline strategy‚Äîit seems that the only way to make this work is to add a bit of coordination. This might take the form of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Designating one or more sites superusers and making them decide on the baselines for all other sites.&lt;/li&gt;
  &lt;li&gt;Putting the baseline to vote among a majority/plurality of connected sites.&lt;/li&gt;
  &lt;li&gt;Relying on a server to synchronously store the current baseline. (This might be the best strategy for a system built on top of something like CloudKit. The syncing mechanism is centralized and synchronous anyway, so might as well force sites to pull the baseline on sync.)&lt;/li&gt;
  &lt;li&gt;Allowing sites that end up losing in a concurrent baseline adjustment to pull the full ORDT from somewhere, or to get the necessary parts from their peers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In summary: while baseline operations are not commutative for every possible value, they can be made commutative with just a sprinkle of coordination. Either you ensure that a baseline &lt;em&gt;does not leave orphaned operations&lt;/em&gt; (which requires some degree of knowledge about every site on the network), or you ensure that &lt;em&gt;each new baseline is monotonically higher than the last&lt;/em&gt; (which requires a common point of synchronization). Fortunately, the messy business of coordination is localized to the problem of picking the data for a single operation, not to the functioning of the operation itself or any other part of the ORDT. There‚Äôs nothing special or unique about the baseline operation with respect to the rules of CRDTs, and it can be treated, transferred, and processed just like any other operation. If the baseline fails to get updated due to network conditions, nothing bad actually happens and sites are still free to work on their documents. The scheme degrades very gracefully!&lt;/p&gt;

&lt;p&gt;Finally, remember that in many cases, ‚Äúdon‚Äôt worry about garbage collection‚Äù is also a viable option. Most collaborative documents aren‚Äôt meant to be edited in perpetuity, and assuming good faith on the part of all collaborators, it would be surprising if the amount of deleted content in a typical document ended up being more than 2 or 3 times its visible length.&lt;/p&gt;

&lt;h2 id=&quot;ordt-design--implementation&quot;&gt;ORDT Design &amp;amp; Implementation&lt;/h2&gt;

&lt;p&gt;I‚Äôve been thinking about the best way to integrate ORDTs into production software. &lt;a href=&quot;https://github.com/gritzko/ron&quot;&gt;RON&lt;/a&gt;, though incomplete, offers a blueprint for a general, configurable, and highly functional architecture. However, I think there‚Äôs also a lot to be said for object-based ORDTs, especially with respect to interactive software where low latency is a core requirement.&lt;/p&gt;

&lt;p&gt;To reiterate, RON stores the operations for any ORDT in a standard, immutable ‚Äúframe‚Äù data structure, and pushes everything unique about the data type into the reducer and mapper functions. The system is data-oriented and self-configuring. Each batch of operations contains location and data type information which lets them automatically get routed to their correct frames. Reducers are actually multi-mode functions that can consistently merge individual operations, partial frames (patches), and full frames (state snapshots) in &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;) time via heap sort, allowing RON to function equally well in CmRDT or CvRDT mode and even mix modes on the fly. Operations are encoded using a regular language (or an alternate binary coding) that compresses very well inside each frame. The end result is a teeming river of operations that can automatically form itself into networks of larger, connected, convergent structures.&lt;/p&gt;

&lt;p&gt;In the object-based approach, operations, arranger/mapper functions, and any relevant caches are herded into persistent, mutable objects. Certainly, there are many hassles compared to the purely-functional RON architecture: everything is tightly-coupled, ownership and object management become critical factors, a lot more boilerplate is involved. In exchange, it becomes possible to target performance chokepoints with precision. A generic RON frame with &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) reads and O(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;) writes might be good in the general case, but there are plenty of problems where &lt;em&gt;O&lt;/em&gt;(1) or &lt;em&gt;O&lt;/em&gt;(log&lt;em&gt;n&lt;/em&gt;) performance for certain functions is a hard requirement. Objects have the freedom to distribute their operations among various data structures, maintain caches of operations, and otherwise structure themselves for maximally efficient queries. The conception of ORDTs as independent structures allows them to be used in a variety of non-network contexts; for example, as a way of dealing with local file merge or synchronizing data across threads. (Atom Xray and xi &lt;a href=&quot;https://google.github.io/xi-editor/docs/crdt.html&quot;&gt;already use CRDTs in this manner&lt;/a&gt;, and it seems that lock-free data structures could similarly benefit from this approach.) And unlike in RON, there‚Äôs no mapping step from frame to user data: the object can be used as a native data type without ever going stale or having to convert itself to a different format. (Think back to the &lt;code class=&quot;highlighter-rouge&quot;&gt;NSMutableString&lt;/code&gt; wrapper around the CT: you can use it just like any old system string.)&lt;/p&gt;

&lt;p&gt;Consider a hypothetical replicated bitmap as a thought experiment. Perhaps in the same vein as Reddit‚Äôs &lt;a href=&quot;http://i.imgur.com/ajWiAYi.png&quot;&gt;/r/place&lt;/a&gt;, you‚Äôre working on a giant image with a bunch of different people (some online, some offline) and you want the whole thing to sensibly merge when the different parts come together. As a starting point, say the bitmap is conceived as a grid of LWW registers&lt;sup id=&quot;fnref:lww&quot;&gt;&lt;a href=&quot;#fn:lww&quot; class=&quot;footnote&quot;&gt;15&lt;/a&gt;&lt;/sup&gt;, and that each operation contains a single pixel‚Äôs coordinates and its RGBA color as the value. Let‚Äôs also say that the image is 5000√ó5000 pixels and that each set-pixel operation couldn‚Äôt be made smaller than 16 bytes. This means that once the entire canvas fills up, you‚Äôll be using about 400MB of uncompressed memory without even considering past history operations. Given that throughput for a single site could be in the hundreds of pixels per second, it‚Äôs crucial that each set-pixel operation execute locally in &lt;em&gt;O&lt;/em&gt;(log&lt;em&gt;n&lt;/em&gt;) time at most. It‚Äôs also vital that the garbage collector be able to trim the ORDT very often and very quickly, since even a few layers of history would eat up all your RAM. (Technically, garbage collection isn‚Äôt even needed in a LWW context‚Äîsee &lt;em&gt;causal redundancy&lt;/em&gt; above‚Äîbut maybe it‚Äôs desirable for the app to retain the full bitmap history until the memory situation is truly dire.) And just like a real bitmap, perhaps it should even be possible to tile this ORDT and pull different chunks from storage as you‚Äôre working on them.&lt;/p&gt;

&lt;p&gt;My feeling is that RON‚Äôs general approach would falter here. The pipeline simply couldn‚Äôt be tuned to fix these performance hot spots, and millions of pixel operations would grind it to a halt. With the object-based approach, you could store store the bitmap as a specialized k-d tree of buffers. The pixel values would be the operations themselves and each buffer would represent a particular area of pixels, subdivided when needed to store each pixel‚Äôs past operations. Since the buffers would be stored in contiguous chunks of memory, subdivision and rebalancing would be very efficient. Garbage collection could be as simple as un-subdividing any buffer with too many subdivisions. Assuming that the RGBA value for each operation was formatted correctly and that a stride could be passed along to the graphics framework, nodes could be blitted as-is into another buffer, making it trivial to only update the dirty parts of the rendered image. In short, it seems that performance could end up being very close to that of an &lt;em&gt;actual&lt;/em&gt; bitmap. It wouldn‚Äôt even surprise me if /r/place itself‚Äîwith its 16 million changes and 1 million unique sites‚Äîcould be reproduced with this kind of object!&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/bitmap.svg&quot; style=&quot;width:60rem&quot; /&gt;
&lt;figcaption&gt;A mockup of what an object-based bitmap ORDT might look like under the hood. Each colored square is a pixel operation. Grid coordinates with subdivisions represent pixels with a change history. Each section of the grid is stored in its own contiguous block of memory.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Finally, a few nascent thoughts on designing new ORDTs, though I‚Äôve admittedly only gone through this process for the basic bitmap shown above. The operational CRDT approach is almost like a ‚Äúreplicated data type construction kit‚Äù. Since ORDTs are merely collections of unique, ordered operations, commutativity and idempotency come standard with any design, and most of the work goes into figuring out how to atomize the data structure, define causal relationships, arrange operations inside the structured log, and optimize performance for critical methods. In other words: perfect engineering work, and not something that requires a PhD to manage!&lt;/p&gt;

&lt;p&gt;Here are some basic rules I‚Äôve come up with for this process:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The operations &lt;em&gt;are&lt;/em&gt; the data. Define and organize your operations so that you can query the ORDT directly without having to actually execute the operations first. Start with the regular data structure and figure out the best way to divide it into atomic units while keeping the skeleton intact. Then, try to find a way to inline any additional operations you might need into that same structure. Always remember that you‚Äôre not dealing with data &lt;em&gt;or&lt;/em&gt; events, but both at the same time. Not every data type will be susceptible to atomization, but many will be.&lt;/li&gt;
  &lt;li&gt;As much as possible, avoid operations that have non-local effects, multiple causes, or may affect multiple future operations. (Good operation: &lt;code class=&quot;highlighter-rouge&quot;&gt;insert letter after letter&lt;/code&gt;. Bad operation: &lt;code class=&quot;highlighter-rouge&quot;&gt;reverse string&lt;/code&gt;.) Operations that behave more like events than data are an anti-pattern. There has to be a degree of symmetry between the operations and their effect on the data structure. Allow the location ID (or ‚Äúcause‚Äù) of your operations to guide the design and weave your data structure together.&lt;/li&gt;
  &lt;li&gt;Always keep in mind the essential functions: initialization, merge and operation integration, garbage collection, serialization and deserialization. Filtering by weft is worth considering, too. Nothing should be slower than &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;).&lt;/li&gt;
  &lt;li&gt;If garbage collection is to be used, ensure that only operations causally preceding and concurrent to any delete-type operation could possibly be affected by its compaction‚Äînone afterwards. In other words, once a site has received a command that‚Äôs intended to remove data, make sure that new commands can‚Äôt be generated that reference the deleted portion of the ORDT.&lt;/li&gt;
  &lt;li&gt;If using the object-based approach, ensure that each operation only exists in a single internal data structure at a time. Don‚Äôt rely on incidental state such as insertion order; keep your internal data structures organized, sorted, and balanced at all times. Avoid moving operations between internal data structures. Instead of thinking of your object as having state, treat it as an organizational framework for your immutable operations. Try to ensure that the object will look the same even if recreated from scratch using the same set of operations.&lt;/li&gt;
  &lt;li&gt;One exception: caches of operations might be needed for optimal performance in some scenarios. (For example, yarns in a CT.) If you have caches, make absolutely, 100% sure that they‚Äôre consistent following all mutating operations; that they‚Äôre never serialized; and that it‚Äôs always possible to efficiently recreate them on initialization and deserialization. Caches are one of the easiest ways to corrupt your data!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With all that said, the need to design a new ORDT should be relatively rare. Most document formats can (and should) be constructed through the composition of existing ORDTs. But it‚Äôs still a fun subject to think about, and it might come in handy when developing high-performance software!&lt;/p&gt;

&lt;h1 id=&quot;causal-trees-in-depth&quot;&gt;Causal Trees In Depth&lt;/h1&gt;

&lt;p&gt;But now, let‚Äôs get back to our roots. I‚Äôd like to argue that our original Causal Tree, though nominally intended for sequence use, is in fact one of the most fundamental and versatile expressions of the ORDT formula. With just a single Causal Tree, you can specify complex and extensible document formats without ever reaching for another ORDT!&lt;/p&gt;

&lt;p&gt;There are several reasons for this. First, the DAG structure of a CT has strong parallels to the git model, making it very intuitive to reason about. Rather than pointing to a historic revision of a file, each ‚Äúcommit‚Äù (or operation) stands for an atomic change in data, while the full timeline considered all at once represents the final output structure. (In essence, the weave could be simply viewed a rebase of the timeline.) Related operations naturally chain together and appear as contiguous ranges in the weave, while conflicts are reified as sibling branches that are easily discovered and interpreted in the mapper/eval step. Causality and authorship metadata can be used to produce a version of the document at a specific point in time, extract the delta from one revision to another, or even create a local copy with a particular author removed. Working changes could be maintained in memory as separate subtrees, then grafted onto the main tree when convenient. The same mental tools used to reason about git naturally transfer over to CTs, with the simplification that none of the commits actually interfere with each other&lt;sup id=&quot;fnref:git&quot;&gt;&lt;a href=&quot;#fn:git&quot; class=&quot;footnote&quot;&gt;16&lt;/a&gt;&lt;/sup&gt;. If the general concept behind ORDTs is that of event logs merged with data structures, then what could be a cleaner expression of this formula than a git timeline merged with a tree?&lt;/p&gt;

&lt;p&gt;Next, we know &lt;a href=&quot;http://www.staff.city.ac.uk/~ross/papers/FingerTree.html&quot;&gt;from other domains&lt;/a&gt; that trees can be used to simulate practically any existing data type, giving CTs the power to organize data in an almost arbitrary way. Trees are also recursive data structures, so a single tree could contain subtrees of sequences, dictionaries, and a variety of other data types. In this way, CTs are inherently structured and composable.&lt;/p&gt;

&lt;p&gt;Performance with CTs is just about as good as it gets. Since CTs are (generally) stored as homogeneous structs in contiguous memory, most operations are &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) or &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;) and massively benefit from spatial locality‚Äîeven to the point where complex copy-on-write or locking schemes can be eschewed in favor of straight, dumb copies when working with multiple threads. It‚Äôs hard to beat plain ol‚Äô range-of-memory when it comes to speed, especially when serialization and deserialization are such frequent operations.&lt;/p&gt;

&lt;p&gt;And finally, the causal relationships CTs are built upon serve as excellent guides for defining proper ORDT operations: data-like and local in effect. Since every operation in a CT needs a parent, it‚Äôs hard to inadvertently create event-like operations that affect data outside the local context and form ‚Äúbubbles‚Äù in the evaluation step. You‚Äôre forced to reframe the actions on your data model in terms of local arguments and outputs, and as you work out the requirements for your document format, the operations practically write themselves.&lt;/p&gt;

&lt;p&gt;Together, all these properties make CTs perfect for use as a sort of quick-and-dirty ‚Äúconvergent struct‚Äù. But we need to flesh out a few details first‚Ä¶&lt;/p&gt;

&lt;h2 id=&quot;implementation-details&quot;&gt;Implementation Details&lt;/h2&gt;

&lt;p&gt;Before even touching the CT code, it makes sense to define a general CvRDT protocol. Among other benefits, this would make CvRDTs composable by allowing container CvRDTs  to forward all relevant calls to their child CvRDTs.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;protocol&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CvRDT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Codable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Hashable&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// must obey CvRDT convergence properties&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;mutating&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;integrate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;inout&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;// for avoiding needless merging; should be efficient&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;superset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;inout&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Bool&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;// ensures that our invariants are correct, for debugging and sanity checking&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;validate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Bool&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;CvRDTs are especially vulnerable to bad input since there‚Äôs no guarantee of a central server to fix mistakes. In order to minimally safeguard against malicious and misbehaving peers, I‚Äôve added a validation method to this interface. In the CT case, the &lt;code class=&quot;highlighter-rouge&quot;&gt;validate&lt;/code&gt; method goes through the weave and checks as many preconditions as possible, including child ordering, atom type, and several others.&lt;/p&gt;

&lt;p&gt;Next: UUIDs. I‚Äôve been describing my site identifiers as 16-bit integers since it‚Äôs unlikely that any document would have more than 65,000 collaborators. (And frankly, in most cases 8 or even 4 bits would do.) However, this is not enough for any reasonable definition of a UUID. Without coordination, you‚Äôll need a minimum of 128 bits to generate a truly unique value, but storing two full 128-bit UUIDs in each atom‚Äîone for its own site and one for its cause‚Äîwould balloon it to 3√ó its original size!&lt;/p&gt;

&lt;p&gt;I‚Äôve solved this with the help of a secondary CRDT that is stored and transferred along with the CT: an ordered, insert-only array of known UUIDs called the &lt;strong&gt;site map&lt;/strong&gt;. The 16-bit site identifier corresponding to a UUID is simply its index in the array.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/site-map.svg&quot; style=&quot;width:68.5rem&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;When two CTs merge, their site maps merge as well. The downside is that our site identifiers are only unique locally, not globally: if a new UUID gets added at a remote site and is then inserted into our local site map, the sorted order of our local UUIDs might change. When this happens, I traverse the full CT and remap any outdated site identifiers to their new values. This is facilitated by the following interface:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;protocol&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IndexRemappable&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;mutating&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;remapIndices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SiteId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SiteId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Any CRDT that makes use of the site map needs to implement this protocol. Whenever a merge that would cause some of the site IDs to change is initiated, the &lt;code class=&quot;highlighter-rouge&quot;&gt;remapIndices&lt;/code&gt; method gets called on the CRDT before the merge is actually executed. We‚Äôre running &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) operations when receiving remote data anyway, so performance is not a huge factor. Nonetheless, I made one additional tweak to ensure that remapping only happens very rarely. Instead of storing just the UUID in the site map, I also store the wall clock time at which the UUID was added. In the site map, these tuples are sorted first by time, then by UUID. Assuming that modern connected devices tend to have relatively accurate clocks (but not relying on this fact for correctness), we can ensure that new sites almost always get appended to the end of the ordered array and thus avoid shifting any of the existing UUIDs out of their previous spots. The only exception is when multiple sites happen to be added concurrently or when the wall clock on a site is significantly off.&lt;/p&gt;

&lt;p&gt;(Compared to RON‚Äôs approach of using a &lt;a href=&quot;https://github.com/gritzko/ron#wire-format-base64&quot;&gt;regular language&lt;/a&gt; to compress operations, this one might seem a bit clunky. However, I‚Äôd argue that there are many possible advantages to storing operations as homogeneous structs, including random access, spatial locality and cacheability, and the ease of moving operations between internal data structures. In any case, the compression scheme for operations can be viewed as a mere implementation detail, not a core part of the design. By their nature, operations are eminently compressible and there are probably dozens of other techniques that can solve the same problem.)&lt;/p&gt;

&lt;p&gt;The skeleton for our CT interface ends up looking something like this:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;protocol&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeSiteUUIDT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Hashable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Comparable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Codable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;protocol&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeValueT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IndexRemappable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Codable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SiteIndex&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeSiteUUIDT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;CvRDT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSCopying&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// etc.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Weave&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeSiteUUIDT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeValueT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;CvRDT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IndexRemappable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSCopying&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; 
    &lt;span class=&quot;c1&quot;&gt;// etc.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTree&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeSiteUUIDT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeValueT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;CvRDT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IndexRemappable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSCopying&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;private(set)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;siteIndex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SiteIndex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;private(set)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;weave&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Weave&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;// etc., with CvRDT interface calls forwarded to the site index and weave&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;My CT exposes its array of operations to the outside world through an &lt;a href=&quot;https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTFramework/CRDTCausalTreesWeave.swift#L723&quot;&gt;array view&lt;/a&gt;. By passing a consistent weft into the accessor function, you can read a historic version of the CT through the same interface, substantially simplifying any wrappers that use the CT as their backing store and making past revision viewing very simple to implement. To accumulate a list of consistent wefts, all you need to do is store the current weft right before any remote changes are integrated.&lt;/p&gt;

&lt;p&gt;One last feature specific to CTs is the priority flag for atoms. If an atom has priority, that atom and all its descendants get sorted ahead of any sibling subtrees in the parent‚Äôs causal block, even if it has a lower Lamport timestamp. (Put another way, a priority flag is simply another variable to be used in the sorting comparator, i.e. priority+timestamp+UUID.) This property gives us a lot of structural control, ensuring that, for instance, delete atoms hug their target atoms and never find themselves lost in the weave if concurrent insert operations vie for the same spot. It does require some tricky special casing during weave mutation and merge, however.&lt;/p&gt;

&lt;p&gt;With the priority flag in tow, the value enum for our CT string atoms now looks something like this:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;protocol&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreePrioritizable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;priority&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Bool&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;enum&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StringValue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeValueT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreePrioritizable&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;null&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UInt16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delete&lt;/span&gt;
  
    &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;priority&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Bool&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;mutating&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;remapIndices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SiteId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SiteId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
  
    &lt;span class=&quot;c1&quot;&gt;// insert Codable boilerplate here&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;typealias&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;StringAtom&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Atom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;StringValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And that‚Äôs all we really need to start implementing custom data types!&lt;/p&gt;

&lt;h2 id=&quot;representing-non-string-objects&quot;&gt;Representing Non-String Objects&lt;/h2&gt;

&lt;p&gt;To implement a custom data type as a CT, you first have to ‚Äúatomize‚Äù it, or decompose it into a set of basic operations, then figure out how to link those operations such that a mostly linear traversal of the CT will produce your output data. (In other words, make the structure analogous to a one- or two-pass parsable format.)&lt;/p&gt;

&lt;p&gt;In the demo section, I presented a CT designed for B√©zier drawing. Here‚Äôs how I coded the value enum for each atom:&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;enum&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DrawDatum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreeValueT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;CausalTreePrioritizable&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// no-op for grouping other atoms&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;pos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSPoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pointSentinelStart&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pointSentinelEnd&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;trTranslate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NSPoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;AtomId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;attrColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;ColorTuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;attrRound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delete&lt;/span&gt;
  
    &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;priority&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Bool&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;switch&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;pointSentinelStart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;pointSentinelEnd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;trTranslate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;attrColor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;attrRound&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;delete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;mutating&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;remapIndices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SiteId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SiteId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;switch&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;trTranslate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;newSite&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;self&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;trTranslate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;AtomId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;newSite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  
    &lt;span class=&quot;c1&quot;&gt;// insert Codable boilerplate here&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;typealias&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;DrawAtom&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Atom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;DrawDatum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Swift is kind enough to compress this down to about 23 bytes: the maximum size of an associated value tuple (&lt;code class=&quot;highlighter-rouge&quot;&gt;trTranslate&lt;/code&gt;, which has a 16-byte &lt;code class=&quot;highlighter-rouge&quot;&gt;NSPoint&lt;/code&gt; and a 6 byte &lt;code class=&quot;highlighter-rouge&quot;&gt;AtomId&lt;/code&gt;) plus a byte for the case.&lt;/p&gt;

&lt;p&gt;Note that &lt;code class=&quot;highlighter-rouge&quot;&gt;trTranslate&lt;/code&gt; has an atom ID as an associated value. Since atom IDs are unique, you can reference them from other atoms without issue&lt;sup id=&quot;fnref:causalpast&quot;&gt;&lt;a href=&quot;#fn:causalpast&quot; class=&quot;footnote&quot;&gt;17&lt;/a&gt;&lt;/sup&gt;. It‚Äôs a great way to represent ranged operations: just pick an atom that represents the outer position of your range, add the ID to the operation‚Äôs value, and handle it in your mapping/evaluation code. (This should especially come in handy when dealing with text formatting in rich text editors.) The only caveat is that the atom has to update this value in its implementation of the &lt;code class=&quot;highlighter-rouge&quot;&gt;IndexRemappable&lt;/code&gt; protocol.&lt;/p&gt;

&lt;p&gt;Anyway, back to shapes. For the following sample document‚Ä¶&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/draw-shapes.svg&quot; style=&quot;width:40rem&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;‚Ä¶we might end up with a tree shaped like this.&lt;/p&gt;

&lt;figure&gt;
&lt;img src=&quot;/images/blog/causal-trees/draw-tree.svg&quot; /&gt;
&lt;figcaption&gt;The pink operations have the priority flag and sort ahead of their sibling subtrees. For completeness, I've added a few extra transformation and attribute operations that aren't directly visible in the user-facing data.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Just a few simple rules define the higher-level structures representing shapes, points, and properties in this tree. A &lt;code class=&quot;highlighter-rouge&quot;&gt;shape&lt;/code&gt; atom can only be parented to other &lt;code class=&quot;highlighter-rouge&quot;&gt;shape&lt;/code&gt; atoms or to the root starting atom. Each &lt;code class=&quot;highlighter-rouge&quot;&gt;shape&lt;/code&gt; has a null atom as its only child, acting as the root node for all property subtrees relevant to that shape. This atom can contain three child subtrees at most: a chain of transformations, a chain of attributes, and a chain of points. Transformation and attribute chains hug their parent in the weave via the priority flag while points go last. Any new transformations and attributes are parented to the last member of their corresponding chain. The value for a chain of operations (currently only &lt;code class=&quot;highlighter-rouge&quot;&gt;trTranslate&lt;/code&gt;) is cumulative, while the value for a chain of attributes (&lt;code class=&quot;highlighter-rouge&quot;&gt;attrColor&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;attrRound&lt;/code&gt;) is just the last atom in the chain. Point chains act more like traditional sequences. A point chain is seeded with a start and end sentinel to cleanly delineate it from its neighbors, and the traversal order corresponds to the order of the points in the output &lt;code class=&quot;highlighter-rouge&quot;&gt;NSBezierPath&lt;/code&gt;. Like shapes, points can have child transformation and attribute chains. Points can also have child delete atoms. (Shapes aren‚Äôt currently deletable: you can individually remove all the points anyway and I got lazy.)&lt;/p&gt;

&lt;p&gt;In essence, this particular CT consists of a bunch of superimposed ORDTs: sequences for shapes and points, LWW registers for attributes, and a kind of counter for transformations.&lt;/p&gt;

&lt;p&gt;Here is the weave we get from reading the tree in DFS order:&lt;/p&gt;

&lt;figure class=&quot;mostly-full-width&quot;&gt;
&lt;img src=&quot;/images/blog/causal-trees/draw-weave.svg&quot; /&gt;
&lt;figcaption&gt;Green brackets are shape blocks, blue brackets are point blocks, and red brackets are attribute blocks.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The rules for generating the output image from this weave are very simple. If you hit a shape atom, you‚Äôre in a shape block until you run into another shape atom or the end of the weave. The shape‚Äôs operation and attribute chains are traversed first on account of their priority flag, and the results are cached for use in the next step. An &lt;code class=&quot;highlighter-rouge&quot;&gt;NSBezierPath&lt;/code&gt; is created once you start reading points. Each point block has to read forward a bit to parse its operation and attribute chains (if any). If a delete atom is found, you can simply move on to the next point. Otherwise, the point‚Äôs position is determined by combining its origin and transform (if any) with the parent shape‚Äôs transform (if any). The point is added to the &lt;code class=&quot;highlighter-rouge&quot;&gt;NSBezierPath&lt;/code&gt; either as as a line or as a B√©zier curve if it has the rounded attribute. Finally, once the next shape block or the end of weave is reached, the path is drawn and stroked.&lt;/p&gt;

&lt;p&gt;When I first started reading up on CRDTs, it was unclear to me how conflict resolution was formalized. Every CRDT seemed to do something a bit different and it was rare to find an approach that the developer could tweak depending on their needs. In CTs, the answer is refreshingly simple: conflicts occur when an atom has more children than expected, and the presentation of this fact is delegated to a higher layer. Translation operations in the B√©zier CT are a good example. Let‚Äôs say three different sites concurrently move the same point in the same direction. By default, the CT would produce a weave with three consecutive translations. Applying them in order would be consistent, but it would also triple the magnitude of the translation and match none of the sites‚Äô intentions. Instead, we can detect when a translation atom has multiple children and then simply average out those values. This would cause the final translation to reasonably approximate each of the original values and hopefully leave all three sites satisfied. If some user still finds this merge offensive, they can manually adjust the translation and implicitly ‚Äúcommit‚Äù the change with their new operation.&lt;/p&gt;

&lt;p&gt;This is only one possible approach, however, and the developer is free to act at their leisure when a conflict is detected: present a selection to the user, pick the value with the lowest timestamp, use some special function for combining the values. The underlying CT will &lt;em&gt;always&lt;/em&gt; remain consistent under concurrency, and conflict resolution is merely a matter of interpretation.&lt;/p&gt;

&lt;p&gt;Finally, my implementation includes a &lt;a href=&quot;https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTPlayground/TestingExtras/Data%20Interfaces/CausalTreeBezierWrapper.swift&quot;&gt;new, stateless layer&lt;/a&gt; on top of the CT that provides a more model-appropriate API and sanity checking. Since the B√©zier tree has more constraints on its structure than the underlying CT, there‚Äôs an additional, higher-level &lt;code class=&quot;highlighter-rouge&quot;&gt;validate&lt;/code&gt; method that verifies the new preconditions after the base CT is itself validated. Other helper functions ensure that the consistency of the tree is not compromised when new points, shapes, or attributes are added. From the outside, callers can safely use methods like &lt;code class=&quot;highlighter-rouge&quot;&gt;addShape&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;updateAttributes&lt;/code&gt; on the wrapper without having to worry about the CT at all. It looks just like any other model object. (Incidentally, this approach to layering CRDTs is discussed in &lt;a href=&quot;https://arxiv.org/pdf/1212.2338.pdf&quot;&gt;this paper&lt;/a&gt;, though the technique isn‚Äôt exactly novel.)&lt;/p&gt;

&lt;p&gt;It‚Äôs possible that the use case of representing custom data types via CTs is a bit esoteric. Certainly, I wouldn‚Äôt use a CT for complex, versioned document formats akin to PSD or DOC. But just as with structs versus objects, or tuples versus arrays, I can imagine a number of scenarios where a small, custom CT might make the code so much cleaner and quicker than a composition of array, map, and register CRDTs. Quick-and-dirty data structures often turn out to be very useful in practice!&lt;/p&gt;

&lt;h2 id=&quot;performance&quot;&gt;Performance&lt;/h2&gt;

&lt;p&gt;OT and CRDT papers often cite 50ms&lt;sup id=&quot;fnref:latency&quot;&gt;&lt;a href=&quot;#fn:latency&quot; class=&quot;footnote&quot;&gt;18&lt;/a&gt;&lt;/sup&gt; as the threshold at which people start to notice latency in their text editors. Therefore, any code we might want to run on a CT‚Äîincluding merge, initialization, and serialization/deserialization‚Äîhas to fall within this range. Except for trivial cases, this precludes &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;) or slower complexity: a 10,000 word article at 0.01ms per character would take 7 hours to process! The essential CT functions have to be &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;) at the very worst.&lt;/p&gt;

&lt;p&gt;The simplest implementation of a weave is a contiguous array of atoms. Since every mutation resolves to an atom insertion, &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) is the baseline for any mutation. On account of spatial locality, this should be fine for the majority of use cases: &lt;a href=&quot;https://www.mikeash.com/pyblog/friday-qa-2016-04-15-performance-comparisons-of-common-operations-2016-edition.html&quot;&gt;Mike Ash‚Äôs benchmarks&lt;/a&gt; show that an iPhone 6s can &lt;code class=&quot;highlighter-rouge&quot;&gt;memcpy&lt;/code&gt; 1MB in 0.12ms, meaning that performance will probably be fine as long as the CT stays under ‚âà400MB. It also helps that the CT involves only a limited number of heap allocations and no pointer-chasing at all. If that‚Äôs not good enough, it should be possible to switch out the array for something like xi‚Äôs &lt;a href=&quot;http://google.github.io/xi-editor/docs/rope_science_00.html&quot;&gt;copy-on-write rope&lt;/a&gt; when the CT is expected to grow very large.&lt;/p&gt;

&lt;p&gt;My CT implementation maintains a cache of site yarns alongside the weave which incurs a slight performance penalty. Yarns are also stored as a single, contiguous array, so there‚Äôs an additional &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) cost for every weave mutation. Additionally, whenever a CT is received from another site, its yarns have to be generated on initialization. (Yarns are not part of the serialized data for reasons mentioned at the end of the ORDT section.) Yarn generation is &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;) since it‚Äôs isomorphic to sorting the weave. In exchange, the yarns give us &lt;em&gt;O&lt;/em&gt;(1) for the very common operation of looking up atoms by their identifier. Finding an atom‚Äôs weave index is still &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;), but this is a minor issue since the index is only really used when inserting new operations, and that‚Äôs an &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;) process already.&lt;/p&gt;

&lt;p&gt;Merging with another CT is almost always &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;). This involves iterating the two weaves together, comparing atoms by parentage and timestamp, constructing a new interwoven weave, and then regenerating the yarn cache. On occasion, a priority atom conflict might require finding the least common ancestor between two atoms in &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;), but this should be exceedingly rare. (And in any case, it‚Äôs unlikely that the two operations will differ by more than a couple of ancestors.)&lt;/p&gt;

&lt;p&gt;Weave validation is only &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;). All we have to do is look at each atom and keep track of a few counters to ensure that sibling order is correct and that causality is not violated. This is usually invoked on deserialization.&lt;/p&gt;

&lt;p&gt;CTs as implemented have a large memory footprint, both on account of the operation size and accumulated garbage. Assuming that a document is unlikely to contain more than 30% deletions, a 20,000 word article (like this one!) would eat up about 3MB versus 125KB as a simple C-string. While perhaps egregious in principle, I don‚Äôt think this is really that big of a deal in practice. First, even a 400,000-word, novel-length document would ‚Äúonly‚Äù take up 60MB of memory in the absolute worst case, which is easily digestible by modern devices. If keeping such large data structures in memory isn‚Äôt acceptable, and if random atom access isn‚Äôt essential to the task at hand, a &lt;a href=&quot;https://github.com/gritzko/ron#wire-format-base64&quot;&gt;RON-style compression strategy&lt;/a&gt; may be pursued.&lt;/p&gt;

&lt;p&gt;Additionally, the eminently-compressible CT format may be shrunk to a fraction of its full size on network transmission and storage. As a quick test, I saved a 125,000-atom, book-length CT to disk. Uncompressed, it took up 3.3MB; compressed via zip, a mere 570KB, or ‚âà6√ó the size of the equivalent C-string. For many use cases, this might be good enough!&lt;/p&gt;

&lt;h2 id=&quot;missing-features--future-improvements&quot;&gt;Missing Features &amp;amp; Future Improvements&lt;/h2&gt;

&lt;p&gt;Finally, it‚Äôs worth noting a few features that my CT currently lacks.&lt;/p&gt;

&lt;p&gt;For the moment, I‚Äôve decided to omit garbage collection altogether. I‚Äôll mainly be using CTs in document-based applications with relatively small files and a limited number of collaborators, so the CTs will only be expected to grow until the document is complete. This is not just a matter of laziness: I‚Äôm very interested in building software for completely decentralized environments without any connectivity guarantees, and garbage collection places constraints on the architecture of such systems. However, if you were using the CT for long-lived tasks such as database replication, messaging, or even preference syncing, you‚Äôd certainly want to implement one of the baselining strategies described in the ORDT section.&lt;/p&gt;

&lt;p&gt;Some CRDTs offer native undo and redo functionality, but I‚Äôm quite happy with this being delegated to a higher level. For example, in the case of string CTs, &lt;code class=&quot;highlighter-rouge&quot;&gt;UITextView&lt;/code&gt; seamlessly turns undo and redo commands into conventional deletes and inserts. Although this may result in excess garbage compared to explicit undo and redo operations, I think this sort of strictly-local approach is more architecturally correct than the alternative. (I‚Äôm not in the camp that believes remote changes should be locally undoable.) As a performance tweak and compromise, it might make sense to keep new operations separate from the main CT and only merge them when some set amount of time has passed or when the user has paused their editing. On undo, these pending operations could simply be dropped. My feeling is that this would significantly increase the complexity of certain functions in the CT and create a new vector for consistency issues, but it‚Äôs certainly worth investigating.&lt;/p&gt;

&lt;p&gt;The atom priority flag adds so much to the CT‚Äôs expressiveness, and I think it could be improved even further by switching to a full integer. &lt;code class=&quot;highlighter-rouge&quot;&gt;INT_MIN&lt;/code&gt; atoms would stick to their parent, &lt;code class=&quot;highlighter-rouge&quot;&gt;INT_MAX&lt;/code&gt; atoms would float to the back, and the rest would be sorted in numeric order. I‚Äôm also eager to play around with alternate tree traversals: to see, for example, if a BFS weave might be faster than the current DFS weave for certain kinds of data. It‚Äôs not yet clear to me whether these changes might break some of the invariants or intractably slow down merge, however.&lt;/p&gt;

&lt;p&gt;One huge advantage to storing the weave as a contiguous array is that it could be memory-mapped and used as an object‚Äôs backing data without having to deserialize it first. Better yet: if something like &lt;a href=&quot;https://capnproto.org&quot;&gt;Cap‚Äôn Proto&lt;/a&gt; were used to represent the atoms, this property could even be retained across the network! A user would be able to receive CT data from a peer or from disk, work with those bytes directly, and then send them right back without having to repackage them. In preparation for this scenario, it would be a good idea to leave a bit of extra space in each atom‚Äôs value for possible expansion of operations in the future. The validation function should also be made to throw an exception if an atom is discovered with an unknown case for its value enum.&lt;/p&gt;

&lt;p&gt;My CT is only a dumb data structure, and as such, has no provisions for dealing with malicious users or Byzantine faults. A bad actor could easily spoof someone‚Äôs UUID and corrupt the data structure with a few choice atoms. The &lt;code class=&quot;highlighter-rouge&quot;&gt;validate&lt;/code&gt; method would likely catch this attempt, but there‚Äôs no path for recovery after that. Consequently, production systems using CTs will likely need to deal with encryption and/or data recovery for when Bad Things happen. But that‚Äôs almost certainly a concern for a different architectural layer, not the core data structure.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Whew, that was a bit more than I intended to write!&lt;/p&gt;

&lt;p&gt;I didn‚Äôt even think such a thing was possible, but CRDTs have proven to be that white whale of eventual consistency I set out to look for all those months ago. They check off every item on my wishlist. You can use them in practically any computing environment and they will happily merge. They work indefinitely offline just as well as online. They‚Äôre composable with each other. You can use them for real-time collaboration, cloud sync, or local file sharing, and they‚Äôre perfectly suited for building convergent document formats.&lt;/p&gt;

&lt;p&gt;But even more remarkable is the discovery of Causal Trees and operation-based CRDTs. With this deconstruction of the CRDT formula, there‚Äôs finally a consistent way to understand, design, and implement arbitrary replicated data types. By breaking up conventional data structures into immutable micro-operations, giving them authorship and causality metadata, and carefully ordering them inside simple containers, you get the resilience and clarity of a convergent event log together with the efficiency of a low-level data structure. Since ORDTs are merely collections of ordered operations, the commutativity and idempotency guarantees required of CRDTs become trivially provable. Operations can just as easily be sent around as-is or condensed into state snapshots. Conflict resolution can be precisely tailored to fit the needs of the app and data type. Version vectors can be used to perform garbage collection, view past revisions, and otherwise split the document in a clean and consistent way. Even the smallest changes to the data can be sourced to individual contributors and linked between ORDTs. The operational approach is general enough to be used a design pattern, not just a specific implementation, which means that ORDTs can be applied to everything from databases to shared objects across threads. And all this is possible while &lt;em&gt;simplifying&lt;/em&gt; the architecture, not complicating it, since the paradigm is almost entirely functional!&lt;/p&gt;

&lt;p&gt;And sure, there are many tradeoffs compared to conventional sync techniques. For instance, CRDT data will always always be ‚Äúlive‚Äù. A user could accidentally make drastic changes to their document on two offline devices, then find that they‚Äôve automatically merged into a mess on reconnection. The lack of an authoritative server gives malicious users a lot of power to irrevocably screw up a document without any possibility of a rollback. CRDTs contain a lot of metadata and require smart and performant peers, whereas centralized architectures are inherently more resource-efficient and only demand the bare minimum of their clients. You‚Äôd be hard-pressed to use CRDTs in data-heavy scenarios such as screen sharing or video editing. You also can‚Äôt necessarily layer them on top of existing systems without significant refactoring, and versioning or updating your schemas in the future might be difficult.&lt;/p&gt;

&lt;p&gt;It‚Äôs true: an ORDT text editor will never be as fast, flexible, or bandwidth-efficient as Google Docs, for such is the power of centralization. But in exchange for a totally decentralized computing future? A world full of systems able to own their data and freely collaborate with one another? Data-centric code that‚Äôs entirely free from network concerns?&lt;/p&gt;

&lt;p&gt;I‚Äôd say: it‚Äôs surely worth a try!&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;OT Algorithm Papers&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hal.inria.fr/file/index/docid/109039/filename/OsterCollaborateCom06.pdf&quot;&gt;Tombstone Transformation Functions for Ensuring Consistency in Collaborative Editing Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;CRDT Algorithm Papers&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hal.inria.fr/inria-00555588/document&quot;&gt;A Comprehensive Study of Convergent and Commutative Replicated Data Types&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hal.archives-ouvertes.fr/inria-00108523/document&quot;&gt;Data Consistency for P2P Collaborative Editing&lt;/a&gt; (WOOT)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hal.inria.fr/inria-00397981/document&quot;&gt;CRDTs: Consistency Without Concurrency Control&lt;/a&gt; (Treedoc)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hal.inria.fr/inria-00336191/document&quot;&gt;Logoot: A P2P Collaborative Editing System&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hal.archives-ouvertes.fr/hal-00921633/document&quot;&gt;LSEQ: An Adaptive Structure for Sequences in Distributed Collaborative Editing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/8470/ae40470235604f40382aea4747275a6f6eef.pdf&quot;&gt;Replicated Abstract Data Types: Building Blocks for Collaborative Applications&lt;/a&gt; (RGA)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ds.ewi.tudelft.nl/~victor/articles/ctre.pdf&quot;&gt;Deep Hypertext with Embedded Revision Control Implemented in Regular Expressions&lt;/a&gt; (Causal Trees)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Operational CRDT Papers&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1710.04469.pdf&quot;&gt;Pure Operation-Based Replicated Data Types&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Other OT and CRDT Papers&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.933&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Operational Transformation in Real-Time Group Editors: Issues, Algorithms, and Achievements&lt;/a&gt; (CP2/TP2)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hal.inria.fr/inria-00629503/document&quot;&gt;Evaluating CRDTs for Real-Time Document Editing&lt;/a&gt; (CRDT performance analysis)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hal.inria.fr/hal-01343941/document&quot;&gt;High Responsiveness for Group Editing CRDTs&lt;/a&gt; (CRDT performance analysis)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1212.2338.pdf&quot;&gt;Controlled Conflict Resolution for Replicated Document&lt;/a&gt; (CRDT layering)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Non-Academic CRDT Writing&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@raphlinus/towards-a-unified-theory-of-operational-transformation-and-crdt-70485876f72f&quot;&gt;Towards a Unified Theory of Operational Transformation and CRDT&lt;/a&gt; (foundational research for the CRDT later used in &lt;a href=&quot;http://google.github.io/xi-editor/docs/crdt-details.html&quot;&gt;xi&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://speakerdeck.com/ept/convergence-versus-consensus-crdts-and-the-quest-for-distributed-consistency&quot;&gt;Convergence Versus Consensus: CRDTs and the Quest for Distributed Consistency&lt;/a&gt; (great illustrated overview by the Automerge folks)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.helftone.com/clear-in-the-icloud/&quot;&gt;Clear in the iCloud&lt;/a&gt; (an event-based, garbage-collected CvRDT in everything but name; highly recommended reading to get a second perspective on many topics covered in this article)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Operational CRDT Code&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/gritzko/ron&quot;&gt;Replicated Object Notation&lt;/a&gt; (the &lt;a href=&quot;https://github.com/gritzko/ron/tree/master/rdt&quot;&gt;rdt folder&lt;/a&gt; contains the CRDT definitions)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Non-Operational CRDT Code&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://google.github.io/xi-editor/docs/crdt-details.html&quot;&gt;xi&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/automerge/automerge&quot;&gt;Automerge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/atom/teletype-crdt&quot;&gt;Atom Teletype&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/y-js/yjs&quot;&gt;Y.js&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Other Materials&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://disi.unitn.it/~montreso/ds/handouts/03-gpe.pdf&quot;&gt;Distributed Algorithms&lt;/a&gt; (I thought this was a great primer)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:commutes&quot;&gt;
      &lt;p&gt;Although it‚Äôs most intuitive to think of individual operations as commuting (or not), commutativity is actually a property of the entire system as a whole and can be specified in many places. For example, a data structure might be entirely composed of operations that are naturally commutative (e.g. only addition), in which case nothing more needs to be done. Or: the system might be designed such that every event is uniquely timestamped, identified, and placed in a persistent and totally-ordered log, which can then be re-parsed whenever remote events are inserted. Or: the system might still be event-based, but instead of keeping around an event log, incoming concurrent operations are altered to ensure that their effect on the data structure is equivalent regardless of their order of arrival. So even if two operations might not be &lt;em&gt;naturally&lt;/em&gt; commutative, they could still be made to commute &lt;em&gt;in effect&lt;/em&gt; through a variety of methods. The trick is making sure that these ‚Äúcommutativity transformations‚Äù produce sensible results in the end.¬†&lt;a href=&quot;#fnref:commutes&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:op-crdt&quot;&gt;
      &lt;p&gt;This might sound a lot like Operational Transformation! Superficially, the approach is very similar, but the operations don‚Äôt have to be transformed since they‚Äôre specified (in concert with the data structure) to already have commutativity built in. &lt;code class=&quot;highlighter-rouge&quot;&gt;insert B to the right of A&lt;/code&gt; does not change its meaning even in the presence of concurrent operations, so long as ‚ÄòA‚Äô leaves a tombstone in case it‚Äôs deleted.¬†&lt;a href=&quot;#fnref:op-crdt&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:uuid&quot;&gt;
      &lt;p&gt;Note that UUIDs with the right bit-length don‚Äôt really need coordination to ensure uniqueness. If your UUID is long enough‚Äî128 bits, let‚Äôs say‚Äîrandomly finding two UUIDs that collide would require generating a billion UUIDs every second for decades. Most applications probably don‚Äôt need to worry about this possibility. If they do, UUIDs might need to be generated and agreed upon out-of-band. Fortunately, there‚Äôs very often a way to get a UUID from the OS or network layer.¬†&lt;a href=&quot;#fnref:uuid&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:complexity&quot;&gt;
      &lt;p&gt;Throughout the rest of this article, &lt;em&gt;n&lt;/em&gt; will generally refer to the total number of operations in a data structure, while &lt;em&gt;s&lt;/em&gt; will refer to the total number of sites.¬†&lt;a href=&quot;#fnref:complexity&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:rga&quot;&gt;
      &lt;p&gt;In fact, this is also how the RGA algorithm does its ordering, though it‚Äôs not described in terms of explicit operations and uses a different format for the metadata.¬†&lt;a href=&quot;#fnref:rga&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:deleteref&quot;&gt;
      &lt;p&gt;There‚Äôs that one delete at S1@T7 that requires backtracking, but we can fix it by using a priority flag for that operation type. More on that later.¬†&lt;a href=&quot;#fnref:deleteref&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:awareness&quot;&gt;
      &lt;p&gt;In the original paper, atoms don‚Äôt have Lamport timestamps, only indices, and atoms are compared by their &lt;strong&gt;awareness&lt;/strong&gt; instead of by timestamp. An atom‚Äôs awareness is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Version_vector&quot;&gt;version vector&lt;/a&gt; (called a &lt;strong&gt;weft&lt;/strong&gt;) that encompasses all the previous atoms its site would have known about at the time of its creation. This value is derived by recursively combining the awareness of the atom‚Äôs parent with the awareness of the previous atom in its &lt;strong&gt;yarn&lt;/strong&gt; (or ordered sequence of atoms for a given site) and requires special no-op ‚Äúcommit‚Äù atoms to occasionally be inserted. Though awareness gives us more information than a simple Lamport timestamp, it is also &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;)-slow to derive and makes certain functions (such as validation and merge) substantially more complex. The 4 extra bytes per atom for the Lamport timestamp are therefore a worthwhile tradeoff, and also one which the author of the paper has adopted in &lt;a href=&quot;https://github.com/gritzko/ron&quot;&gt;subsequent work&lt;/a&gt;.¬†&lt;a href=&quot;#fnref:awareness&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:lemma&quot;&gt;
      &lt;p&gt;Lemma 2: simply iterate through the atoms to the right of the head atom until you find one whose parent has a lower Lamport timestamp than the head. This atom is the first atom past the causal block. Although the paper uses awareness for this algorithm, you can easily show that the property applies to Lamport timestamps as well.¬†&lt;a href=&quot;#fnref:lemma&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:missing&quot;&gt;
      &lt;p&gt;Notably, the ordering of operations inside the structured log, as well as location identifiers for each operation. The former makes eval queries a lot slower, while the latter forces each operation to carry around a chunky vector clock instead of a simple Lamport timestamp.¬†&lt;a href=&quot;#fnref:missing&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:eventlog&quot;&gt;
      &lt;p&gt;In studying these structures, it was fascinating to discover how a design pattern could arc so elegantly across concepts! Treating your data model as the result of a persisted, append-only event log is a very clean approach that happens to be well-suited for convergence. (Milen Dzhumerov‚Äôs &lt;a href=&quot;https://blog.helftone.com/clear-in-the-icloud/&quot;&gt;sync architecture for Clear&lt;/a&gt; is a great example of this. I suggest carefully studying his article for a second perspective on many concepts also featured in mine.) But performance approaches an abysmal &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;&lt;sup&gt;2&lt;/sup&gt;) in many situations where rewinding history is required, such as merging distant revisions or recreating the data model from scratch. Zooming in and applying the event log pattern to the &lt;em&gt;data&lt;/em&gt; level suddenly makes the whole thing come together. Most of the performance hotspots are fixed, while all the benefits of convergence and history-tracking are retained.¬†&lt;a href=&quot;#fnref:eventlog&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:ops&quot;&gt;
      &lt;p&gt;And indeed, not all operations are necessarily meant to be executed! For example, the MVRegister CRDT is designed to present every concurrent value to the client in case of a conflict. ORDT operations are &lt;em&gt;simultaneously&lt;/em&gt; events and data, and in some situations might be treated more like one than the other. &lt;em&gt;PORDT&lt;/em&gt; describes it thusly: ‚Äúindeed, there are useful concurrent data types in which the outcomes of concurrent executions are not equivalent (on purpose) to some linearization.‚Äù¬†&lt;a href=&quot;#fnref:ops&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:causalorder&quot;&gt;
      &lt;p&gt;That is to say, assuming a site is guaranteed to have received every operation falling under a baseline before receiving the baseline itself. By the nature of version vectors, every operation included in a baseline is automatically in its causal past.¬†&lt;a href=&quot;#fnref:causalorder&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:preservation&quot;&gt;
      &lt;p&gt;If we still had access to our site-to-version-vector map, we could pick a baseline common to every reasonably active site. This heuristic could be further improved by upgrading our Lamport timestamp to a &lt;a href=&quot;http://sergeiturukin.com/2017/06/26/hybrid-logical-clocks.html&quot;&gt;hybrid logical clock&lt;/a&gt;. (A Lamport timestamp is allowed to be arbitrarily higher than the previous timestamp, not just +1 higher, so it can be combined with a physical timestamp and correction data to retain the approximate wall clock time for each operation.)¬†&lt;a href=&quot;#fnref:preservation&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:baselines&quot;&gt;
      &lt;p&gt;With this scheme, we have to use a sequence of baselines and not just a baseline register like before because all sites, per CRDT rules, must end up with the same data after seeing the same set of operations. (This is the very definition of strong eventual consistency!) With a simple baseline register, if a site happens to miss a few baselines, it could end up retaining some meant-to-be-orphaned operations if a new baseline later gets introduced that includes their timestamp. Now some sites would have the orphans and others wouldn‚Äôt. Inconsistency!¬†&lt;a href=&quot;#fnref:baselines&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:lww&quot;&gt;
      &lt;p&gt;In reality, in order to make the merge more meaningful and avoid artifacts, it would be better to keep around a sequence ORDT of session IDs alongside the bitmap. Each site would generate new session IDs at sensible intervals and add them to the end of the sequence, and each new pixel would reference the last available session ID. Pixels would be sorted first by session, then by timestamp+UUID. (Basically, these would function as ad hoc layers.) But LWW is easier to talk about, so let‚Äôs just go with that.¬†&lt;a href=&quot;#fnref:lww&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:git&quot;&gt;
      &lt;p&gt;And in fact, CT-based documents would be quite synergetic with regular git! Instead of pointing to a file blob, each git commit would only need to retain a single version vector together with the commit message. The CT would already include all the relevant history and authorship information and could restore the commit‚Äôs view of the data from the version vector alone, assuming no garbage collection had taken place.¬†&lt;a href=&quot;#fnref:git&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:causalpast&quot;&gt;
      &lt;p&gt;Well, as long as the referenced atom is in the new atom‚Äôs causal past. What this means is that you shouldn‚Äôt reference atoms that aren‚Äôt already part of your CT, which‚Äîwhy would anyone do that? Are you smuggling atom IDs through a side channel or something? I suppose it might be a case worth adding to the &lt;code class=&quot;highlighter-rouge&quot;&gt;validate&lt;/code&gt; method to help detect Byzantine faults.¬†&lt;a href=&quot;#fnref:causalpast&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:latency&quot;&gt;
      &lt;p&gt;This is a number pulled from several CRDT papers, but in principle, I‚Äôm more inclined to agree with Atom Xray‚Äôs &lt;a href=&quot;https://github.com/atom/xray#high-performance&quot;&gt;8ms target&lt;/a&gt;. Regardless, the conclusions don‚Äôt change very much: &lt;em&gt;O&lt;/em&gt;(&lt;em&gt;n&lt;/em&gt;log&lt;em&gt;n&lt;/em&gt;) remains sufficient even for very large files, and there are alternate solutions for the bulky edge cases.¬†&lt;a href=&quot;#fnref:latency&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 24 Mar 2018 00:00:00 -0700</pubDate>
        <link>http://archagon.net/blog/2018/03/24/data-laced-with-history/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2018/03/24/data-laced-with-history/</guid>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Bluetooth Headphone Sound-Off: Audio-Technica, Sony, Bowers &amp; Wilkins, V-MODA</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/blog/bluetooth-headphones/table.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I am once again in the market for Bluetooth headphones. My last pair, the first edition Sony MDR-1RBT, served me very well for the last four-and-a-half years. I didn‚Äôt (and still don‚Äôt) have much experience with the high end of the audio market, but when I was picking them out, they were among the best sounding headphones I‚Äôd heard. The feeling of space was especially startling: for the first time in a headphone, I felt like the music was all around me instead of being localized to a point between my ears. Now, parts of it were held together with glue and the remaining pleather was flaking all over my jacket. The time was right for an upgrade.&lt;/p&gt;

&lt;p&gt;I started to research comparable, $200 to $400 over-ear wireless replacements. My wishlist included noise cancellation, multi-device pairing, volume controls that interfaced with your device, tactile controls with previous/next buttons, and foldability. The only real technical requirements were audio quality, a zero-latency wired connection, and at least &lt;em&gt;some&lt;/em&gt; kind of physical control. But non-technical, quality-of-life attributes were also very important. It‚Äôs hard to deny that headphones play many important roles in our lives apart from simply reproducing audio. They are most certainly a fashion item. They serve as earmuffs in cold weather. They block out the outside world when we need to retreat into our work. For many of us, they‚Äôve become one of the most important and frequently used accessories in our wardrobe! Soon, we‚Äôll be seeing health and fitness sensors incorporated right into the earcups. Especially with the cord cut, there‚Äôs a lot more to headphones than just audio these days.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Based on a wide and thorough reading of the field‚Äî&lt;a href=&quot;https://www.head-fi.org&quot;&gt;Head-Fi&lt;/a&gt;, &lt;a href=&quot;https://www.innerfidelity.com&quot;&gt;InnerFidelity&lt;/a&gt;, &lt;a href=&quot;https://www.lesnumeriques.com&quot;&gt;Les Num√©riques&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/headphones/&quot;&gt;/r/headphones&lt;/a&gt;, and more‚ÄîI eventually whittled down my list to four pairs of headphones: the &lt;a href=&quot;http://amzn.to/2AHdwT4&quot;&gt;Audio-Technica ATH-DSR7BT&lt;/a&gt;, the &lt;a href=&quot;http://amzn.to/2AGYk8J&quot;&gt;Sony WH‚Äë1000xM2&lt;/a&gt;, the &lt;a href=&quot;http://amzn.to/2AIyZew&quot;&gt;Bowers &amp;amp; Wilkins PX&lt;/a&gt;, and the &lt;a href=&quot;http://amzn.to/2Bi4qgZ&quot;&gt;V-MODA Crossfade II Wireless&lt;/a&gt;. Since it was impossible to proceed past this point based on stats alone, I decided to get them all together in a room and give them a thorough, comparative workout.&lt;/p&gt;

&lt;h1 id=&quot;technology&quot;&gt;Technology&lt;/h1&gt;

&lt;p&gt;The &lt;a href=&quot;http://amzn.to/2AHdwT4&quot;&gt;Audio-Technica ATH-DSR7BT&lt;/a&gt; came widely recommended, but my first impressions were sorely disappointing. What I took out of the box was a creaky, plasticky set that clamped down hard on my head. The earpads don‚Äôt feel comfortable at all‚Äîcertainly nothing like the pillows on my old MDR-1RDT. The cover over the USB port will not stay seated. The strange IR play/pause ‚Äúbutton‚Äù positioned next to the regular buttons screams ‚Äúbudget design‚Äù and frequently misfires. The headphone volume controls appear to act independently of your paired device, forcing you to juggle two different sets of volume. There is also a quiet, tape-like hiss audible over silent passages. My 1RBT has occasional buzzing and popping over silence, but not to this degree. Perhaps the only technical advantage here is the fact that the volume rocker performs double duty as previous and next: very useful for jogging back and forward in audiobooks and podcasts.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://amzn.to/2AGYk8J&quot;&gt;Sony WH‚Äë1000xM2&lt;/a&gt; also didn‚Äôt amaze me in the build quality department. Though these are in fact the lightest set of the bunch, the materials here simply feel cheap. The plastic is on the same level I would expect to see in a bundled TV headphone, not a $350 product. Comfort-wise, they are OK but not great. The pads in particular are strictly pragmatic and lack the gentleness my MDR-1RBT. The earcups are roomy enough and the clamping force is light enough that the headphones slide around on your head when moving around. In terms of fashion, I‚Äôm just not fond of the design. It‚Äôs hard to describe these headphones as anything but office-grey boring, though the parallel &lt;a href=&quot;http://amzn.to/2BKjLCT&quot;&gt;h.ear on 2&lt;/a&gt; models do come in different colors. (On that note, I‚Äôve actually seen some scattered accounts of people who prefer the sound of the h.ear on 2 over the 1000xM2, even though h.ears look identical and cost $50 less. Reviews are still scarce, though, so it‚Äôs hard to know for sure.) On the upside, these headphones fold and come with a carrying case.&lt;/p&gt;

&lt;p&gt;Aside from the two buttons for switching power and ANC, the controls here are touch based. You can double-tap on the right earcup to play/pause and swipe in one of four directions for previous/next and volume adjustment. I didn‚Äôt expect to prefer these controls over physical buttons, but in practice they worked flawlessly. Buttons are often tricky to find on earcups anyway, so having a wide berth for gestures is a big plus. (No pun intended.) And in any case, it‚Äôs certainly worth having for the discrete previous/next gestures. You can also place your hand over the right earcup to pipe sound in during conversations. This feature is not useful to me since I‚Äôd prefer to just take my headphones off out of politeness, but maybe handy for noisy offices with ANC enabled.&lt;/p&gt;

&lt;p&gt;Unfortunately, it doesn‚Äôt seem that these headphones have the ability to pair with multiple devices simultaneously. (I did not test this myself, but it‚Äôs been mentioned in a number of forum posts.) This means you have to do the Bluetooth disconnection dance if you‚Äôre switching between laptop and phone, which is rather annoying.&lt;/p&gt;

&lt;p&gt;As reviews have stressed, ANC does not seem to affect sound quality in any major way. I didn‚Äôt visit any noisy environments with these headphones so I can‚Äôt vouch for the ANC‚Äôs effectiveness, though reviewers have reported it to be best-in-class. The Sony Connect app is a sight to behold, featuring several pages of settings mostly related to ANC behavior. There‚Äôs even a built-in EQ. (I tried out some of the surround effect settings, but the results were frankly underwhelming.)&lt;/p&gt;

&lt;p&gt;In terms of background noise, there is surprisingly very little here. If you strain very hard you can detect a slight hiss when the amp is on, but it‚Äôs basically imperceptible.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://amzn.to/2AIyZew&quot;&gt;Bowers &amp;amp; Wilkins PX&lt;/a&gt; is certainly the most interesting headphone of the bunch. In terms of build quality, it really can‚Äôt be faulted. Every surface features lovely premium materials, including metal and real leather. The design is very attractive too, though I confess that I‚Äôm not too fond of the gaps the headband forms with the sides of my head. The pads aren‚Äôt cushy, but I don‚Äôt find them to be actively uncomfortable like some reviewers have. In fact, coupled with the high clamping force, I can really appreciate just how firmly these headphones sit on my ears. No amount of motion is likely to dislodge them. This also gives the PX the best passive isolation I‚Äôve heard in a headphone. You don‚Äôt even need to enable ANC to block out most of the outside world. The earcups are fairly small, so this pair might not be a good choice if you have large ears. Personally, I find them cozy.&lt;/p&gt;

&lt;p&gt;Tech-wise, the PX attempts some very interesting things. First, the headphones pause your music when you take them off and then resume playing when you put them back on. In essence, this works almost the same as with the AirPods. Some people have complained about the sensitivity (which you can adjust in the B&amp;amp;W Control app) but I found it to be tuned just right. The feature works just as well on Mac and Windows, and on a technical level I was surprised by how many different kinds of media it was able to pause. (YouTube videos, for example.) Unfortunately, there are several flaws that might compel you to disable the feature altogether. (This is also possible through the app.) One, if you remove a single earcup to talk to someone, the headphones might pause and then immediately resume after detecting the back of your neck. Two, if you pause your media &lt;em&gt;before&lt;/em&gt; taking off your headphones, it will still start playing after you put them back on. This can create some loud and unpleasant surprises.&lt;/p&gt;

&lt;p&gt;Next, these headphones have the ability to connect to multiple devices simultaneously. This doesn‚Äôt mean that your laptop and phone can interleave their audio, but it does allow you to switch back and forth between devices without any friction. The execution here is a bit questionable, though. If you‚Äôre connected to two devices and one of them produces a sound, the other device will automatically pause its media in the same way as the auto-pausing feature. In practice, this means that you have to put your phone on mute if you‚Äôre also connected to your laptop, since any notification sounds will immediately pause your music. &lt;span class=&quot;update&quot;&gt;(Update: it actually seems that the pausing behavior between laptop and phone depends on which device you connected to first. See my notes at the end for more info.)&lt;/span&gt; If you prefer not to switch devices this way, you also have the option of quickly disconnecting from the currently paired device by way of a brief hold of the power button. This is significantly improved over the usual Bluetooth headphone switching hullabaloo, which involves going to your paired device and manually disconnecting the headphones in the Bluetooth device list. Having a disconnect option right on the earcup is a great convenience.&lt;/p&gt;

&lt;p&gt;ANC has its own switch, and you can adjust the sensitivity from inside the app. Reviewers have pointed out that sound quality suffers when ANC is set to the highest setting, and from cursory testing I have to agree. The loss is diminished with ANC is switched to the lower setting (Office), though it does seem quite weak. The highest setting (Flight) surprised me with just how serene it made the surrounding world. Riding on a train felt just like sitting in a quiet room. Plus, there was no sense of pressure at all.&lt;/p&gt;

&lt;p&gt;Battery saving on the PX is fairly aggressive. If there‚Äôs no audio stream detected for about a second, you can hear the amplifier turning off. (You can tell because there‚Äôs a very, very faint hiss when the amplifier is on. I‚Äôd say it‚Äôs on par with the 1000xM2 and only really detectable in contrast to absolute silence. These headphones have a &lt;em&gt;very&lt;/em&gt; clean sound.) Then, when streaming resumes, the audio takes a second to fade back in. This is much improved over my MDR-1RBT, which simply switches off on audible silence and causes cleaned-up audiobooks and podcasts to glitch out&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Here, even if there‚Äôs no sound coming from the drivers, the amplifier will remain on as long your software has an active audio session going. (I believe this is the case with the other three headphones as well.)&lt;/p&gt;

&lt;p&gt;One of the biggest technical flubs with these headphones is the standby mode. As per the manual, the PX go into ‚Äústandby‚Äù after 2 minutes of inactivity when not being worn. While in this mode, they disconnect from Bluetooth and turn off most of their electronics. Then, when the user puts them back on, they spring back to life and reconnect to the last paired Bluetooth device (but not multiple ones). Unfortunately, having this work semi-reasonably absolutely requires the wear sensor to be enabled. Presumably, the wear sensor is what lets the headphones detect when they‚Äôre being taken off or put back on. Without that sensor working, the headphones turn off after 2 minutes of silence &lt;em&gt;even if you‚Äôre still wearing them&lt;/em&gt;. This means you could pause your music, have a 5 minute conversation, then resume‚Äîonly to have your 90‚Äôs grunge favorites blare out of your speakers for the whole office to hear! To me, this makes leaving the wear sensor disabled a non-option.&lt;/p&gt;

&lt;p&gt;The PX, really, has three modes: wireless, USB wired (which turns the headphones into a USB output device), and ‚Äúanalog‚Äù 3.5mm. That last mode is in quotes because even though the PX has a 3.5mm output, the headphones still have to be charged in order to use it. A bit annoyingly, when in USB mode (though thankfully not in 3.5mm mode), the headphones apply the same power-saving, amp-switching logic as in wireless mode. In practice it‚Äôs not really a problem, but you might be surprised if you hit the volume button expecting a beep and don‚Äôt hear anything because the amp hasn‚Äôt warmed up yet. I perceive the USB wired mode as having very slightly more latency than the 3.5mm mode‚Äîmaybe 1 to 2 extra milliseconds‚Äîthough I only tested this by switching back and forth in a game of Overwatch. &lt;span class=&quot;update&quot;&gt;(Update: according to an informal latency test using Crypt of the Necrodancer‚Äôs audio settings, USB latency is actually on the order of 30‚Äì40 milliseconds. Not sure if there‚Äôs any way to make this lower.)&lt;/span&gt; I was hoping to gain access to the microphone over USB in order to use the PX as an quick-fix gaming headset, but this functionality is unfortunately locked away. The microphone does technically show up as an input device in both macOS and Windows, but it doesn‚Äôt produce any sound.&lt;/p&gt;

&lt;p&gt;Meanwhile, the 3.5mm connection is very audibly noisy‚Äîfar more than either of the other modes, including wireless. Usually this manifests as a hum, but sometimes you can even hear crackling or static. This interference is amplified twofold when the USB cable is attached simultaneously, making me think that the analog lines inside the headphones haven‚Äôt been shielded for some reason. (Other users on Head-Fi have suggested that this might be a grounding issue, and indeed the hiss does change depending on the device and even the workload, but there doesn‚Äôt seem to be any way to make it disappear completely. In any case, plenty of ungrounded devices sound great with my other headphones, so it‚Äôs a sorry excuse.) Since 3.5mm is the only analog, near-zero latency connection to this headphone, this strikes me as a pretty big oversight. The quality of the analog connection might not matter for games, but if you‚Äôre interested in musical performance, having any sort of noise on that line is simply unacceptable.&lt;/p&gt;

&lt;p&gt;Along with the ANC and power buttons, there are three controls on the right earcup: one multi-use button for play/pause/forward/back and two buttons for volume adjustment. I wish it was possible to make the volume buttons act like previous/next instead, since double- and triple-clicking the multi-use button for navigation can be finicky. (It‚Äôs been pretty consistent for me, but navigating in the wrong direction even one time out of twenty is really frustrating.) At least the multi-use button is contoured and very clicky so you can definitely tell when you‚Äôve pressed it.&lt;/p&gt;

&lt;p&gt;The PX earcups turn flat for travel and come with a magnetic pouch, but the space savings are minimal. Actually, I wish the cups turned in the opposite direction, since wearing them over your neck with the earcups facing up is a bit awkward.&lt;/p&gt;

&lt;p&gt;Of the four headphones, the &lt;a href=&quot;http://amzn.to/2Bi4qgZ&quot;&gt;V-MODA Crossfade II Wireless&lt;/a&gt; is certainly the most comfortable and (to my taste) the best looking. There‚Äôs some plastic here, but it‚Äôs the &lt;em&gt;good&lt;/em&gt; kind of plastic. You get the sense that you‚Äôd be able to throw these headphones around without much fear of damage. The design is fun and a bit 90‚Äôs, and I particularly love the subtle gold accents in my color scheme&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. The earcups are soft and pillowy and fit snugly over your ears. Many people suggest getting XL earcups for these headphones, but I actually like the default size.&lt;/p&gt;

&lt;p&gt;Much like the PX, you can pair these headphones with multiple devices. Unlike the PX, audio does not pause when sound comes in on a second device. My empirical understanding is that you‚Äôre only able to start listening on a different device when the active audio session on your current device finishes playing. In practice, this seems to be triggerable by pausing your media or maybe closing your music or video player in the worst case. I prefer this behavior to the PX‚Äôs, since I don‚Äôt have to work around notifications interrupting my playback.&lt;/p&gt;

&lt;p&gt;Much like in the ATH-DSR7BT, there‚Äôs a very noticeable hiss in wireless mode over silent passages. In practice you can‚Äôt hear it over most music (except classical), but it &lt;em&gt;is&lt;/em&gt; always there in the background, subtly shifting the quality of your music. I‚Äôve heard it said that these headphones were designed first and foremost to be great wired cans, and at least two people have corroborated that they do in fact sound terrific in analog mode. (Many other Bluetooth headphones don‚Äôt sound nearly as good without their circuitry switched on.) The included 3.5mm braided cable features a microphone and a multi-use button, though the microphone quality is very poor.&lt;/p&gt;

&lt;p&gt;Oddly enough, iOS seems to track the battery level of these headphones in 20% increments. (The PX appears to use 10% increments, but at least you can check the precise battery level from the app.) For some boneheaded reason, V-MODA decided that it would be a great idea to have the headphones beep once a minute for the entirety of the last half-hour of battery life. The effect only serves to shorten the battery life even further since it‚Äôs just so difficult to tolerate.&lt;/p&gt;

&lt;p&gt;The physical controls work the same as on the PX: three buttons, two for volume and one multi-use. Here, the multi-use button sits on top of the earcup‚Äôs hexagonal inlay so it‚Äôs fairly easy to feel out. The buttons are a bit mushier than on the PX, making it easier to misclick if you‚Äôre going for those double or triple clicks.&lt;/p&gt;

&lt;p&gt;V-MODA has a couple out-of-band perks that are worth noting. First, you can send them your headphones even if they get completely trashed (if they‚Äôre still on sale) and receive a 50% coupon for a comparable model in return. (Especially important in the fast-moving world of wireless audio!) Second, the company is closely affiliated with the Head-Fi userbase and seems very much in touch with the audio enthusiast community. This gives me a bit more faith in their product and support than I would otherwise have.&lt;/p&gt;

&lt;h1 id=&quot;sound&quot;&gt;Sound&lt;/h1&gt;

&lt;p&gt;First, I should state for the record that I‚Äôm not really an audiophile. To be sure, I enjoy high quality audio and keep a hard drive worth of FLACs on standby. But the most expensive pair of headphones I‚Äôve ever owned is the MDR-1RBT, and I‚Äôve not had an opportunity to test and especially ABX any true audiophile cans. My only high-end frame of reference is a Sennheiser HD 800 S I briefly demoed at the SF Sennheiser store. (Incidentally, this experience was an excellent calibrator for all my future audio expectations. Never thought audio could sound so crisp and spacious through a pair headphones!)&lt;/p&gt;

&lt;p&gt;Second, I‚Äôm an audiophilia skeptic. Though I do love my FLACs as a collector, I believe that V2 MP3s (or equivalent) are universally transparent for the vast majority of music. I‚Äôm also very wary of magical-sounding terms used to describe audio equipment, since the placebo effect is so darn powerful when it comes to sound. For this test, I tried my best to describe exactly what I heard and to compare headphones as analytically as possible. This required switching sets many times over the course of a single piece of music and sometimes even a single section. I don‚Äôt have much hands-on experience with the vocabulary used in audio enthusiast circles (e.g. ‚Äúdark‚Äù, ‚Äúwarm‚Äù, ‚Äúdetailed‚Äù, ‚Äúanalytical‚Äù, etc.) so I tried to describe the sound in my own words. Even as a skeptic, I was surprised by just how unique each headphone sounded on close listen!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/blog/bluetooth-headphones/testing.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For testing, I got four iOS devices and paired a headphone to each one. I tried to equalize the volumes as best as possible. Then, I would pick the same piece of music on each device and hit play simultaneously, switching between headphones as the piece went along. As I listened, I took notes on each headphone. My playlist featured old and new favorites across a diverse set of genres as well as a few fancy masterings. I tried to select pieces that were well-mastered and featured a variety of instruments, frequencies, and sounds. Here‚Äôs what I ended up listening to over the course of several hours:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dire Straits ‚Äî¬†Sultans of Swing&lt;/li&gt;
  &lt;li&gt;Deep Purple ‚Äî Space Truckin‚Äô&lt;/li&gt;
  &lt;li&gt;The Clash ‚Äî London Calling&lt;/li&gt;
  &lt;li&gt;Prince ‚Äî¬†Purple Rain&lt;/li&gt;
  &lt;li&gt;Brian Wilson ‚Äî Good Vibrations&lt;/li&gt;
  &lt;li&gt;Sufjan Stevens ‚Äî Decatur&lt;/li&gt;
  &lt;li&gt;Nickel Creek ‚Äî Reasons Why&lt;/li&gt;
  &lt;li&gt;Punch Brothers ‚Äî Passepied&lt;/li&gt;
  &lt;li&gt;Acoustic Alchemy ‚Äî¬†Mr. Chow&lt;/li&gt;
  &lt;li&gt;Acoustic Alchemy ‚Äî¬†No Messin‚Äô&lt;/li&gt;
  &lt;li&gt;Paul Gilbert ‚Äî Three Times Rana&lt;/li&gt;
  &lt;li&gt;Rebecca Pidgeon ‚Äî¬†Spanish Harlem&lt;/li&gt;
  &lt;li&gt;Elliot Smith ‚Äî Bottle Up and Explode&lt;/li&gt;
  &lt;li&gt;Poe ‚Äî¬†Hey Pretty&lt;/li&gt;
  &lt;li&gt;Tori Amos ‚Äî¬†A Sorta Fairytale&lt;/li&gt;
  &lt;li&gt;Radiohead ‚Äî¬†Let Down&lt;/li&gt;
  &lt;li&gt;Radiohead ‚Äî¬†How to Disappear Completely&lt;/li&gt;
  &lt;li&gt;Radiohead ‚Äî¬†Kid A&lt;/li&gt;
  &lt;li&gt;London Zoo ‚Äî¬†Poison Dart&lt;/li&gt;
  &lt;li&gt;Porcupine Tree ‚Äî¬†Mellotron Scratch&lt;/li&gt;
  &lt;li&gt;The Derek Truck Band ‚Äî¬†Sahib Teri Bandi/Maki Madni&lt;/li&gt;
  &lt;li&gt;Polyphia ‚Äî¬†Finale&lt;/li&gt;
  &lt;li&gt;Galneryus ‚Äî Lament&lt;/li&gt;
  &lt;li&gt;Tipper ‚Äî Gulch&lt;/li&gt;
  &lt;li&gt;Tipper ‚Äî It‚Äôs Like&lt;/li&gt;
  &lt;li&gt;Tipper ‚Äî Cubic Squeal&lt;/li&gt;
  &lt;li&gt;Ott ‚Äî¬†Adrift in Hilbert Space&lt;/li&gt;
  &lt;li&gt;Opiuo ‚Äî Axolotl Throttle&lt;/li&gt;
  &lt;li&gt;Yori Horikawa ‚Äî Letter&lt;/li&gt;
  &lt;li&gt;–ü–µ—Å–Ω–∏ –ù–∞—à–µ–≥–æ –í–µ–∫–∞ ‚Äî –ö–æ–Ω—Ç—Ä–∞–±–∞–Ω–¥–∏—Å—Ç—ã&lt;/li&gt;
  &lt;li&gt;–ü–µ—Å–Ω–∏ –ù–∞—à–µ–≥–æ –í–µ–∫–∞ ‚Äî –ì—Ä–µ–Ω–∞–¥–∞&lt;/li&gt;
  &lt;li&gt;–ü–µ—Å–Ω–∏ –ù–∞—à–µ–≥–æ –í–µ–∫–∞ ‚Äî –ö—É–ø–æ–ª–∞&lt;/li&gt;
  &lt;li&gt;Pat Metheny ‚Äî¬†Last Train Home&lt;/li&gt;
  &lt;li&gt;Beethoven, Josef Bulva ‚Äî Piano Sonata No. 14 in C# Minor, Op. 27/2 ‚ÄúMoonlight‚Äù: III. Presto agitato&lt;/li&gt;
  &lt;li&gt;Rachmaninoff ‚Äî¬†√âtude-tableau in B Minor, Op. 39/4&lt;/li&gt;
  &lt;li&gt;David Bowie ‚Äî¬†Lady Stardust (Ryko Au20)&lt;/li&gt;
  &lt;li&gt;David Bowie ‚Äî Moonage Daydream (Ryko Au20)&lt;/li&gt;
  &lt;li&gt;Supertramp ‚Äî Take the Long Way Home (MFSL)&lt;/li&gt;
  &lt;li&gt;Pink Floyd ‚Äî Time (MFSL)&lt;/li&gt;
  &lt;li&gt;Pink Floyd ‚Äî¬†Wish You Were Here (Mastersound Gold)&lt;/li&gt;
  &lt;li&gt;Pink Floyd ‚Äî¬†Hey You (MFSL)&lt;/li&gt;
  &lt;li&gt;Metallica ‚Äî Master of Puppets (DCC)&lt;/li&gt;
  &lt;li&gt;Miles Davis ‚Äî All Blues (Japan DSD)&lt;/li&gt;
  &lt;li&gt;Stan Getz &amp;amp; Jo√£o Gilberto ‚Äî Doralice (MFSL)&lt;/li&gt;
  &lt;li&gt;Stan Getz &amp;amp; Jo√£o Gilberto ‚Äî O Grande Amor (MFSL)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;a href=&quot;http://amzn.to/2AHdwT4&quot;&gt;Audio-Technica ATH-DSR7BT&lt;/a&gt; was the obvious straggler of the four. Although the soundstage was reasonably spacious (more so than the Crossfade) with good instrument separation, crispness, and detail, I frequently noted that the tone was shrill, sibilant, and harsh‚Äîeven tinny. This was the only pair that was actually unpleasant to listen to in some vocal sections. It often felt like the low end was sometimes attenuated, leaving behind jagged and unpleasant remains in the higher registers. Which is not to say that this pair sounded &lt;em&gt;bad&lt;/em&gt;, but compared to the competition, it felt like it lagged a few generations behind. Coupled with the hardware issues, bizarre design, and build quality, I would definitely avoid this one.&lt;/p&gt;

&lt;p&gt;Next in ranking was the &lt;a href=&quot;http://amzn.to/2AGYk8J&quot;&gt;Sony WH‚Äë1000xM2&lt;/a&gt;. The soundstage here was very wide, but it felt, for lack of a better word, spherical. The sound lacked dimensionality and detail. The instruments sounded kind of murky and blended with each other instead of sticking out in space. (I wrote down: rounded, hollow, dull, muted, faded.) The bass was quite boomy and exaggerated in a way that just didn‚Äôt feel very realistic. Songs would often sound overly resonant or reverby. I realized while listening to this set that none of my favorite musical moments had any pop or excitement to them. These headphones sounded fine, but they kind of sucked the life out of everything. They simply felt cold. (Surprisingly, even my MDR-1RBT sounded comparitively warm and lively despite having a flatter and much tinnier sound.)&lt;/p&gt;

&lt;p&gt;The last two headphones were just so different in their tone that I couldn‚Äôt assign them an order.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://amzn.to/2AIyZew&quot;&gt;B&amp;amp;W PX&lt;/a&gt; was definitely the odd one of the bunch. (Listening notes were taken with ANC off. ANC significantly degrades the sound quality.) First thing that jumped out at me was the sheer spatiality. Much like my memory of the 800 S, recordings that used to feel relatively flat suddenly sounded almost binaural with this pair. Instruments would hang in the air with a wonderful amount of empty space between them. If you closed your eyes, you almost had the sense of being on a small stage with the musicians. (I wrote down: crisp, balanced, layered, subtly detailed, like a band playing around you.) For genres like jazz and classical (especially piano), this effect was simply transcendent. However, in comparison to the other headphones, there was something odd about the tone of certain instruments. Vocals in particular sounded a bit metallic, compressed, or rounded in a way I couldn‚Äôt quite pin down. I don‚Äôt know if I would have noticed if I was just listening to this pair in isolation, but in contrast especially to the Crossfade, the difference was quite stark. Maybe it‚Äôs simply a matter of preference; maybe it‚Äôs a sonic flaw; or maybe some longer burn-in is required. I know people on Head-Fi have complained about a boxy or tunnel-like character to vocals, but I don‚Äôt know they were referring to the same effect since the soundstage and detail are otherwise amazing. (I couldn‚Äôt get the pair to sound any different when pressing down on both earcups, as one user suggested. The earcup seals hold very well for me even with glasses on.) I also found that the headphones had a very neutral sound. Vocals fell in line with the other instruments. Plucky guitars lost their warmth and reverb. Bass was certainly there, but reserved. Many songs sounded very immersive but lacked ‚Äúwow‚Äù in their most kinetic passages. And especially combined with a hint of harshness in the upper registers (cymbals, occasional vocals), bassy electronic music tended to fall flat and lose its lush, enveloping effect.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://amzn.to/2Bi4qgZ&quot;&gt;V-MODA Crossfade II&lt;/a&gt;, on the other hand, simply sounded fun. Incredibly fun. Several times in my notes, I wrote that it was like sinking into a pillow of sound. The signature felt intimate and warm. The soundstage was relatively small, but you could hear each instrument plucking away around you. And oh, those plucks! You could almost physically feel every string on the guitar. (My notes mentioned a rich, cozy, lush, plump, and enveloping sound.) Color-wise, bass is clearly emphasized (to the point of occasionally being boomy) and vocals float forward. In terms of detail, I‚Äôd say they beat Sony but defer to B&amp;amp;W. You can still pick out the smaller details, but it‚Äôs not quite as clear and the instruments don‚Äôt have their near-binaural separation. (In fact, I noted that the soundstage occasionally felt a bit flat and that the vocals sometimes sounded a bit muddy or fuzzy.) Nonetheless, whereas the PX astounds in certain genres (jazz, classical) but flubs in others (downtempo, trip-hop), the Crossfade excels in music featuring bass, vocals, and acoustic guitars and does a &lt;em&gt;good&lt;/em&gt; job with just about everything else. Best of all, this pair is generous with its ‚Äúwow‚Äù moments. Crescendos, bass drops, and other dramatic passages hit you just as hard as the artists intended. At its worst, the Crossfade produces a hyperactive mass of sound. At its best, it grabs you and all but forces you to move your feet. And in contrast to the PX, the sound doesn‚Äôt demand your attention. You can sit back and just let it wash over you. Still, I couldn‚Äôt help but wonder: was this what the music was &lt;em&gt;supposed&lt;/em&gt; to sound like, or was it just sugar for my ears? The 650 and 800 I tested at Sennheiser certainly sounded a lot more like the PX than this pair. (Incidentally, I knew going in that these were considered basshead cans, but I tried my best to avoid the trap of conflating bass with sound quality. Indeed, I thought the Sony headphones actually had a bassier sound, but there it felt hollow and reverby while here it was resonant, impactful, and lively.)&lt;/p&gt;

&lt;h1 id=&quot;an-inconclusive-conclusion&quot;&gt;An Inconclusive Conclusion&lt;/h1&gt;

&lt;p&gt;Choosing between the &lt;a href=&quot;http://amzn.to/2AIyZew&quot;&gt;PX&lt;/a&gt; and &lt;a href=&quot;http://amzn.to/2Bi4qgZ&quot;&gt;Crossfade&lt;/a&gt; has been rather difficult. I love the Icarus-like reach of the PX towards a higher audio plane but feel burned by its glitches and oversights. The aggressive power saving causing the unit to frequently turn off is quite annoying, though the long battery life (30-40 hours) is certainly a huge plus. Meanwhile, the Crossfade keeps things very simple and elegant on a technical level but suffers from a pretty short battery life (10-15 hours), along with incessant beeping towards the tail end. The Crossfade also has that frustrating hiss over silence in wireless mode, though wired performance is quite excellent. The PX stays perfectly silent when used wirelessly or over USB, but has an even worse hiss in 3.5mm wired mode. In terms of materials, the PX feels more premium but I think the Crossfade just looks better when worn. It‚Äôs also significantly more comfortable in a direct comparison. But despite the cushier materials, I‚Äôve found the clamping force to be more annoying on the Crossfade than the PX over several hours. The PX also clearly wins out in terms of sound isolation, both passively and with the help of ANC. Sound-wise, the two headphones couldn‚Äôt be more different. The PX is spacious, detailed, and sterile, while the Crossfade is enveloping, warm, and resonant. Jazz and classical music spring to life with the PX, while plucky guitars, vocals, and electronic music make you want to get out of your seat with the Crossfade. In terms of support, the PX are set to get frequent firmware updates, but V-MODA has an excellent reputation and a lucrative trade-in program. The choice is made even harder by the fact that I got the Crossfade on sale for $240 while the PX is fixed at $400 with no sales in sight.&lt;/p&gt;

&lt;p&gt;I think I‚Äôll have to spend a few more hours listening to each set before I make up my mind!&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;update-2017-12-29&quot;&gt;Update 2017-12-29&lt;/h3&gt;

&lt;p&gt;After a few more weeks (!) of deliberation, I‚Äôve decided to go with the Crossfade as my headphone of choice.&lt;/p&gt;

&lt;p&gt;It‚Äôs undeniable that the PX sounds amazing, maybe even beyond its price class in classical, jazz, and acoustic music‚Äîreally, anything that‚Äôs recorded from live instruments. For the first time in a headphone I‚Äôve personally tested, the music becomes a perfect little diorama in which I can easily shift my locus of attention from one sound to the next. In many songs, I‚Äôve even been compelled to turn around after hearing a particularly realistic noise! It almost feels like putting on 3D glasses. The weird effect I noticed with the vocals has also gone away over time.&lt;/p&gt;

&lt;p&gt;Ultimately, though, music is more than just what‚Äôs recorded, and so much of what‚Äôs released today is drawn from whole cloth: synths, sounds, and code combined together in ways that have no real-world analogue. Neutral headphones are said to give you exactly what the audio engineers intended, but perhaps this is archaic advice. There are plenty of producers today who specialize in designing resonant, enveloping soundscapes that fail the neutral test but spring to life once a little color added. And unfortunately, no matter how hard you tweak the EQ, you‚Äôll never get the kind of bass impact and resonance out of the PX as you get with the Crossfade. It‚Äôs strictly a hardware issue.&lt;/p&gt;

&lt;p&gt;Still, the detail and clarity of the PX might be awfully tempting. I certainly couldn‚Äôt stop myself from going back and forth between the two headphones over the last month. In truth, were it a better product, I‚Äôd almost certainly pick the PX. But a wireless headphone is more than just a spigot of sound. It‚Äôs a wearable that‚Äôs supposed to make your life easier, not conscript you into finding solutions to its dozens of little problems‚Äîand that‚Äôs all I‚Äôve been doing with the PX as of late. Both headphones have multi-device mode, but the PX requires pairing with your laptop first if you don‚Äôt want your music to immediately pause as soon as you wake your phone. If both your phone and laptop simultaneously demand an audio stream, your music will be stuck in a pause loop; this notably happens if you open the Spotify app on both devices and try to use one as a remote for the other. (One solution is to change the output device on your phone to use speakers instead of Bluetooth, but that‚Äôs an extra step.) The PX goes to sleep 2 minutes after you take it off, losing any connection to your secondary device and forcing you to wait several seconds for it to reconnect to your primary device once you put it back on. If the wear sensor is disabled‚Äîwhich many people would want to do on account of its flakiness‚Äîthe headphones go to standby after 2 minutes of silence even when worn, causing awkward speaker blares once you eventually resume your music. A direct USB connection confers 30‚Äì40ms of latency, and the lag-free 3.5mm port adds very loud noise and static related to the grounding of your equipment. (With my &lt;a href=&quot;/blog/2016/12/31/cheap-and-painless-egpu-thrills-on-a-2013-macbook-pro/&quot;&gt;Macbook eGPU setup&lt;/a&gt;, it is simply unbearable. Silences in games are filled with pops and crackles, and the only way to stop the noise is to lay both hands on the metal chassis of my laptop. Sure: you could argue that my grounding situation is messed up, but there exists plenty of audio equipment that doesn‚Äôt even have a ground plug to begin with!) ANC works great but substantially deteriorates the sound quality. Finally, the PX is undeniably an uncomfortable headphone, clamping your head and almost making you feel like you‚Äôre wearing plastic cups over your ears. Definitely not a ‚Äúsink-into-it‚Äù kind of device.&lt;/p&gt;

&lt;p&gt;In terms of quality of life, the Crossfade excels in all regards. It keeps things simple. It‚Äôs a piece of analog audio equipment first and foremost, and the 3.5mm connection works perfectly. It connects to your devices and stays connected when you put it down. Multi-device audio (one or the other, not simultaneous) tends to work without hitches or errant pausing. The earcups are warm and cozy. To a certain taste, it looks great, and you can even add custom 3D-printed shields to the sides if you‚Äôre really into the fashion aspect. It folds up nicely and comes with a lovely hard case that you can chuck into your bag without a worry. There‚Äôs even a &lt;a href=&quot;http://amzn.to/2DxowRt&quot;&gt;boom mic&lt;/a&gt; you can separately buy that turns it into a gaming headset. (This one is compatible with other headphones that have the 3.5mm port in the same spot, but it‚Äôs nice to have the designs match.) Everything about these headphones‚Äîsound signature, comfort, design, features‚Äîseems tailored to making you cozy and comfortable, which is precisely what you want out of a piece of gear that you expect to wear for hours every day and use for many different functions.&lt;/p&gt;

&lt;p&gt;There are several additional flaws I‚Äôve discovered with the Crossfade in my most recent testing, though none of them are dealbreakers. On a nitpicky level, the latency in Bluetooth mode appears to be on the order of 180ms vs. 150ms for the PX. When this can‚Äôt be compensated, the former is a lot more noticeable during movies than the latter. The included SpeakEasy cable is nice, but I just couldn‚Äôt get the microphone to show up in Bootcamp. (Every other TRRS cable I tried worked just fine, and the SpeakEasy cable worked perfectly in macOS.) The Crossfade also doesn‚Äôt do nearly as well as the PX in binaural recordings. I suppose this is on account of the smaller soundstage, reduced instrument separation, and unusual tuning: the illusion falters a little when the original sound can‚Äôt be reproduced precisely. This also makes the Crossfade much less effective for spatial positioning than the PX in games. You can still pinpoint your enemies in a game of CS:GO, but the PX just feels categorically more sharp and precise in that regard. (I‚Äôm not sure if this is just a frequency illusion or if the game is doing some binaural processing under the hood. In Overwatch, the effect isn‚Äôt nearly as pronounced.) I don‚Äôt have enough headphone experience to say with certainty, but I believe these drawbacks might be caused by a somewhat dampened treble response in the Crossfade. Instruments lack a bit of definition in the upper registers, though not to any degree that will ruin your favorite songs.&lt;/p&gt;

&lt;p&gt;I think what I‚Äôve learned from this arduous journey is that there really is no perfect headphone. Much as we like to pretend otherwise, neutrality is not the be-all, end-all of audio. Some music, especially modern music, simply deflates when the tuning is flat. If you‚Äôre a genre omnivore, this is a problem when it comes to picking a single pair of headphones and sticking to them faithfully until your next big purchase. Perhaps this is the first step towards having one of those crazy-person headphone walls!&lt;/p&gt;

&lt;p&gt;On the Bluetooth horizon, we have the Beyerdynamic Aventho and Amiron Wireless, the NAD HP70, the PSB M4U 8, and the Audio-Technica ANC700BT. In a year, I‚Äôd love to give these new contenders a listen and revisit my choice. The PX really is a great headphone, but it feels like it needs quite a bit more work and polish in order to excel as a Bluetooth all-arounder.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;I even wrote an open source iOS app to help me with this: &lt;a href=&quot;https://github.com/archagon/ios-bluetooth-headphone-unsleeper&quot;&gt;ios-bluetooth-headphone-unsleeper&lt;/a&gt;. All it does is play a near-silent audio stream when you hit the switch, forcing the MDR-1RBT to stay on while the app is running.¬†&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Incidentally, the rose gold model costs $20 more than the others and happens to be the only one that supports the high resolution aptX codec. Why? I have no idea!¬†&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 08 Dec 2017 01:38:07 -0800</pubDate>
        <link>http://archagon.net/blog/2017/12/08/bluetooth-headphone-sound-off/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2017/12/08/bluetooth-headphone-sound-off/</guid>
        
        
        <category>reviews</category>
        
      </item>
    
      <item>
        <title>MX Master Continued: Mouse Latency Measurements</title>
        <description>&lt;p&gt;In the course of doing latency testing for &lt;a href=&quot;/blog/2017/05/22/almost-winning-the-wireless-mouse-game-logitech-mx-master/&quot;&gt;my previous article&lt;/a&gt; on the Logitech MX Master, I discovered a couple of flaws in my helper app, and I also realized that I should have probably recorded a few more sample points. So now, as a followup, I have devised a better testing methodology and run a full suite of tests. Unfortunately, with this new data in hand, I must now retract my original recommendation. The Master is still a good mouse for the average user, but its wireless performance is just too unreliable for precise gaming or Bluetooth use.&lt;/p&gt;

&lt;p&gt;If you‚Äôre looking for a great all-arounder, I would instead give my highest recommendation to the &lt;a href=&quot;http://amzn.to/2uDAeF2&quot;&gt;G403 Wireless&lt;/a&gt;, which I‚Äôve been happily using for several months with zero issues. While this mouse does require a dongle and only has a tenth of the Master‚Äôs battery life, its best-in-class performance, non-existent latency, svelte form factor, and incredible clicky side buttons more than make up for these downsides. Better yet, you can routinely find it on sale for $50 or lower on Amazon and at Best Buy. I‚Äôll try to post a fuller account sometime in the near future.&lt;/p&gt;

&lt;p&gt;In the meantime, here are the new test results for the MX Master, G602, and MX 518.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;data&quot;&gt;Data&lt;/h2&gt;

&lt;div class=&quot;image-gallery&quot;&gt;
&lt;h1&gt;MX 518&lt;/h1&gt;
&lt;div class=&quot;image-gallery-two-column&quot;&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mx518-left.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mx518-right.png&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;image-gallery&quot;&gt;
&lt;h1&gt;G602&lt;/h1&gt;
&lt;div class=&quot;image-gallery-two-column&quot;&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/g602-left.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/g602-left-2.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/g602-right.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/g602-right-2.png&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;image-gallery&quot;&gt;
&lt;h1&gt;MX Master&lt;/h1&gt;
&lt;div class=&quot;image-gallery-two-column&quot;&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mxmaster-left.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mxmaster-left-extended.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mxmaster-left-charging.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mxmaster-right.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mxmaster-right-2.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mxmaster-right-extended.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mxmaster-right-charged.png&quot; /&gt;&lt;/div&gt;
&lt;div style=&quot;max-width: 40rem&quot;&gt;&lt;img src=&quot;/images/mx-master/charts/mxmaster-bluetooth.png&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Note: I also ran a few tests in &lt;a href=&quot;http://www.overclock.net/t/1535687/mousetester-software&quot;&gt;microe‚Äôs MouseTester&lt;/a&gt; to compare the motion graphs of the three mice, but they looked pretty much the same to my eye. So I think the difference in feel of these mice is mostly due to latency and, to a lesser degree, weight and shape.&lt;/p&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;p&gt;Since last time, my helper app has been revised to explicitly update the left label every frame instead of implicitly relying on AppKit‚Äôs timing. I‚Äôve also switched my scrubbing program from VLC to QuickTime, as the latter additionally allows you to step backwards frame-by-frame. (Extremely useful if you happen to overshoot the mouse movement point!) Combined with a Numbers spreadsheet for processing, the sampling process took maybe a minute or two per data point.&lt;/p&gt;

&lt;p&gt;In every test, the cursor begins moving two screen frames ahead of the right label, so there‚Äôs on the order of two frames of extra latency (~33ms) in these measurements. Subtracting this amount from the recorded values will get you closer to the absolute latency of the mouse. But again, if you‚Äôre only comparing these numbers to each other (which I am) then the extra latency doesn‚Äôt really matter. You may as well just subtract the latency of the wired mouse since that‚Äôs as close as you‚Äôre going to get to zero.&lt;/p&gt;

&lt;p&gt;I ended up testing both USB ports on my Macbook because I‚Äôve had USB peripherals behave differently depending on which side they used. Not sure if the resulting variance is due to the ports themselves (power issues?) or simply reception.&lt;/p&gt;

&lt;p&gt;OK, on to the results!&lt;/p&gt;

&lt;p&gt;As the wired ‚Äúcontrol‚Äù, the MX 518 showed 33ms of average latency with the left USB port and 38ms with the right. Theoretically, none of the other results should have surpassed this value ‚Äî though the G602 stood a slight chance with its higher 500Hz polling rate.&lt;/p&gt;

&lt;p&gt;During its worst run, with the adaptor plugged in to the left USB port, the MX Master had 62ms of average latency, or 30ms more than the wired MX 518. However, every subsequent run resulted in significantly quicker average values. Two more tests with the left USB port ‚Äî one using a USB extender and one while simultaneously charging ‚Äî gave me a better average of 54ms for both. And with the right port, things got better still, with two runs sporting an average of 45ms (including dips down to the thirties) and the other two responding at a respectable 47ms and 49ms on average.&lt;/p&gt;

&lt;p&gt;With Bluetooth, the Master responded at an average of 65ms. So my conclusion in the original article was overly optimistic: there can be up to 20ms difference between Bluetooth and the USB adaptor.&lt;/p&gt;

&lt;p&gt;During its first trial, the G602 reported with an astounding 34ms of latency ‚Äî just 1ms more than wired! However, each subsequent run (including one with the very same setup as the first) only gave me 50ms on average.&lt;/p&gt;

&lt;p&gt;What can we conclude from these results?&lt;/p&gt;

&lt;p&gt;The main issue with the Unifying receiver seems to be that the latency is rather inconsistent and spiky. With the G602, regardless of whether it‚Äôs averaging 35ms or 50ms, the latency curve is always baby-butt smooth. In contrast, the Unifying receiver needs to be pampered to attain optimal performance.&lt;/p&gt;

&lt;p&gt;It seems that a variety of minute factors can drastically affect the latency of these mice, ranging from adaptor placement to USB port selection. The G602 might have a lower baseline than the MX Master, but the Master can still come within a respectable 10ms of that baseline. And in any case, it seems the G602 can‚Äôt be guaranteed to perform in this range. I wish I knew what caused the G602 to spike up to 50ms for all its subsequent trials!&lt;/p&gt;

&lt;p&gt;The first sample point in several of the MX Master runs was much higher than the rest. (A few are omitted since they‚Äôre not representative of the average running latency.) I assume this is the result of some energy-saving feature. Doesn‚Äôt really matter for games since you‚Äôre constantly moving the mouse anyway.&lt;/p&gt;

&lt;p&gt;The battery level in the MX Master doesn‚Äôt seem to have much of an effect on performance.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I spent another week with the MX Master in daily use, and unfortunately, I had to concede the results: the Master was noticeably 1-2 frames behind my other mice. Frankly, I was really surprised by how much this affected gameplay. With the MX Master in CS:GO and Overwatch, I always felt like I was a little drunk. My cursor would constantly overshoot and I would miss many of my flick shots. Hot-swapping the G602 brought an instant wave of relief: my sense of immersion immediately returned and I felt like I could aim almost twice as well. (Maybe this is what happens when you hammer your synapses with FPS gameplay over the course of two decades!) I tried to account for the placebo effect as best as I could without doing a completely blind test, but I could easily see my performance suffer even when running around and shooting bots in the Overwatch training area.&lt;/p&gt;

&lt;p&gt;I followed up with a few more informal measurements, and all of them continued to show the MX Master trailing the G602 in performance ‚Äî mostly on account of the lag spikes, but sometimes pretty drastically even on average. I also discovered that Bluetooth performance was quite unreliable on the Mac side, frequently dropping off or disconnecting altogether and requiring a hard mouse reset. Given that the Master was intended as an all-arounder for both gaming and Bluetooth use, this was a huge disappointment. It clearly wasn‚Äôt up to snuff in either respect, and I decided to send it back.&lt;/p&gt;

&lt;p&gt;As a last-ditch stop in my mousing hunt, I visited my local Best Buy to take a gander at Logitech‚Äôs gaming mice. The lineup had all the problems I was expecting: tacky designs, an overabundance of buttons, horrible tilt-click scroll wheels‚Ä¶ except for the lone &lt;a href=&quot;http://amzn.to/2uDAeF2&quot;&gt;G403&lt;/a&gt;. As soon as I put this mouse in my hand, I knew it was the one. This was the only wireless gaming mouse that had just the five standard buttons in a classic body. Its scroll wheel was the normal kind, not the mushy tilt-wheel kind. Its internal hardware was the same as that of the possibly-best-in-class &lt;a href=&quot;http://amzn.to/2hHjvj4&quot;&gt;G900&lt;/a&gt;. And most surprising of all, its side buttons were actually &lt;em&gt;clicky!&lt;/em&gt; (I know it‚Äôs such a small detail, but I hadn‚Äôt used a new mouse with clicky side buttons in years.) Before me was a phenomenal gaming mouse in the guise of a business accessory, evocative of the classic Microsoft Intellimouse ‚Äî and USB dongle or not, this was exactly the mix I was searching for. I took it home and haven‚Äôt had a single complaint in the three months since. (Bonus: it fits snugly in my &lt;a href=&quot;http://amzn.to/2qJl3LO&quot;&gt;MX Master Hermitshell case&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;The Master is 80% of the way to being an ideal all-arounder, but sadly, it‚Äôs killed for power users by inconsistent performance.&lt;/p&gt;

</description>
        <pubDate>Wed, 24 May 2017 21:55:52 -0700</pubDate>
        <link>http://archagon.net/blog/2017/05/24/mx-master-continued-mouse-latency-measurements/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2017/05/24/mx-master-continued-mouse-latency-measurements/</guid>
        
        
        <category>reviews</category>
        
      </item>
    
      <item>
        <title>(Almost) Winning the Wireless Mouse Game: Logitech MX Master</title>
        <description>&lt;div&gt;&lt;img src=&quot;/images/mx-master/master-top.jpg&quot; /&gt;&lt;/div&gt;

&lt;div class=&quot;notification&quot;&gt;&lt;span&gt;&lt;strong&gt;Update:&lt;/strong&gt; I added a &lt;a href=&quot;/blog/2017/05/24/mx-master-continued-mouse-latency-measurements/&quot;&gt;companion article&lt;/a&gt; with latency graphs for all three of my mice. I have also revised my conclusion to no longer recommend the MX Master for Bluetooth use or use cases sensitive to latency.&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;We all know that Bluetooth has an abundance of flaws, ranging from frustrating latency to arcane pairing rituals. By many measures, it still feels like a technology stuck in the early 90‚Äôs. And yet, once you‚Äôve experienced the freedom of going wireless, it‚Äôs very hard to go back to the old ways. Reaching to unplug your headphones when leaving your desk, only to realize that you can simply walk away? Bliss!&lt;/p&gt;

&lt;p&gt;For several years, I‚Äôve been on the lookout for a Bluetooth mouse that could also be used for non-casual gaming. At minimum, the mouse needed to be on par with my trusty &lt;a href=&quot;http://amzn.to/2qbhqeY&quot;&gt;MX 518&lt;/a&gt; at 1600 DPI and have little to no latency. Unfortunately, the vast majority of reputable Bluetooth mice maxed out at around 1000 DPI and had a reputation for being a bit laggy. The &lt;a href=&quot;http://amzn.to/2qbb8fi&quot;&gt;Razer Orochi&lt;/a&gt; was one of the few models that supported high DPI over Bluetooth, but it was a cramped little thing that felt rather unpleasant to use.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;There were a few wireless gaming mice that used proprietary USB adaptors to improve performance, including my latest mouse, the &lt;a href=&quot;http://amzn.to/2rb0idv&quot;&gt;Logitech G602&lt;/a&gt;. This model did what it said on the tin, but despite the praise it garnered from gamers, I ended up somewhat disappointed with it. The USB receiver was pretty weak and would routinely cut out if you moved more than a few feet from the port. The fact that you had to use the receiver at all meant that you still plugged up one of your USB ports, causing significant setbacks with a two-port Macbook. (Hubs helped, but not while trying to use two USB-powered hard drives at the same time.) I was also unimpressed with the design and build in general: the body creaked in several prominent areas (including under the main buttons), the side buttons were unpleasant and hard to press, and the scroll wheel felt a bit mushy. After using it for about a year, I just ended up switching back to the MX 518.&lt;/p&gt;

&lt;p&gt;Recently, I‚Äôve been working more in caf√©s, and the endless dance of the wire once again started to irk me. At first, I thought about getting an extra, cheapie Bluetooth mouse for use on the go, but then my ‚Äúoptimization sense‚Äù kicked in. It‚Äôs been 4 years since the G602, and technology moves quickly. Surely, I thought, there now &lt;em&gt;had&lt;/em&gt; to be a mouse that could solve my wireless needs and also work for gaming! Besides, I deeply enjoyed finding tools for my life that could optimally solve multiple problems at once.&lt;/p&gt;

&lt;p&gt;Sure enough, Logitech had two new headlining models in the Bluetooth category: the &lt;a href=&quot;http://amzn.to/2qbiPSM&quot;&gt;MX Master&lt;/a&gt; and &lt;a href=&quot;http://amzn.to/2rb6SRe&quot;&gt;MX Anywhere 2&lt;/a&gt;. These were clearly top-shelf devices, sporting sleek designs, several color choices, and Logitech‚Äôs free-spinning MicroGear Precision scroll wheel. Interestingly, they also reached 1600 DPI and shared the ability to connect to Bluetooth &lt;em&gt;or&lt;/em&gt; a Logitech Unifying USB receiver at the user‚Äôs discretion. &lt;span class=&quot;update&quot;&gt;(Update: the newly-released &lt;a href=&quot;http://amzn.to/2vlQkFe&quot;&gt;MX Master 2S&lt;/a&gt; goes up to 4000 DPI.)&lt;/span&gt; Based on my experience with the G602, I figured Bluetooth might be handy for everyday use while the USB receiver would work well for lag-free gaming. Were these the first Bluetooth mice that could actually fit the bill? I had to give them a spin!&lt;/p&gt;

&lt;p&gt;Eventually, I got my hands on both models and did some side-by-side testing. The MX Master was love at first touch, fixing almost everything I hated about the G602 and even adding a few extra features to win me over. Meanwhile, the MX Anywhere 2 was marred by one awful design decision and just felt too small for ergonomic comfort. &lt;span class=&quot;update&quot;&gt;(Update: unfortunately, I had to eventually give up the Master due to &lt;a href=&quot;/blog/2017/05/24/mx-master-continued-mouse-latency-measurements/&quot;&gt;latency and connectivity issues&lt;/a&gt;. But the hardware remains spectacular!)&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Below is a discussion of several aspects of these mice that haven‚Äôt been covered in most reviews, including handfeel, clickiness, gaming use, and latency measurements.&lt;/p&gt;

&lt;h2 id=&quot;mx-anywhere-2&quot;&gt;&lt;a href=&quot;http://amzn.to/2rb6SRe&quot;&gt;MX Anywhere 2&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The MX Anywhere 2 is a cute little mouse. Some reviewers have been comfortable switching to it as their primary work mouse, but in my testing, I found it just a bit too small. This is definitely a travel mouse in form and function. The weight, however, is great for usability, as it‚Äôs just hefty enough to stick a little to the mousepad without losing its high mobility.&lt;/p&gt;

&lt;p&gt;Click-wise, the two main buttons feel pretty good while the rest aren‚Äôt particularly notable. I was happy that the side navigation buttons were fairly normal sized compared to the scrunched side buttons on the Master. The coating feels grippy but maybe a tiny bit less premium than I‚Äôd hoped.&lt;/p&gt;

&lt;div class=&quot;caption&quot;&gt;
&lt;video controls=&quot;&quot; width=&quot;100%&quot; poster=&quot;/images/mx-master/anywhere-clicks.jpg&quot;&gt;
	&lt;source src=&quot;/images/mx-master/anywhere-clicks.mp4&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Clicking every button on the MX Anywhere 2.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In case you‚Äôre not aware, many Logitech mice now feature a scroll wheel that can also be clicked side-to-side. In reviews of Logitech mice, I often see praise for this sideways-clicking mouse wheel, and some go as far as to call it a ‚Äúpremium feature‚Äù. But I think I‚Äôve come to realize that most people just don‚Äôt use their middle click all that much. Me? I‚Äôm an compulsive middle-clicker. I use that button for everything. New links. Closing tabs. Panning. Reloading. In fact, it‚Äôs possibly the second most important button on my mouse! Unfortunately, sideways-click cripples this button thoroughly, making it rattle from side to side with every minor push.&lt;/p&gt;

&lt;p&gt;If I otherwise loved the Anywhere, I figured I could get accustomed to this annoying hardware quirk. But Logitech &lt;em&gt;really&lt;/em&gt; screwed up the wheel here. Incomprehensibly, there‚Äôs no middle click; instead, you get a tiny button right below the wheel that could be rebound to this function. (By default, it serves as the ‚Äúgesture‚Äù button, which lets you show Expos√© and whatnot.) The wheel itself, when depressed, &lt;em&gt;mechanically&lt;/em&gt; toggles between traditional ratchet and free spin modes for scrolling, resulting in a heavy, chunky ‚Äúclunk‚Äù that feels like you‚Äôre squishing something deep inside the mouse‚Äôs guts. Is there any other Logitech mouse that behaves this way? The middle-click has been a staple feature on mice since the 70‚Äôs, so why is changing scroll wheel modes suddenly more important? Considered together with the usual sideways-click complaints, this scroll wheel disappointed me in practically every respect.&lt;/p&gt;

&lt;div class=&quot;caption&quot;&gt;
&lt;video controls=&quot;&quot; width=&quot;100%&quot; poster=&quot;/images/mx-master/anywhere-rattle.jpg&quot;&gt;
	&lt;source src=&quot;/images/mx-master/anywhere-rattle.mp4&quot; type=&quot;video/mp4&quot; /&gt;
	Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;A demonstration of the janky scroll wheel.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;For a while, I tried rebinding the square button and sideways-click buttons to middle click. It felt OK‚Ä¶ in the sense that I could probably get used to it over time. But I knew I‚Äôd never be happy with this compromise, and it‚Äôs what ultimately pushed me to give the Master a try.&lt;/p&gt;

&lt;h2 id=&quot;mx-master&quot;&gt;&lt;a href=&quot;http://amzn.to/2qbiPSM&quot;&gt;MX Master&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;I‚Äôm delighted that tech companies have started to inject fashion into even their most pragmatic products. Both MX models come in black, navy, and white (‚Äústone‚Äù). I liked the idea of white in honor of my old favorite &lt;a href=&quot;http://amzn.to/2rKpWCQ&quot;&gt;Microsoft Intellimouse&lt;/a&gt;, and it‚Äôs the color I chose for my initial Anywhere purchase. But seeing it in person didn‚Äôt impress me as much as I had hoped. It was attractive but a little business casual, and in any case, it didn‚Äôt mesh with my recent black &lt;a href=&quot;http://amzn.to/2rbgpb0&quot;&gt;Logitech K380&lt;/a&gt; keyboard purchase. (Peripheral matching, whaddaboutit?) So I decided to seek a different color with the MX Master.&lt;/p&gt;

&lt;p&gt;Between the other two options, navy looked svelte in pictures while black appeared to have some ugly beige accents that screamed ‚ÄúHP peripheral‚Äù. And yet‚Ä¶ Amazon Prime Now had a promotion going where I could chip $10 off the purchase of just the black model, bringing the price down to a mere $50 and delivering it the very same day. Meanwhile, navy would cost me close to $70 and arrive several days later! Friends, I must admit I did not pass the marshmallow test on that day.&lt;/p&gt;

&lt;p&gt;Fortunately, this turned out to be a great decision: the black model looks fantastic in person. Despite what the photos might show, the accents are actually not beige at all but more along the lines of Apple‚Äôs space gray, perfectly complementing the darker matte gray of the body. In addition, the buttons have a slightly different coating from the rest of the mouse, giving them a pleasant sheen under certain lighting conditions.&lt;/p&gt;

&lt;p&gt;As most reviews have stated, the ergonomic comfort of this mouse is close to perfect. You lay your hand down and it feels like it was sculpted just for you. What‚Äôs more, the main buttons feel incredible to click ‚Äî perhaps more so than any other mouse I‚Äôve used! Seriously, I can‚Äôt stop clicking these buttons.&lt;/p&gt;

&lt;div class=&quot;caption&quot;&gt;
&lt;video controls=&quot;&quot; width=&quot;100%&quot; poster=&quot;/images/mx-master/master-clicks.jpg&quot;&gt;
	&lt;source src=&quot;/images/mx-master/master-clicks.mp4&quot; type=&quot;video/mp4&quot; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Clicking every button on the MX Master.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;The Master‚Äôs sideclick-less wheel intrigued me when I first saw it. Most Logitech mice either feature sideclicking and free spinning together, or otherwise just throw in a plain old scroll wheel and call it a day. This was the first mouse I found which omitted sideways-clicking while still retaining the free spin mode, a feature I thought might come in handy as a substitute for the trackpad‚Äôs inertial scrolling. Prior to handling the Master, I hoped this setup might finally allow me to have an uncompromised middle click while still benefitting from Logitech‚Äôs fancy scroll wheel tech. And‚Ä¶ that‚Äôs exactly what happened! The middle click on this mouse feels excellent, to the point where it‚Äôs very nearly as pleasing as the main buttons. (There‚Äôs a slight bit of wobble before the click is triggered, but I don‚Äôt think that can be helped on account of the complex mechanism.)&lt;/p&gt;

&lt;p&gt;There‚Äôs a subtle issue I noticed with the middle click that might be worth mentioning. When Smooth Scrolling is enabled in Logitech Options, if you click the mouse wheel and then immediately start scrolling, your scroll won‚Äôt actually register until several seconds later. This happens in both Windows and OS X. I assume this is some sort of hardware safeguard to prevent accidental scroll triggering, but it‚Äôs noticeable on occasion.&lt;/p&gt;

&lt;p&gt;My main issue with the build is the very poor layout of the back and forward buttons. I use these buttons quite frequently for navigation, and I miss the old Intellimouse days when the side buttons were enormous and clicked just as well as the main buttons. Here? The buttons are quiet and super annoying to differentiate. Why couldn‚Äôt they have spread them out just a little bit? The horizontal scroll wheel feels nice, but I don‚Äôt see myself getting much mileage out of it, especially now that I‚Äôve learned you can simply Shift-scroll in OS X to get native horizontal scrolling.&lt;/p&gt;

&lt;p&gt;There‚Äôs one hidden button on this mouse: the ‚Äúgesture‚Äù button, which can be activated by smashing down on the mesh pad next to your thumb. Unlike the other buttons, this button feels mushy and difficult to press, similar to those membrane buttons you find on cheap remotes. I guess they had to design it this way to avoid accidental clicks, but I wish they thought of something else or eliminated it altogether. I‚Äôve been trying to use it as a surrogate back button instead of the tiny default one, but it‚Äôs not particularly pleasant or responsive to use. Oh well.&lt;/p&gt;

&lt;p&gt;Weight-wise, this mouse is pretty hefty, but not overbearing. I‚Äôll have to get used to the inertia compared to my MX 518, which barely feels like it has any weight at all.&lt;/p&gt;

&lt;div class=&quot;caption&quot;&gt;
&lt;video controls=&quot;&quot; width=&quot;100%&quot; poster=&quot;/images/mx-master/master-use.jpg&quot;&gt;
	&lt;source src=&quot;/images/mx-master/master-use.mp4&quot; type=&quot;video/mp4&quot; /&gt;
	Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;The MX Master in regular use.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;I was worried when I was first looking at this mouse that it would just be a minor iteration on the G602, but these fears have been unfounded. The Master fixes every problem I had with the G602 (aside from perhaps the weight) and adds a bunch of great features to boot. I feel immediately at home with this device.&lt;/p&gt;

&lt;h2 id=&quot;common-issues&quot;&gt;Common Issues&lt;/h2&gt;

&lt;p&gt;There are a few issues common to both mice that should be addressed.&lt;/p&gt;

&lt;p&gt;Both of these mice can be used while charging, but they don‚Äôt register as USB devices even when directly connected to your computer. You still have to use them via Bluetooth or the Unifying receiver, which means that there‚Äôs no zero-latency mode. &lt;span class=&quot;deprecated&quot;&gt;In practice, as I demonstrate below, the mice are pretty darn close to lag-free. Most people didn‚Äôt consider wireless-only to be an issue with the G602, and I don‚Äôt see it as an issue here either. (The feature would have been appreciated, though.)&lt;/span&gt; &lt;span class=&quot;update&quot;&gt;Update: as it turns out, the latency is still an issue for gaming. Read on below.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Second, there‚Äôs some scrolling weirdness, which seems to be a mix of OS issues as well as user habits. On the OS side, when smooth scrolling is enabled in Logitech Options, it doesn‚Äôt always seem to work right. Fairly frequently, you get some weird acceleration or momentum before things get going. (Both OS X and Windows have this issue, though manifested in different ways.) Most unfortunately, the wheel in free spin mode doesn‚Äôt seem to have a 1:1 mapping to page scrolling, which feels a lot less physically correct than using the trackpad. I think I could get used to this behavior, but even my ancient MX 518‚Äôs scrolling felt more natural. In terms of habits, if you‚Äôre used to trackpad momentum scrolling in OS X, you‚Äôll be surprised when you‚Äôre free-scrolling a page and then find other pages continuing to scroll when switching windows! It might take a while to internalize the fact that the mouse has a mechanical component that needs to be stopped before switching tasks.&lt;/p&gt;

&lt;p&gt;These mice worry me a little with their reliance on mechanical trickery. On the MX Master, whenever the lever (or whatever it is) stops the wheel when switching to ratchet mode, I can feel the entire mouse shudder slightly. At least one user &lt;a href=&quot;https://toemat.com/logitech-mx-master-fix/&quot;&gt;has already demonstrated&lt;/a&gt; that this part can get stuck. (This has apparently been &lt;a href=&quot;https://toemat.com/logitech-mx-master-fix/#comment-3138781165&quot;&gt;quietly fixed by Logitech&lt;/a&gt;.) How long will it take for the mechanism to break or wear out? Fortunately, Logitech has an exceptional warranty department, so I don‚Äôt doubt that they‚Äôll send me a replacement if anything bad happens. Still, I don‚Äôt like the idea of having to pamper my mouse.&lt;/p&gt;

&lt;p&gt;The Unifying receiver, unfortunately, tends to have a very short range if there‚Äôs any sort of interference nearby. (For example, I can hardly move the mouse a foot away if a Thunderbolt cable is attached to the port next to the receiver. Or maybe it‚Äôs the eGPU itself?) As a result, I‚Äôve resorted to plugging the receiver into a USB extender. With Bluetooth, this is not an issue at all, so it comes up fairly infrequently.&lt;/p&gt;

&lt;h2 id=&quot;latency&quot;&gt;Latency&lt;/h2&gt;

&lt;p&gt;Now, for my personal dealbreaker with wireless mice: latency. I had a bit of a misconception when I first set my eyes on these two MX models. My assumption was that the Unifying receiver was identical to the one used by my G602, meaning that the adaptor would be highly optimized for reduced latency. But &lt;a href=&quot;https://www.reddit.com/r/LogitechG/comments/2vz5ie/can_i_use_the_same_usb_reciever_with_the_g602/cookz42/&quot;&gt;according to a Logitech representative&lt;/a&gt;, only Logitech‚Äôs gaming peripherals use the improved, custom-designed adaptor to get the ‚Äúprecision report rate‚Äù, whereas Unifying technology is less fancy and reserved for use with the business lineup. My question was: did ‚Äúprecision report rate‚Äù only refer to the polling rate, or were the gaming adaptors additionally less laggy? In other words, was I missing out with my Unifying receiver?&lt;/p&gt;

&lt;p&gt;I knew I wouldn‚Äôt have peace of mind until I had solid numbers, so I decided to measure the latency myself. There were two data points I needed to capture: the moment the mouse started moving, and the subsequent moment that the computer registered mouse activity. Both actions had to be on the same clock. My iPhone‚Äôs camera could record at 240 FPS, so precision wasn‚Äôt an issue; the problem was that my laptop display only refreshed at 60 Hz, meaning that I couldn‚Äôt rely on a recording of the screen alone to figure out how fast the mouse signal was going through. (There was only one display frame for every four video frames.)&lt;/p&gt;

&lt;p&gt;I ended up writing a small, single-window Mac application to help me along. On the left side, the window has a running millisecond timer, refreshing at the exact frequency of the display. This gave me the precise timestamp of each display cycle. (Well ‚Äî with a possible delta of 1 frame or ~17ms, depending on how the labels spaced out their updates under the hood. But I was only interested in relative latencies between the mice, not the absolute latency, so the only important detail was that this offset was consistent.) The app also captured the timestamp for the precise moment mouse movement was first detected. This was displayed in a label on the right side. Both timestamps were generated using the same time function,¬†&lt;code class=&quot;highlighter-rouge&quot;&gt;CACurrentMediaTime&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next, I placed a mousepad next to my display along with a small box to evenly and consistently push the mouse along. I set up my phone to show both the laptop display (with the timer app running) and a side view of the mouse and box contact point. I filmed three trials each of the MX 518, MX Master with the USB adaptor, and MX Master in Bluetooth mode, resetting the righthand timer between each trial.&lt;/p&gt;

&lt;p&gt;Finally, I went through the videos frame-by-frame in VLC. (The ‚Äòe‚Äô key: highly convenient!) The left timestamp was used to determine the exact moment when the mouse started moving. If the movement occurred between two timestamps, I could simply interpolate the precise value based on which intermediary frame out of four I landed on. After that, I noted the righthand (‚Äúmouse was detected‚Äù) timestamp and did a bit of math to arrive at the latency value. Perhaps not a perfect system, but as accurate as I could manage with the tools I had at hand!&lt;/p&gt;

&lt;div class=&quot;full-width&quot;&gt;&lt;img src=&quot;/images/mx-master/slide2.gif&quot; /&gt;&lt;/div&gt;

&lt;p&gt;&lt;span class=&quot;update&quot;&gt;Update: since publishing this article, &lt;a href=&quot;/blog/2017/05/24/mx-master-continued-mouse-latency-measurements/&quot;&gt;I have run a more thorough and accurate suite of tests on all three of my mice&lt;/a&gt;. The conclusions are a bit different from the initial ones greyed out below, namely concerning Bluetooth accuracy (notably worse than originally tested) and MX Master latency characteristics (spiky and 10-20ms slower than wired).&lt;/span&gt;&lt;/p&gt;

&lt;p class=&quot;deprecated&quot;&gt;&lt;span&gt;The results were: &lt;strong&gt;55ms/58ms/50ms&lt;/strong&gt; for the wired MX 518; &lt;strong&gt;63ms/74ms/51ms&lt;/strong&gt; for the MX Master in USB receiver mode; and &lt;strong&gt;70ms/58ms/68ms&lt;/strong&gt; for the MX Master in Bluetooth mode. (Keep in mind that these values were not a measure of absolute latency and were only meant to be compared to each other, since the test did not deduct OS latency, monitor latency, etc.)&lt;/span&gt;&lt;/p&gt;

&lt;p class=&quot;deprecated&quot;&gt;&lt;span&gt;To my great surprise, not only was wireless latency very close to wired (~55ms vs. ~65ms), but &lt;em&gt;Bluetooth was practically as performant as the USB receiver!&lt;/em&gt; I don‚Äôt know how Logitech managed it, but somehow the Bluetooth performance of these mice is nearly flawless, to the point where perhaps the dongle is basically unnecessary. (Except for edge cases like BIOS use.) You could make the argument that wireless performance is less consistent than wired, but I‚Äôd need to do more tests to figure this out. (And it‚Äôs probably more effort than it‚Äôs worth.)&lt;/span&gt;&lt;/p&gt;

&lt;p class=&quot;deprecated&quot;&gt;&lt;span&gt;So is 10ms of lag a dealbreaker when it comes to precision gaming? I strongly suspect it won‚Äôt be noticeable ‚Äî especially given how much latency already exists in the long chain from mouse to display ‚Äî but I‚Äôd love to see some empirical evidence backing this up.&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;gaming&quot;&gt;Gaming&lt;/h2&gt;

&lt;p&gt;There‚Äôs some mild consternation for these two MX models when it comes to gaming. Whenever people ask, some enthusiast always shows up and levies the following grievances against them:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;They have no wired mode, and thus always feature some latency.&lt;/li&gt;
  &lt;li&gt;They have built-in acceleration and angle snapping.&lt;/li&gt;
  &lt;li&gt;They only poll at 125 Hz.&lt;/li&gt;
  &lt;li&gt;They only go up to 1600 DPI. &lt;span class=&quot;update&quot;&gt;(Update: the newly-released &lt;a href=&quot;http://amzn.to/2vlQkFe&quot;&gt;MX Master 2S&lt;/a&gt; goes up to 4000 DPI.)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In contrast, they suggest, Razer and Logitech themselves make gaming-tailored wireless mice (the &lt;a href=&quot;http://amzn.to/2rvezS9&quot;&gt;Logitech G900&lt;/a&gt;, or the new &lt;a href=&quot;https://www.razerzone.com/gaming-mice/razer-lancehead&quot;&gt;Razer Lancehead&lt;/a&gt;) that go up to 12000 DPI at 1000 Hz and use proprietary receivers for optimal performance. All technically true! However, the mouse I‚Äôve loved the longest, and gamed the most with, has been my trusty MX 518, a classic model popular with gamers even today. &lt;a href=&quot;http://www.pcgamer.com/gaming-mouse-myths-busted/&quot;&gt;And it turns out&lt;/a&gt; that this mouse &lt;em&gt;also&lt;/em&gt; has built-in angle snapping, &lt;em&gt;also&lt;/em&gt; only goes up to 1600 DPI, and &lt;em&gt;also&lt;/em&gt; polls at a mere 125 Hz. The horror!&lt;/p&gt;

&lt;p&gt;In practice, none of these quirks are dealbreakers. 1600 DPI is more than enough for the vast, vast majority of people; it was a high standard a decade ago and accuracy-per-inch demands in humans have not suddenly spiked during that time. (DPI is more of an issue with enormous monitors and insane resolutions, but it doesn‚Äôt matter for my use case.) Same goes for 125Hz polling, which is effectively 2x the refresh rate of most monitors. On top of that, you‚Äôll get about 30x less battery life (30 hours vs. 40 days!)  with gaming wireless mice ‚Äî not to mention losing all the benefits of Bluetooth. Unless you‚Äôre a pro, I don‚Äôt think it‚Äôs nearly worth the tradeoff.&lt;/p&gt;

&lt;p&gt;However‚Ä¶ I have to admit that something about these mice definitely feels off when playing FPS. Side-by-side with the MX 518, the difference is immediately noticeable. With the 518, I feel like I‚Äôm directly inside the character‚Äôs head. With the Master, there‚Äôs a bit of a ‚Äúcockpit effect‚Äù, or a very subtle sense that my movements aren‚Äôt perfectly mapped to the camera. Accordingly, things like rapid 180 degree turns and flick shots feel more hesitant and unnatural. &lt;span class=&quot;deprecated&quot;&gt;For a while, I assumed this was due to wireless latency, but my experiments showed that this was unlikely to be the case. (Besides, my setup was a mess and there was plenty of latency coursing through the system already.) I also thought it might be the weight of the Master, but no dice: the Anywhere had the same issue at half the weight. So my working hypothesis is that this issue is caused by some subtle differences in mapping of mouse movement between the Master and the 518, meaning that I‚Äôll have to reprogram my brain a little before I‚Äôm fully comfortable with it. (I think I could also customize this curve in software using various third-party tools, but this might be too finicky even for my tastes.) I actually remember having this exact response to the G602, so maybe that 10ms does make a critical difference in FPS gameplay after all? Or perhaps the G602 shares its motion curve with the Master? Who knows!&lt;/span&gt; &lt;span class=&quot;update&quot;&gt;Update: after using the Master for another week and &lt;a href=&quot;/blog/2017/05/24/mx-master-continued-mouse-latency-measurements/&quot;&gt;doing some thorough testing&lt;/a&gt;, I have concluded that, unfortunately, latency is almost certainly the culprit here. That‚Äôs not something that you can really train yourself to ignore, at least not in fast-paced multiplayer games.&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The MX Master is so very close to a perfect all-arounder mouse. It supports Bluetooth. It works for gaming. It feels incredible in the hand and even features a free-scrolling mouse wheel with a solid middle click. Unfortunately, despite my initial excitement in the first version of this article, I‚Äôve decided to return the mouse it in favor of the gamer-centric &lt;a href=&quot;http://amzn.to/2uDAeF2&quot;&gt;G403 Wireless&lt;/a&gt;. (The lack of Bluetooth support is a bummer, but this mouse hits it out of the park in every other respect.)&lt;/p&gt;

&lt;p&gt;There are two primary flaws that sealed the Master‚Äôs fate for me.&lt;/p&gt;

&lt;p&gt;First, the Bluetooth functionality is lackluster. I don‚Äôt know which company is responsible, but compared to my wireless Apple trackpad, the Master‚Äôs cursor movement under Bluetooth feels rough and jittery. On occasion, I‚Äôve even seen it stop tracking altogether until the on/off switch is toggled. (Dozens of users have reported the same problem on Logitech forums.) Furthermore, Bluetooth performance seems to vary dramatically depending on software conditions. For example, if there are lots of windows on the screen and I free-spin the scroll wheel, the cursor might only be able to move once a half-second. One of my primary goals with this mouse was to have it immediately start working when setting up at a caf√©, and this doesn‚Äôt quite pass my baseline of ‚Äúworking‚Äù.&lt;/p&gt;

&lt;p&gt;The other issue is gaming performance. This feels like such a very minor and nebulous nitpick, but at this point I‚Äôm reasonably certain that I‚Äôm not imagining it. Presumably on account of the additional 10-20ms of latency, I just don‚Äôt feel as in-control with this mouse as I do with my G602. When playing FPS with the G602, I have no problem running down a hallway, executing a precise about-face, and then turning right back in the span of a half-second. With the Master, this gesture simply feels sluggish and unnatural. I often have to make a concerted effort and then end up taking longer or miss the target altogether. The effect is immediately noticeable when using the two mice side-by-side over the course of a long gaming session. The G602 just feels much more precise.&lt;/p&gt;

&lt;p&gt;I really wish it was practical for me to keep this mouse, but it‚Äôs not quite the master-of-everything I was hoping to get. Still, I have no doubt most people would be very happy with the MX Master, especially now that the 2S revision has been released.&lt;/p&gt;

&lt;p&gt;If you decide to get this mouse, I recommend grabbing a &lt;a href=&quot;http://amzn.to/2qJl3LO&quot;&gt;Hermitshell case&lt;/a&gt;. It fits the mouse perfectly and keeps it safe for tossing into your backpack or bag.&lt;/p&gt;

&lt;div class=&quot;full-width&quot;&gt;&lt;img src=&quot;/images/mx-master/master-keyboard.jpg&quot; /&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 22 May 2017 13:14:48 -0700</pubDate>
        <link>http://archagon.net/blog/2017/05/22/almost-winning-the-wireless-mouse-game-logitech-mx-master/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2017/05/22/almost-winning-the-wireless-mouse-game-logitech-mx-master/</guid>
        
        
        <category>reviews</category>
        
      </item>
    
      <item>
        <title>An Even Better Travel Gaiwan</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/klean-kanteen-gaiwan/front.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Previously, I wrote about the &lt;a href=&quot;/2015/12/26/the-perfect-travel-gaiwan/&quot;&gt;Asobu Travel Mug&lt;/a&gt; as an excellent (if unintentional) travel gaiwan. Now, there‚Äôs a new leader in the not-a-gaiwan-but-almost-better-than-one category: the &lt;a href=&quot;http://amzn.to/2j2ie1U&quot;&gt;Klean Kanteen 8oz insulated tumbler&lt;/a&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;This mug is a bit thicker than the Asobu, but in trademark Klean Kanteen fashion the quality is simply superb. Heat is retained perfectly: there are no hot spots around the lip or anywhere on the body. Compared to the flaky finish of the Asobu, the matte black of the Klean Kanteen is &lt;em&gt;slick&lt;/em&gt; and feels like it‚Äôll last for ages. The shape is a little odd on first glance but feels great in the hand, and the rounded lip is perfect to drink from.&lt;/p&gt;

&lt;p&gt;Like the Asobu, the Klean Kanteen has a rubber-lined lid that can double as a strainer. For the most part, I use the sipping hole to strain: the lid snaps on very tightly and most loose-leaf teas expand enough to avoid going through the hole. (You might get a few stragglers, but the same thing happens with my regular gaiwan technique anyway.) If that doesn‚Äôt work, you can just pop the lid off and use the rubber seal as a makeshift strainer. As with the Asobu, the ‚Äúlever‚Äù on the back of the lid can serve as a stopper while tilting it back. Admittedly, I did prefer the Asobu lid for its looser fit ‚Äî the Klean Kanteen takes some strength to pop open! ‚Äî but it‚Äôs a very minor ding on an otherwise excellent product. (Also, this might entirely be in the realm of personal preference. The Klean Kanteen lid looks and feels like it was precisely machined to fit the tumbler, which is a far cry from the ramshackle Asobu construction.)&lt;/p&gt;

&lt;p&gt;The mug fits about 7.7 ounces of water when filled right up to the lid, though you‚Äôll get less when factoring in the tea leaves. It‚Äôs the ideal size for a single-serving cup of tea and about twice as big as your typical gaiwan. (Of course, there‚Äôs no issue using it for smaller steepings.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/klean-kanteen-gaiwan/steeping.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(As an aside: it took me way too long to realize this, but in addition to using a gram scale to measure out the exact amount of tea, you can also use it to measure the precise volume of water desired. This is because 1ml of water normally weighs 1g. Before, I used to eyeball the water; now, I just pour the water into the mug right after weighing the tea. This might seem super-finicky, but I‚Äôve internalized Eco-Cha‚Äôs recommendation to use 9g of tea to 175ml of water for oolongs as a starting point, and it‚Äôs really nice to have reproducible results when comparing different steepings. The only question is whether to subtract the weight of the tea from the weight of the water,  especially as the leaves expand. My hunch is yes.)&lt;/p&gt;

&lt;p&gt;As I mentioned in the previous article, one of the major reasons to use an insulated mug as a ‚Äúgaiwan‚Äù is for its heat retention properties. Very little heat escapes the mug while making tea, maintaining the water at a stable temperature for the entire duration of the brew. My understanding is that certain kinds of teaware are especially prized for this property, but it‚Äôs almost impossible to beat vacuum-insulated steel in this race!&lt;/p&gt;

&lt;p&gt;Of course, it‚Äôs great that you can just throw this mug into your backpack or suitcase and not have to worry about it breaking or weighing you down. And since Klean Kanteen is such an entrenched brand, you can even find a number of accessories for it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/klean-kanteen-gaiwan/tea.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://amzn.to/2j2ie1U&quot;&gt;The Klean Kanteen 8oz insulated tumbler&lt;/a&gt;: highly recommended as a surrogate travel gaiwan!&lt;/p&gt;

</description>
        <pubDate>Sun, 08 Jan 2017 13:41:34 -0800</pubDate>
        <link>http://archagon.net/blog/2017/01/08/an-even-better-travel-gaiwan/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2017/01/08/an-even-better-travel-gaiwan/</guid>
        
        
        <category>reviews</category>
        
      </item>
    
      <item>
        <title>MusicMessages! Making a Collaborative Sequencer for iMessage</title>
        <description>&lt;div&gt;&lt;img src=&quot;/images/music-messages/banner.png&quot; /&gt;&lt;/div&gt;

&lt;p&gt;Last month, I released an unusual little app for iMessage. It‚Äôs called &lt;a href=&quot;http://musicmessages.io&quot;&gt;MusicMessages!&lt;/a&gt;, and it‚Äôs a collaborative step sequencer that lets you work on short pieces of music together with your friends. As far as I can tell, it‚Äôs the only app of its kind in the iMessage App Store. (Probably for good reason!)&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;The app presents you with a grid of buttons, each corresponding to a musical note. Time is horizontal and pitch is vertical, and the entire grid can be panned like any other iOS scroll view. To place a note, simply tap one of the buttons; tap it again to erase the note. (If you have a 3D Touch capable device, you can depress the button using finger pressure. On an iPhone 7, there‚Äôs even a bit of haptic feedback at the end.) The tabs on top of the screen represent independent layers of notes, and if you tap their icons, you can pick a new instrument out of 40+ different ones (including percussion). Once you‚Äôre happy with your portion of the piece, you can send it off to one or more fellow iMessage users for their contributions. Each participant‚Äôs notes show up in their own unique color, making it easy to track the changes to a piece over time.&lt;/p&gt;

&lt;p&gt;Why iMessage? Since releasing &lt;a href=&quot;http://composerssketchpad.com&quot;&gt;Composer‚Äôs Sketchpad&lt;/a&gt;, I‚Äôve wanted to create a companion app that would make it even easier to play around with simple musical ideas, though at the expense of expressiveness. Initially, I envisioned this as a tabbed, pannable, &lt;a href=&quot;/images/music-messages/synth.png&quot;&gt;Minesweeper-like step sequencer&lt;/a&gt; for OSX. But when I started investigating the new iMessage frameworks in iOS 10, I realized that iMessage might be as good a place as any to work out this idea. No sync issues, no file I/O, a format that incentivized short experiments, and plus ‚Äî the social aspect just seemed neat! Wouldn‚Äôt it be fun to riff on a melody or percussion line with your friends?&lt;/p&gt;

&lt;p&gt;&lt;div class=&quot;youtube_16_9&quot;&gt;&lt;iframe src=&quot;https://www.youtube.com/embed/T5B6lANpduI?showinfo=0&amp;amp;rel=0&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;Total development lasted exactly two months and involved approximately 8000 new lines of Swift code, plus 1000 lines and a bunch of assets borrowed from Composer‚Äôs Sketchpad.&lt;/p&gt;

&lt;p&gt;Favorite tech bit? The data format! I hate spinning up and maintaining servers, so my aim was to avoid any outside dependencies by sending data strictly through the iMessage APIs. Unfortunately, iMessage sends data via NSURL, which in this case had a hidden limit of 5120 characters. I hit this limit with plain old NSArchiver after about a dozen notes. To solve the problem, I had to compress all my data ‚Äî 5+ layers, 5+ participants, and as many notes as possible ‚Äî into  approximately 3.75kb, assuming base64 encoding for the data string. Swift is pretty terrible at dealing with tightly-packed data structures (a 256-element static array can only be represented by a non-iterable 256-member tuple) and so I designed a struct and corresponding helper functions for my data in straight C. Lots of fun counting bits and optimizing for maximum data density‚Ä¶ eventually, I settled on a maximum of 12 layers, 8 participants, and 1120 notes, along with a ton of extra data and even some room to spare. Nothing terribly complex, but it‚Äôs still fun to optimize within tight constraints.&lt;/p&gt;

&lt;p&gt;Another feature I enjoyed integrating was the perceptually-balanced &lt;a href=&quot;http://www.hsluv.org/comparison/&quot;&gt;HSL&lt;sub&gt;UV&lt;/sub&gt; color space&lt;/a&gt; for all my user-selected colors. Normally, if you generate colors in the usual HSB color space by varying the hue and keeping saturation and brightness constant, you get colors that are perceived as unequally bright by the human eye. (An artifact of biology, alas.) Perceptually-accurate color spaces like CIELUV attempt to compensate for this, but most of them have large swaths of empty space where impossible colors lie, making it very difficult to create linear ranges of color parametrized by hue. HSL&lt;sub&gt;UV&lt;/sub&gt; goes one step further and stretches the chroma to fill in these gaps. Not perceptually perfect, but just a ton more convenient and usable in practice!&lt;/p&gt;

&lt;p&gt;Since there‚Äôs an element of self-marketing in iMessage apps ‚Äî recipients of app messages are automatically prompted to download the corresponding apps ‚Äî it was important to make my app free. As I really didn‚Äôt want to plaster my interface with ugly ads, I decided to lock some non-critical features behind an in-app purchase. I‚Äôd never dealt with this payment model before, and as a complete novice in cryptography the code samples for receipt decryption and validation seemed quite daunting! Fortunately, I discovered an excellent OSX application called &lt;a href=&quot;https://geo.itunes.apple.com/us/app/receigen/id452840086?mt=12&amp;amp;at=1000lqfl&quot;&gt;Receigen&lt;/a&gt; that generated auto-obfuscated receipt and IAP validation headers for my app. Ended up saving what probably would have been several days of frustrating, unrewarding work for just $30. Highly recommended!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/music-messages/icons_full.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As before, designing the icon was a lot of fun. Just like last time, there was a long period in the middle where I was sure that the right design ‚Äî one that would equally hint at the interface, functionality, and ambiance of the app ‚Äî would elude me. And just as before, after a chain of prototype designs that I wasn‚Äôt crazy about, the right pieces suddenly snapped into into place all at once. On a lark, I even spent a few days parametrizing and animating the icon for my trailer, adding another 900 lines of code through Swift Playgrounds. (Next time, I should probably use something like After Effects or Flash. Keyframing in code is a huge pain, and performance in Playgrounds is hardly sufficient.) The thrill of creative experimentation and discovery is something I sorely miss in my day-to-day programming and makes me all the more eager to get started on my game project.&lt;/p&gt;

&lt;p&gt;Speaking of Adobe, I finally moved on from iMovie to &lt;a href=&quot;http://www.adobe.com/products/premiere-elements.html&quot;&gt;Premiere Elements&lt;/a&gt; for my trailer. What a relief! Although deceptively simple at first, PE conceals enormous power in its effects and keyframing features. In trademark Adobe fashion, the program does its best to &lt;em&gt;infuriate&lt;/em&gt; you into almost paying for the full CC; but with some clunky zoomed-in B√©zier adjustments and begrudging cut-and-paste alignment of keyframe positions, it‚Äôs easy to create a video that moves, changes color, and feels very dynamic. The trailer I saw in my head came together in just a few days, and now iMovie feels like a joke in comparison. Well worth the $50 I paid for it on sale.&lt;/p&gt;

&lt;p&gt;MusicMessages! was an attempt at a speed project, so there‚Äôs many stones left unturned. The UI takes up too much room. The instrument tabs in horizontal mode are too hard to reach. Transitions are jittery and some of the UI glitches out on rotation. There should probably be a chord option for beginners. Percussion is in MIDI order, which is‚Ä¶ a little bit crazy. But overall, I‚Äôm quite happy with the result! I hope people get a kick out of this weird project and enjoy sending their oddball musical ideas to each other.&lt;/p&gt;

&lt;p&gt;One more thing. There‚Äôs a good chance I‚Äôll be releasing a standalone, file-based version of the app in the future (with MIDI, IAA, Audiobus and all that good stuff). If you‚Äôd be interested in using such an app, do let me know!&lt;/p&gt;

</description>
        <pubDate>Tue, 03 Jan 2017 15:09:01 -0800</pubDate>
        <link>http://archagon.net/blog/2017/01/03/musicmessages-making-a-collaborative-sequencer-for-imessage/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2017/01/03/musicmessages-making-a-collaborative-sequencer-for-imessage/</guid>
        
        
        <category>releases</category>
        
      </item>
    
      <item>
        <title>Cheap and Painless eGPU Thrills on a 2013 MacBook Pro</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/egpu/egpu.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My late-2013 15‚Äù MacBook Pro‚Äôs discrete GPU ‚Äî an NVIDIA GeForce GT 750M ‚Äî was pretty good for gaming during the first year of its life.  But around the time that the new generation of consoles dropped, AAA games on the PC started becoming unplayable, even at postage-stamp resolutions with the lowest possible settings. I lived on a strict diet of indie games from 2015 to 2016 ‚Äî thank goodness for well-tuned titles like Overwatch and The Witness! ‚Äî but the itch to try games like the new Mirror‚Äôs Edge and Deus Ex became too great. Initially, I thought it might be time to switch out my MacBook for the upcoming 2016 model, but the winter reveal wasn‚Äôt particularly tempting: CPU performance was about the same as mine and the GPU was ‚Äî at best ‚Äî 3 times as powerful. (Still need to see the benchmarks on that ‚Äî educated guess.) Worth it for a few hundred bucks, but $2000? No way!&lt;/p&gt;

&lt;p&gt;Building a gaming PC wasn‚Äôt an option due to my mobile lifestyle, and in any case the kind of CPU I could buy for cheap would be comically underpowered compared to the i7 4850HQ I already had in front of me. So I started looking into the scary world of external Thunderbolt GPUs, colloquially known as eGPU. Modern Thunderbolt 3 (allegedly) supports external GPUs in an official capacity, but older Thunderbolt 2 can get the job done as well, even though it‚Äôs unsanctioned by Intel. I‚Äôm usually reluctant to pursue these sorts of under-the-radar hobbyist projects, but there was enough prior art to make it worth a shot!&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Unlike many gaming enthusiasts, my goal was to optimize for simplicity over power: the fewer hacks and workarounds I had to use, the better. I already knew I‚Äôd have to use an external monitor and do my gaming in BootCamp, which was already the case. I knew there would be some performance loss from the limited bandwidth of TB2. I gathered that there may be timing issues and other problems that would require a bevy of software hacks to fix ‚Äî mostly on the Windows side of things. But I was most concerned about the hardware hacking required to get the thing up and running in the first place.&lt;/p&gt;

&lt;p&gt;The majority of published eGPU builds involve enormous graphics cards connected to hotwired desktop PSUs, sitting in unseemly, torn-apart Thunderbolt-to-PCI chassises. It was clear that the anointed case for the job was the &lt;a href=&quot;http://amzn.to/2itWCP9&quot;&gt;AKiTiO Thunder2&lt;/a&gt;. The Thunder2 wasn‚Äôt designed for eGPU use, but dozens of eGPU enthusiasts on forums like &lt;a href=&quot;https://www.techinferno.com/index.php?/forums/forum/83-diy-e-gpu-projects/&quot;&gt;TechInferno&lt;/a&gt; demonstrated that it ran stable and performed admirably. (AKiTiO engineers even popped in on occasion to offer under-the-table eGPU advice ‚Äî off-warranty, of course.) It was also one of the cheapest options on the market at around $200: very fair considering that a barebones development Thunderbolt 2 board cost nearly as much!&lt;/p&gt;

&lt;p&gt;Most eGPU builders buy this case to hack up, not to use as-is. Usually, the front panel is bent back or removed to fit larger cards, and then a desktop PSU is made to turn on with a paperclip and adapted to fit the DC plug. There are also arcane startup rituals to get everything powered and running with the right timing. I really didn‚Äôt want to have a PSU octopus and a ragged hunk of metal sitting bare on my table, though it sadly seemed inevitable. Then I discovered an alternate route.&lt;/p&gt;

&lt;p&gt;Most GPUs are power hogs that rely on one or two extra power ports on top of the card, but there are a few designed to pull power straight from the PCI slot. These aren‚Äôt super-extreme gaming cards, but these days they more than get the job done. For example, the just-released NVIDIA GeForce GTX 1050 Ti can pull 1080p at medium-high settings in many recent games and currently benchmarks as the ~40th best video card on the market! Better yet, many of these single-slot offerings are short and half as long as the monster enthusiast cards, easily fitting into AKiTiO‚Äôs compact case without any modifications. Using this type of card, I‚Äôd be able to keep my Thunder2 in one piece and avoid using a PSU entirely. No hacks required!&lt;/p&gt;

&lt;p&gt;At peak, these slot-powered cards can draw 75W from the PCI Express slot. Unfortunately, the AKiTiO Thunder2 only comes with a 60W adaptor, 30W of which is allocated to the circuitry. A dead-end? Not so fast: &lt;a href=&quot;https://www.akitio.com/faq/270-thunder2-pcie-box-what-s-the-maximum-power-output-through-the-pcie-slot&quot;&gt;as stated in the official docs&lt;/a&gt; and verified by employees, the Thunder2 can actually pull as much as 120W from a more powerful adaptor. To be compatible, the new power brick needs to sport a 5.5√ó2.5mm barrel plug, provide 12V output, and have &lt;a href=&quot;https://en.wikipedia.org/wiki/Polarity_symbols&quot;&gt;center positive polarity&lt;/a&gt;. (Practically every power adaptor has these last two items listed on the back.) My hope was to find a laptop power brick with these same specs, but it turned out that most laptops used chargers with an all-too-high output of 20V. Surprisingly, well-reviewed 12V/10A bricks weren‚Äôt common at all on Amazon (unless you &lt;a href=&quot;https://www.amazon.de/Netzteil-Laufwerke-Lichtschl√§uche-LED-Strips-geeignet/dp/B006Z9TQE6&quot;&gt;lived in the UK or Europe&lt;/a&gt;), with most of the listings taken up by rebranded versions of a sketchy-looking adaptor with model number CT-1250. Eventually, I discovered one vendor who was selling bricks with model number CD120100A, which had a more confident label and looked identical to a power brick I saw in another successful closed-case AKiTiO build. (The Amazon listing was full of typos and the product photos didn‚Äôt match the user photos, but it just so happened that the adaptor in the user photos was exactly the one I was hoping to find ‚Äî and Prime allowed for painless returns in any case.) If the US 12V/10A adaptor market was really dominated by CT-1250 and CD120100A, the latter just seemed like a better bet.&lt;/p&gt;

&lt;p&gt;For the graphics card, I decided to give the &lt;a href=&quot;http://amzn.to/2itNpGC&quot;&gt;EVGA factory-overclocked version of the 1050 Ti&lt;/a&gt; a try, since one eGPU enthusiast mentioned that their EVGA card handled boot timing issues a bit better. (True or not, I‚Äôve also had positive experiences with EVGA warranty and support in the past, so it was an easy decision.) Potentially, the overclock was a problem: the AKiTiO Thunder2 wouldn‚Äôt provide more than 75W of power to the slot, and any excess power pulled by the card could destabilize the system or even fry the circuitry (as reported by one user). But from everything I read, factory-overclocked EVGA cards were designed to never exceed the 75W threshold, and any instability could simply be fixed by underclocking the card slightly using EVGA‚Äôs (or possibly NVIDIA‚Äôs) own tools. Factor in the fact that the non-overclocked version cost exactly the same as overclocked while probably having lower resale value, and it became clear that the SC model was almost certainly the better buy ‚Äî even if you dropped the clocks right from the get-go.&lt;/p&gt;

&lt;p&gt;(Note: many reviews will point out that the regular 1050 is a much better deal than the 1050 Ti from a price/performance perspective. Still, the Ti is about 20% faster than the non-Ti for just $20 more, and for the sake of future-proofing as well as TB2 performance loss it just makes sense to wring as much power from the purchase as possible.)&lt;/p&gt;

&lt;p&gt;Trawling eGPU forums for installation instructions was quite frustrating. Most users preferred to write about how they got their eGPUs working with their laptop displays (using Optimus drivers ‚Äî¬†possible with NVIDIA GTX cards) and/or in OSX. Both tasks involved copious scripts and hacks. I was only interested in the bare minimum ‚Äî BootCamp on an external display ‚Äî but most guides simply skipped that ‚Äúeasy‚Äù part. Would I need to make a custom build of Windows? Edit drivers? Install a custom bootloader? Nothing was clear, so I decided to just jump into it.&lt;/p&gt;

&lt;p&gt;Once I got all the parts assembled, I plugged the Thunder2 into my laptop and my monitor into the Thunder2, crossed my fingers, and turned on the computer while holding down the Alt key (for the boot menu ‚Äî I already had BootCamp with the latest Windows 10 installed). At first‚Ä¶ nothing. Just a black screen and no chime. I tried unplugging the cable, turning the machine on, waiting for the chime, and &lt;em&gt;then&lt;/em&gt; plugging it in. The boot menu showed up, but froze when I selected Windows. I tried one more time to boot with the cable plugged in and it worked! Or ‚Äî¬†at least, it booted into Windows. Nothing showed up on the external display, but the Windows Device Manager had a tempting entry named ‚ÄúMicrosoft Basic Display Adapter‚Äù. Hopeful, I searched for other eGPU users who had gotten to this step, and it became apparent that all I had to do was install the latest NVIDIA drivers. One reboot later (with no issues this time) and I was seeing ‚ÄúNVIDIA GTX 1050 Ti‚Äù in my Device Manager. I gave Overwatch a quick run on the highest settings, but performance didn‚Äôt seem particularly great; my suspicion was that the laptop defaulted to the discrete 750M instead of the eGPU. I returned to Device Manager and disabled the 750M, restarted Overwatch, and‚Ä¶ 60fps! It actually worked! Holy cow!&lt;/p&gt;

&lt;p&gt;eGPU setup can be daunting depending on your hardware, but I seem to have gotten away with a problem-free configuration. The ‚Äúhardest‚Äù part is getting the computer to chime on boot, presumably indicating that POST went correctly. This involves turning the computer off and on again one or two times in the worst case: if it chimes and the boot menu appears, everything is sure to work fine. (Recently, I‚Äôve been getting the boot menu on first try 100% of the time. Maybe I was just impatient before!) Once booted into Windows, I‚Äôve learned that simply changing the display settings to only use the external monitor, or to extend the desktop and use the external monitor as the main monitor, ensures that the eGPU is used over the discrete chip. (And I believe Windows remembers this preference when you launch with the eGPU connected.)&lt;/p&gt;

&lt;p&gt;Now for some benchmarks! The main bottleneck in this setup is the TB2 connection. TB2 doesn‚Äôt allow for the full PCIe x16 throughput, potentially crippling graphics card performance. In practice, this isn‚Äôt really that big of a deal: users have reported at most a 20% performance loss over native, and usually a bit less. Let‚Äôs see how well we do.&lt;/p&gt;

&lt;p&gt;
&lt;div class=&quot;tablecontainer&quot;&gt;
&lt;div class=&quot;tablepadding&quot;&gt;
&lt;table&gt;

&lt;colgroup&gt;
&lt;col class=&quot;ch&quot; /&gt;
&lt;col span=&quot;3&quot; class=&quot;data&quot; /&gt;
&lt;/colgroup&gt;

&lt;tbody&gt;

&lt;tr class=&quot;rh&quot;&gt;
&lt;td class=&quot;corner&quot;&gt;&lt;/td&gt;
&lt;th&gt;GTX 1050 Ti SC&lt;/th&gt;
&lt;th&gt;GT 750M&lt;/th&gt;
&lt;th&gt;Improvement&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;3DMark Fire Strike&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics Score&lt;/th&gt;
&lt;td&gt;6993&lt;/td&gt;
&lt;td&gt;1911&lt;/td&gt;
&lt;td&gt;3.66√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 1&lt;/th&gt;
&lt;td&gt;32.28&lt;/td&gt;
&lt;td&gt;8.74&lt;/td&gt;
&lt;td&gt;3.69√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 2&lt;/th&gt;
&lt;td&gt;28.74&lt;/td&gt;
&lt;td&gt;7.96&lt;/td&gt;
&lt;td&gt;3.61√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;3DMark Time Spy&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics Score&lt;/th&gt;
&lt;td&gt;2040&lt;/td&gt;
&lt;td&gt;450&lt;/td&gt;
&lt;td&gt;4.53√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 1&lt;/th&gt;
&lt;td&gt;13.67&lt;/td&gt;
&lt;td&gt;3.00&lt;/td&gt;
&lt;td&gt;4.56√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 2&lt;/th&gt;
&lt;td&gt;11.43&lt;/td&gt;
&lt;td&gt;2.54&lt;/td&gt;
&lt;td&gt;4.50√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;3DMark Sky Dive&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics Score&lt;/th&gt;
&lt;td&gt;22564&lt;/td&gt;
&lt;td&gt;5602&lt;/td&gt;
&lt;td&gt;4.03√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 1&lt;/th&gt;
&lt;td&gt;102.25&lt;/td&gt;
&lt;td&gt;26.41&lt;/td&gt;
&lt;td&gt;3.87√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 2&lt;/th&gt;
&lt;td&gt;103.83&lt;/td&gt;
&lt;td&gt;24.80&lt;/td&gt;
&lt;td&gt;4.19√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;3DMark11 Free&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics Score&lt;/th&gt;
&lt;td&gt;8802&lt;/td&gt;
&lt;td&gt;2445&lt;/td&gt;
&lt;td&gt;3.60√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 1&lt;/th&gt;
&lt;td&gt;42.83&lt;/td&gt;
&lt;td&gt;11.27&lt;/td&gt;
&lt;td&gt;3.80√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 2&lt;/th&gt;
&lt;td&gt;42.18&lt;/td&gt;
&lt;td&gt;11.40&lt;/td&gt;
&lt;td&gt;3.70√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 3&lt;/th&gt;
&lt;td&gt;54.32&lt;/td&gt;
&lt;td&gt;15.52&lt;/td&gt;
&lt;td&gt;3.50√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;th class=&quot;th1&quot;&gt;Graphics FPS 4&lt;/th&gt;
&lt;td&gt;25.13&lt;/td&gt;
&lt;td&gt;7.39&lt;/td&gt;
&lt;td&gt;3.40√ó&lt;/td&gt;
&lt;/tr&gt;

&lt;/tbody&gt;

&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;p&gt;Quite an upgrade! According to Passmark and other benchmark listings, a 1050 Ti should, under normal circumstances, be about 4.5√ó as powerful as a 750M. Factor in 10%-20% performance loss from the TB link and that‚Äôs exactly what we see in our results: a 4x boost on average.&lt;/p&gt;

&lt;p&gt;Even without any underclocking, stability has not been an issue. I‚Äôve been playing hours of Crysis 3, Far Cry 4, and Mirror‚Äôs Edge Catalyst over the past few days and everything‚Äôs still working great. I‚Äôm keeping the case closed, but I don‚Äôt think there‚Äôs any real risk of overheating: the GPU fan is designed to funnel heat right out through the back and there‚Äôs an extra front fan build into the case anyway. According to 3DMark, temperature during benchmarking has been stable.&lt;/p&gt;

&lt;p&gt;I‚Äôm not interested in running any weird scripts to get Optimus drivers for the internal display working, but I learned something interesting while fiddling with the Windows display settings. If you set the multiple display setting to &lt;a href=&quot;/images/egpu/duplicate.png&quot;&gt;‚ÄúDuplicate these displays‚Äù&lt;/a&gt;, it seems that somehow the eGPU gets used for both the internal and external display! Assuming I‚Äôm interpreting this finding correctly, this means that theoretically you could buy something like this &lt;a href=&quot;https://www.amazon.com/CompuLab-fit-Headless-Display-Emulator/dp/B00FLZXGJ6&quot;&gt;HDMI display emulator&lt;/a&gt; and use the eGPU on the internal display without an external monitor and without having to go through the hacky process of getting Optimus up and running. Unfortunately, there‚Äôs a performance penalty of about 20%-25% (according to my benchmarks) as well as approximately 0.25 seconds of latency, making this approach untenable for first-person shooters and other twitchy games. (I wonder if this is also the case with the Optimus driver route?)&lt;/p&gt;

&lt;p&gt;Another interesting finding: if you keep the discrete GPU enabled, there‚Äôs a setting in the NVIDIA control panel to &lt;a href=&quot;/images/egpu/physx.png&quot;&gt;dedicate one of the GPUs to PhysX&lt;/a&gt;. I‚Äôm not sure if this will make a real difference in performance or cause stability issues, but it might be worth investigating in the future.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/egpu/egpu2.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To summarize, using only‚Ä¶&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://amzn.to/2itWCP9&quot;&gt;An AKiTiO Thunder2 PCIe Box&lt;/a&gt; ($220)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://amzn.to/2itNpGC&quot;&gt;An EVGA GeForce GTX 1050 Ti SC&lt;/a&gt; ($140)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://amzn.to/2iQUoWJ&quot;&gt;A 120W 12V/10A power adaptor with a 5.5√ó2.5mm plug and center positive polarity&lt;/a&gt; ($35 ‚Äî though buy it from a seller with Prime in case it‚Äôs the wrong one! This listing used to have a Prime seller, but I don‚Äôt see them anymore. Also, HN has pointed out that &lt;a href=&quot;http://www.mini-box.com/12v-10A-AC-DC-Power-Adapter&quot;&gt;this&lt;/a&gt; may be a far better adaptor, even if it‚Äôs not sold on Amazon.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;‚Ä¶you can assemble a painless, hack-less eGPU build and use it with your late-2013 15‚Äù dGPU MacBook as a relatively inexpensive graphics upgrade compared to building a PC from scratch or buying a console. (Cheaper still if you wait for rebates or use an older/weaker X50 card.) &lt;strong&gt;Caveat emptor:&lt;/strong&gt; the same build might not work so well ‚Äî or at all! ‚Äî on other MacBook models or even with a different driver version. In other words, &lt;strong&gt;what worked for me might not work for you!&lt;/strong&gt; Remember that eGPU on TB2 is not officially supported and mostly works by accident, though clearly it can work very well.&lt;/p&gt;

&lt;p&gt;(Also, there‚Äôs some great information in the &lt;a href=&quot;https://news.ycombinator.com/item?id=13303912&quot;&gt;HN thread for this post&lt;/a&gt; about new and upcoming TB3 enclosures. If you can get one working with a TB3-to-TB2 adaptor, it might be the best option of all for upgradability, reliability, and future-proofing. On the other hand, you‚Äôll probably spend more money and the case will be a lot bigger. Do your research!)&lt;/p&gt;

&lt;p&gt;In time, I hope somebody releases a Thunderbolt 3 eGPU the size of one of those Square credit card readers ‚Äî maybe sporting a GTX 980M caliber chip? ‚Äî that plugs into a USB-C port and works seamlessly with the internal display. But for now, this lovely little eGPU will do just fine. I‚Äôm confident that my trusty MacBook can now serve me for another few years, especially if NVIDIA continues to release excellent and inexpensive PCI-powered cards on the regular.&lt;/p&gt;

&lt;p&gt;Let‚Äôs hope that the eGPU revolution is just beginning!&lt;/p&gt;

</description>
        <pubDate>Sat, 31 Dec 2016 18:18:54 -0800</pubDate>
        <link>http://archagon.net/blog/2016/12/31/cheap-and-painless-egpu-thrills-on-a-2013-macbook-pro/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2016/12/31/cheap-and-painless-egpu-thrills-on-a-2013-macbook-pro/</guid>
        
        
        <category>technology</category>
        
        <category>reviews</category>
        
      </item>
    
      <item>
        <title>Turning Your macOS Desktop into a Rotating Art Gallery with Backgroundifier</title>
        <description>&lt;div&gt;&lt;img src=&quot;/images/backgroundifier-gallery/title_2.jpg&quot; /&gt;&lt;/div&gt;

&lt;p&gt;The category of static visual art is in a bit of an awkward phase right now. Entertainment in the 21st century has evolved to actively engage our minds and senses, to the point where movies, music, games, and even audiobooks require little more than putting on a pair of headphones or fixing our vision to the nearest screen. Where does the immense body of work from genres such as fine art, photography, and illustration fit into this world? Museums ‚Äî physical beasts that they are ‚Äî can hardly be visited on a whim, and as of yet there‚Äôs (sadly) no Spotify for visual art. Meanwhile, hundreds of amazing works are posted daily on Instagram, DeviantArt, and Reddit. How do we find the time to fit them into our content-saturated lives? And how do we return to view the works we‚Äôve already enjoyed?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;For several years, I wanted to create a sort of ‚Äúdigital museum‚Äù that would give me random, on-demand access to this very important side of the art world. The constraints weren‚Äôt complicated. All I needed was a large amount of art along with a mechanism that would randomly show me new works from this collection every fifteen minutes or so. But while acquiring the art was hardly a problem, there were relatively few areas in my life where I could idly display images. Screensavers? Showed up too infrequently and weren‚Äôt easily controllable. Wallpapers? Couldn‚Äôt deal with arbitrary aspect ratios. I thought I had my solution when I ran the &lt;a href=&quot;http://www.google.com/culturalinstitute/beta/project/art-camera&quot;&gt;Google Art Project&lt;/a&gt; in a full-screen browser tab on a second monitor, but the selection turned out to be too limited and I could no longer rely on the luxury of having more than one display when I set out on my travels.&lt;/p&gt;

&lt;p&gt;(As an aside, Clay Bavor solved this exact problem in hardware by creating a &lt;a href=&quot;http://www.claybavor.com/?p=407&quot;&gt;digital photo frame that automatically compensated for ambient light&lt;/a&gt;. Amazing solution! But I‚Äôm a software guy, so‚Ä¶)&lt;/p&gt;

&lt;p&gt;After discovering Chris Tomkins-Tinch‚Äôs &lt;a href=&quot;https://itunes.apple.com/us/app/artful/id940324777?ls=1&amp;amp;mt=12&amp;amp;at=1000lqfI&quot;&gt;Artful app&lt;/a&gt; which turned your desktop wallpaper into a rotating collection of fine art, I realized that I had given the humble desktop too little consideration. With a simple Gaussian blur, a soft drop shadow, and a sprinkle of magic, it was in fact quite simple to create dynamic backgrounds for images at practically any aspect ratio. But Artful was designed to automatically pull images from proprietary sources, whereas I already had a sizable ‚Äúinspiration‚Äù folder of collected art that I wanted to add to the mix. I also wished to keep my system as clean and simple as possible: Artful interfaced directly with your system preferences, but I much preferred to just keep a wallpaper folder that I‚Äôd occasionally drop new images into. And so a new app was born: &lt;a href=&quot;https://itunes.apple.com/us/app/backgroundifier/id1040333206?mt=12&amp;amp;at=1000lqfI&quot;&gt;Backgroundifier&lt;/a&gt;, a native converter droplet that let you easily turn arbitrary images into lovely desktop wallpapers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/sample.jpg&quot; width=&quot;900px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Just having this app around increased my consumption of art tremendously. But it wasn‚Äôt enough. I wanted to bridge the gap between finding an image on the web and having it appear in my desktop rotation, and I also wanted to be able to show new works of art on a whim. Fortunately, macOS is no slouch! Using Backgroundifier‚Äôs command-line mode, Automator, and the native power of Mission Control and Spaces, I‚Äôve finally been able to create the digital museum experience I‚Äôve always wanted.&lt;/p&gt;

&lt;p&gt;Naturally, the process begins with finding the art.&lt;/p&gt;

&lt;h2 id=&quot;wheres-the-art&quot;&gt;Where‚Äôs the Art?&lt;/h2&gt;

&lt;p&gt;Some people want their art carefully curated, and there are a number of existing apps and services for that. (See the aforementioned &lt;a href=&quot;https://itunes.apple.com/us/app/artful/id940324777?ls=1&amp;amp;mt=12&amp;amp;at=1000lqfI&quot;&gt;Artful&lt;/a&gt; and the &lt;a href=&quot;http://www.google.com/culturalinstitute/beta/project/art-camera&quot;&gt;Google Art Project&lt;/a&gt;.) Not me, though! I want everything in my wallpaper shuffle: the ‚Äúgreat artists‚Äù of the past; modern digital and concept art; Russian textbook illustrations; architectural photography. Much of my daily discoveries come from Reddit, and though the site &lt;em&gt;is&lt;/em&gt; an awful cesspool in many respects, subs like &lt;a href=&quot;https://www.reddit.com/r/ImaginaryLandscapes/top/&quot;&gt;r/imaginarylandscapes&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/CozyPlaces/top/&quot;&gt;r/cozyplaces&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/SpecArt/top/&quot;&gt;r/specart&lt;/a&gt; ‚Äî and even plain old &lt;a href=&quot;https://www.reddit.com/r/Art/top/&quot;&gt;/r/art&lt;/a&gt; and &lt;a href=&quot;https://www.reddit.com/r/photographs/top/&quot;&gt;/r/photographs&lt;/a&gt; ‚Äî make it all worthwhile. Whenever I run into an interesting new sub specializing in visual art, I immediately sort by the top posts of all time and pull my favorite images from that list. (Fun tip: if you ever run into an Imgur gallery that you particularly like, you can find a link at the bottom to download the entire collection as a zip! I‚Äôve done this with things like Miyazaki backgrounds.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/download.jpg&quot; width=&quot;849px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you‚Äôre interested in scouring some of the &lt;em&gt;less savory&lt;/em&gt; parts of the web, there are Russian torrent sites featuring comprehensive collections of art from practically any famous artist or museum you could think of. There‚Äôs nothing particularly unethical about this approach ‚Äî a lot of older art is at this point public domain, after all ‚Äî and it‚Äôs quite an experience to drop ‚ÄúThe Best of the Louvre‚Äù into your background rotation for a week.&lt;/p&gt;

&lt;p&gt;Running every single file through Backgroundifier and plonking it in your wallpaper folder is bound to be a chore. Fortunately, this can be entirely automated using Backgroundifier‚Äôs command-line mode and macOS‚Äôs native Automator.&lt;/p&gt;

&lt;h2 id=&quot;harnessing-the-command-line&quot;&gt;Harnessing the Command Line&lt;/h2&gt;

&lt;p&gt;Although Backgroundifier presents a user-friendly GUI, it can also be accessed through the command line. (To see how one can make such a dual-mode app in Swift, you can examine my code &lt;a href=&quot;https://github.com/archagon/backgroundifier-public/blob/master/Backgroundifier/main.swift&quot;&gt;here&lt;/a&gt;.) One way to do this is to navigate to your &lt;code class=&quot;highlighter-rouge&quot;&gt;Backgroundifier.app&lt;/code&gt; bundle in Terminal and run the Backgroundifier executable found in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Contents/MacOS&lt;/code&gt; subdirectory. With the standard &lt;code class=&quot;highlighter-rouge&quot;&gt;--usage&lt;/code&gt; flag, you can view all the options available to you. (Some of these aren‚Äôt even accessible through the GUI!)&lt;/p&gt;

&lt;p&gt;The simplest way to process a file is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;Backgroundifier -i /path/to/input_image.jpg -o /path/to/output_image.jpg -w 1920 -h 1080&lt;/code&gt;. Unfortunately, due to the fact that Backgroundifier is a sandboxed app, you can‚Äôt just do this for any random directory. Whereas a sandboxed GUI app can expand its sandbox to include any directories opened through the file picker or dropped directly onto it, command line apps (to my knowledge) have no such ability. You can therefore only process files located in your &lt;code class=&quot;highlighter-rouge&quot;&gt;~/Pictures&lt;/code&gt; directory.&lt;/p&gt;

&lt;p&gt;Fortunately, there‚Äôs another way. In the Resources directory of &lt;code class=&quot;highlighter-rouge&quot;&gt;Backgroundifier.app&lt;/code&gt; bundle, there‚Äôs a zip file containing a non-sandboxed, Developer ID signed version of the command line tool. Extract it and you can use it in any directory you please.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/bgify.png&quot; width=&quot;885px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;magic-folders-with-automator&quot;&gt;Magic Folders with Automator&lt;/h2&gt;

&lt;p&gt;Automator, macOS‚Äôs powerful visual scripting tool, can be used to create so-called ‚ÄúFolder Actions‚Äù, or workflows that run whenever the contents of a predetermined directory are changed. As you might expect, this is ideal for file conversion. Below is my Folder Action workflow for automatically ‚Äúbackgroundifying‚Äù images into a separate output directory:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/workflow.png&quot; width=&quot;629px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Item 2 contains the path to the output directory and item 3 contains the path to the Backgroundifier command line utility. (They exist as separate items to make the paths easy to modify without having to resort to scripting.) Here‚Äôs the full text for the script in item 3:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# assign paths
bgify=$1
output=$2

# remove path arguments
shift 2

# process images
for var in &quot;$@&quot;
do
    filename=$(basename &quot;$var&quot;)
    full_output=&quot;$output/$filename&quot;
    echo &quot;Processing $full_output ...&quot;
    &quot;$bgify&quot; -i &quot;$var&quot; -o &quot;$full_output&quot; -w 2560 -h 1600
done
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Nothing too complicated! You can find the workflow file &lt;a href=&quot;/images/backgroundifier-gallery/Backgroundify.workflow.zip&quot;&gt;here&lt;/a&gt;, and I assume you can just drop it into your &lt;code class=&quot;highlighter-rouge&quot;&gt;~/Library/Workflows/Applications/Folder Actions&lt;/code&gt; directory. You can also pretty easily recreate it from scratch: just make a new Automator workflow with a Folder Action document type and copy the items.&lt;/p&gt;

&lt;p&gt;Whenever I find an interesting new image on Reddit, all I now have to do is drag-and-drop it straight from my browser into the designated Input directory on my desktop. macOS and Backgroundifier automatically take care of the rest.&lt;/p&gt;

&lt;h2 id=&quot;dealing-with-the-desktop&quot;&gt;Dealing with the Desktop&lt;/h2&gt;

&lt;p&gt;macOS‚Äôs desktop background settings allow us to pick a source directory and change the background to a random image at a set time interval (with 30 minutes being the default). All we really need to do here is drag the output directory from the previous step into our list, select it, check ‚ÄúChange picture‚Äù and ‚ÄúRandom order‚Äù, and set our desired time interval.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/backgroundifier-gallery/wallpaper.jpg&quot; width=&quot;668px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It‚Äôs no fun to manually move every window out of the way whenever you want to peek at your wallpaper. Fortunately, there are several macOS-native shortcuts for showing the desktop. One is to use a four-finger trackpad pinch, selectable under &lt;code class=&quot;highlighter-rouge&quot;&gt;Trackpad ‚Üí More Gestures ‚Üí Show Desktop&lt;/code&gt; in System Preferences. Personally, I prefer binding the action to a keyboard shortcut: &lt;code class=&quot;highlighter-rouge&quot;&gt;Command-Option-down&lt;/code&gt;, to go with my assigned &lt;code class=&quot;highlighter-rouge&quot;&gt;Command-Option-left&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;right&lt;/code&gt; shortcuts for switching spaces. You can do this under &lt;code class=&quot;highlighter-rouge&quot;&gt;Keyboard ‚Üí Shortcuts&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Some of us are‚Ä¶ more messy than others. The desktop can acquire quite a bit of cruft over time, blocking view of the beautiful art below. But why bother cleaning it up when you can just sweep the mess under a rug? If you‚Äôre lazy like me, you can toggle visibility for the icons on your desktop by running &lt;a href=&quot;/images/backgroundifier-gallery/toggle_desktop.command.zip&quot;&gt;this simple script&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/sh&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Toggles desktop icons.&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;defaults &lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;com.apple.finder CreateDesktop&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Showing desktop icons.&quot;&lt;/span&gt;
    defaults write com.apple.finder CreateDesktop &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;else
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hiding desktop icons.&quot;&lt;/span&gt;
    defaults write com.apple.finder CreateDesktop &lt;span class=&quot;nb&quot;&gt;false
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;killall Finder
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And voil√†! Clutter-free art with hardly a fuss.&lt;/p&gt;

&lt;h2 id=&quot;spaces--showing-new-art&quot;&gt;Spaces &amp;amp; Showing New Art&lt;/h2&gt;

&lt;p&gt;Here‚Äôs where it all comes together. One my favorite macOS features is Spaces, or virtual desktops. Spaces have an extra hidden benefit for our use case: whenever a new Space is created, its desktop background settings are taken from the previous space. This means that any new Space created in our configuration will automatically arrive with a fresh work of art in tow!&lt;/p&gt;

&lt;p&gt;Whenever you wish to see a new work of art, just pop open Mission Control (in my case, bound to &lt;code class=&quot;highlighter-rouge&quot;&gt;Command-Option-up&lt;/code&gt;), create a few new Spaces, and keep switching Spaces to the right. It‚Äôs just like leafing through an art book!&lt;/p&gt;

&lt;video controls=&quot;&quot; width=&quot;800px&quot; poster=&quot;/images/backgroundifier-gallery/demo.jpg&quot;&gt;
	&lt;source src=&quot;/images/backgroundifier-gallery/demo.mp4&quot; type=&quot;video/mp4&quot; /&gt;
	Your browser does not support the video tag.
&lt;/video&gt;

&lt;p&gt;And that‚Äôs all it takes to create your own personal art gallery using &lt;a href=&quot;https://itunes.apple.com/us/app/backgroundifier/id1040333206?mt=12&amp;amp;at=1000lqfI&quot;&gt;Backgroundifier&lt;/a&gt;. No mysterious system overrides or hacks. No 3rd party tools of unknown provenance. Just a Unix-y converter, an Automator script, and a couple of native macOS features to tie it all together.&lt;/p&gt;

&lt;p&gt;It‚Äôs quite a thing knowing that a new, enriching artistic discovery ‚Äî be it a Picasso, a Van Gogh, or even a Mike From Around The Web ‚Äî is only a quick peek away!&lt;/p&gt;

</description>
        <pubDate>Mon, 19 Sep 2016 16:10:16 -0700</pubDate>
        <link>http://archagon.net/blog/2016/09/19/turning-your-macos-desktop-into-a-rotating-art-gallery-with-backgroundifier/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2016/09/19/turning-your-macos-desktop-into-a-rotating-art-gallery-with-backgroundifier/</guid>
        
        
        <category>releases</category>
        
      </item>
    
      <item>
        <title>GoodNotes &amp; The Joys of Digital Note-Taking</title>
        <description>&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/header.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I have to admit: I‚Äôm an analog kind of fellow. Much as I benefit from our growing roster of digital tools, I‚Äôm always on the lookout for software that reminds me of reality‚Äôs imperfect grit. Fake mechanical clock faces. &lt;a href=&quot;http://fffff.at/noisy-typer-a-typewriter-for-your-laptop/&quot;&gt;Typewriter sounds&lt;/a&gt;. &lt;a href=&quot;http://www.secretgeometry.com/apps/cathode/&quot;&gt;Simulated CRT monitors&lt;/a&gt;! Some might call them skeumorphic, clunky, or even fraudulent; but in a world increasingly bent on making things shiny and pristine, I enjoy having a reminder of which side of the screen is the more important one.&lt;/p&gt;

&lt;p&gt;The same even applies to my work notes. No doubt, there are immense benefits to limiting your note-taking to professional software like OneNote or Google Docs, starting with obvious features like copy &amp;amp; paste and text search that we all rely on while taking completely for granted. But whenever I undertake a major project, any spare pieces of paper lying around (including napkins, envelopes, and candy wrappers) will inevitably become conscripted as scratch paper, despite the vast universe of affordances on the digital side of the divide. As much as I‚Äôve tried to adopt my thinking to software, the cold, hard truth of digital type just doesn‚Äôt represent my thoughts very well. On paper, my ideas becomes non-linear: sometimes visually grouped with related bits of info, sometimes crawling up the sides, sometimes accompanied by quick sketches and diagrams.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;One day, after failing yet again to trace my line of thought in Evernote, I decided to just give in and buy myself a nice paper notebook. Despite my initial concerns about all the features I was giving up, the switch turned out to be remarkably liberating. I loved to dig around in my backpack for my latest set of notes; feel the ever-growing creases in the covers; flip past all the dog-eared pages. And of course, no app in the world could replicate the joy of jotting down a rickety diagram with ink flowing in its wake! It felt significant that I could hold in my hands a tangible artifact representing the course of my project, and I looked forward to the days when I would exhaust my current notebook and have to go shopping for a new one. The tactile pleasures of this simple thing couldn‚Äôt be reproduced by any computer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/notebook.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The digital world still beckoned, slightly. Largely spurred by my light-packing travels, most of my other media had become digital at this point. My work notes usually served the role of scratch paper, so I didn‚Äôt miss the search feature in Evernote too much. Still, it was a terrible shame that once a project was over, all these notebooks had to be thrown in a closet to gather dust in obscurity. I tried scanning bits of them in, but it was too much of a hassle.&lt;/p&gt;

&lt;p&gt;In September 2015, Apple announced the new iPad Pro along with their brand new stylus, the Apple Pencil. This was a necessary purchase for my work anyway, and so a new hope crossed my mind: could I finally reconcile the analog and digital worlds with this tech? Here was a tablet that could finally act like a digital pad of paper, sporting a glass-welded, ambient-light-adapting screen and a digitizer running at 120Hz with barely any latency. Just a few years before, you needed an enormous desk-sized piece of hardware to do the same thing ‚Äî and people still complained about the lag. With the Apple Pencil, seemingly everyone (artists and reviewers alike) agreed that it was the closest thing to paper they‚Äôd ever tried.&lt;/p&gt;

&lt;p&gt;After receiving my new iPad, I started to search for a very specific kind of software. Plenty of great drawing apps were out already, but I wanted more than that. I wanted an app that would let me collect a roster of virtual notebooks, all sporting different shapes and covers. I wanted each notebook to have a variety of pages, customizable with their own type and texture. Most importantly, I wanted every notebook to exist as an open-format file on my Dropbox. Instead of relying on a proprietary app to access my notebooks, it was critical that I be able to leaf through them ‚Äî and maybe even edit them! ‚Äî using other software. It seemed that PDF might be suited for the task; I‚Äôd routinely used it for book scans to great effect, and I also knew that the underlying rendering technology ‚Äî PostScript ‚Äî was more than capable of displaying any manner of graphic. Perhaps there was an app that fused PDF creation and annotation with just the right amount of magic make it work?&lt;/p&gt;

&lt;p&gt;There were a good handful of contenders, but three names kept coming up: &lt;a href=&quot;https://itunes.apple.com/us/app/notability/id360593530?mt=8&amp;amp;at=1000lqfI&quot;&gt;Notability&lt;/a&gt;, &lt;a href=&quot;https://itunes.apple.com/us/app/noteshelf/id392188745?mt=8&amp;amp;at=1000lqfI&quot;&gt;Noteshelf&lt;/a&gt;, and &lt;a href=&quot;https://itunes.apple.com/us/app/goodnotes-4-notes-pdf/id778658393?mt=8&amp;amp;at=1000lqfI&quot;&gt;GoodNotes&lt;/a&gt;. None were perfect. Notability had many bells and whistles and was clearly the audience favorite, coming up in any thread where people were talking notes. Noteshelf was beautifully designed and seemed to be directly targeting my digital notebook use case, sporting flippable pages and an iBooks-like shelf for your notebooks. Unfortunately, both options felt fairly proprietary. If PDF export was even a feature, it was clearly treated in a throw-it-over-the-fence kind of way: the pristine copies of your notebooks only lived inside their respective app silos. Then there was GoodNotes. This was a subtle app without too much pizzaz and not overflowing with features. It almost resembled an Office-style product more than any of its hipper competitors. But the features it did offer were incredible.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/note.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First, GoodNotes stored your drawings as vectors instead of rasterizing them out. Every line, shape, and highlight you drew was retained as a pristine geometric shape, preserving your work for the ages and offering 100% clarity at any zoom level. Any text that you wrote would automatically get OCR-ed, allowing you to actually search through your notes if your handwriting was legible enough. Covers and pages could be swapped with ease to any image of your choosing, even in the middle of an existing notebook. (Templates such as graph paper and even musical staff paper were included.) The UI and gestures were bog-standard iOS, and accordingly intuitive: it took little effort to figure out how to manage your documents and create new content. You still got all the ‚Äúparity features‚Äù offered by other note-taking apps such as typing, shapes, image support, and more, which weren‚Äôt particularly relevant to me but still felt like they could be useful on occasion. Then there was the kicker. Even though your notebooks weren‚Äôt stored &lt;em&gt;directly&lt;/em&gt; as PDF, you could opt to encode them into Dropbox right as you were working. The implementation here was simply remarkable. Each PDF produced was, functionally, a lossless copy of your notebook, harnessing the full power of PDF to reproduce every GoodNotes feature in full. Digging around in the generated file internals, I saw that everything was layered just as it was in the app. The background texture of each page was its own asset. Your writing was stored in its original vector form. &lt;em&gt;Even the OCR text was there&lt;/em&gt;, hidden from view but layered on top of the original text and searchable using most PDF software. This was as close to a perfect copy of your notebook as you could get, and I felt confident that my data would be perfectly safe were GoodNotes to ever go out of business.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/pages.jpg&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(It should be noted that there‚Äôs one downside to GoodNotes‚Äô vector drawing approach: performance is proportional to the amount of content on the page. In most cases, this isn‚Äôt a problem: loading takes no time at all and drawing is lag-free. But if one of your pages is especially dense with translucent lines and complex shapes, it might take a second for everything to tile in. In practice, the tradeoff of having a lossless copy of your data versus fixed performance is well worth it. I can wait a second if it means that my writing will look as crisp 100 years from now as it does today.)&lt;/p&gt;

&lt;p&gt;It‚Äôs hard to deny that you lose something in moving away from the physical world. No amount of code will give back the glide of an ink pen across cream-colored paper or  the crinkle of a bound old set of pages. But you only trade one kind of magic for another. I can now switch colors and brush strokes in a snap. Mistakes can be erased and even undone with barely a thought. If I need to make a graph or draw some musical notes, I can switch out the ‚Äúpaper‚Äù I‚Äôm using to almost any other format ‚Äî or even provide my own. And covers! Whereas in my paper notebook days, I could spend hours window-shopping for a cover with just the right look and feel, the joy of discovering the perfect vector image for the cover of my digital notebook comes very close indeed. Best of all, I now have a digital archive of all my notes without any extra work on my part. On finishing my work for the day, I can peek inside my Dropbox and leaf through a remarkable document featuring every paragraph, graph, and schematic I‚Äôd scribbled.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/goodnotes-review/preview.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Today, all my work-related notes are made directly on my iPad using &lt;a href=&quot;https://itunes.apple.com/us/app/goodnotes-4-notes-pdf/id778658393?mt=8&amp;amp;at=1000lqfI&quot;&gt;GoodNotes&lt;/a&gt;. And it‚Äôs just wonderful!&lt;/p&gt;

</description>
        <pubDate>Tue, 30 Aug 2016 13:26:53 -0700</pubDate>
        <link>http://archagon.net/blog/2016/08/30/goodnotes-and-the-joys-of-digital-note-taking/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2016/08/30/goodnotes-and-the-joys-of-digital-note-taking/</guid>
        
        
        <category>technology</category>
        
      </item>
    
      <item>
        <title>Indie App Reliance</title>
        <description>&lt;p&gt;Today, &lt;a href=&quot;https://twitter.com/brentsimmons/status/767461318538383360&quot;&gt;with a single tweet&lt;/a&gt;, the note-taking app &lt;a href=&quot;http://vesperapp.co&quot;&gt;Vesper&lt;/a&gt; has officially been shuttered. At its release, Vesper was &lt;a href=&quot;https://marco.org/2013/06/06/vesper&quot;&gt;widely promoted&lt;/a&gt; by the &lt;a href=&quot;https://www.macstories.net/reviews/vesper-review-collect-your-thoughts/&quot;&gt;Apple indie developer communtiy&lt;/a&gt; as the hot new thing to try. More than anything else, it had an excellent pedigree, with influential blogger John Gruber of &lt;a href=&quot;http://daringfireball.net&quot;&gt;Daring Fireball&lt;/a&gt; at the helm. Many hopeful users switched to it for their primary note-taking needs, expecting that features like Mac support would arrive in short order. If any app from this circle was destined to be a breakaway hit, it was this one. And now, with barely a mention, it‚Äôs all but swept away, years after langishing with barely an update.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;This is not a post about why Vesper ultimately failed. There are plenty of others who will happily chat about the rusty economics of the App Store. Instead, I want to focus on the other end of this unfortunate feedback loop: the effect that these highly visible app shutdowns might have on App Store customers.&lt;/p&gt;

&lt;p&gt;Several bloggers have expressed curiosity as to why public interest in the App Store has waned so much. I can‚Äôt answer for everyone, but at least within myself, I‚Äôve noticed an increasing and persistant reluctance to try new apps. It‚Äôs just that I‚Äôve seen same pattern crop up over and over again. Somebody releases an interesting new app, touting fantastic design and improved productivity. The app gains some (but not overwhelming) traction. The app gets a few updates. The app lingers for a few years. And finally, the app untriumphantly rides off into the sunset, taking entire years of not just developer time, but thousands of users‚Äô ingrained habits with it. The case is clear: most apps ‚Äî and especially indie apps ‚Äî¬†cannot be reliably expected to continue operating.&lt;/p&gt;

&lt;p&gt;After being burned so many times by products that have been pulled out from under me, I‚Äôve unconsciously adopted a worrying philosophy for trying new apps: unless the app I‚Äôm using is backed by a large corporation or is outright open-source, I‚Äôm not going to use it for anything particularly important in my life.  (And even then, certain corporations ‚Äî ahem, Google ‚Äî are put under further scrutiny.) I hate having to do this because many amazing UX advancements can be found in apps produced by smaller developers. (Apple folks love to talk about how certain categories of apps are &lt;a href=&quot;https://daringfireball.net/2009/04/twitter_clients_playground&quot;&gt;design playgrounds&lt;/a&gt;.) But at the same time, I know that with these apps, there is an inevitable sunset e-mail waiting for me in the not-too-distant future. It‚Äôs gotten so bad that I‚Äôm starting to seriously consider switching most of the (snappy, beautiful, well-designed) productivity apps on my phone over to their (ugly, clunky) open-source alternatives, just because I know that OpenWhatever will long outlive the current App Store darling for that category. (1Password is one hot spot that immediately comes to mind. Losing them would be a disaster.) I don‚Äôt want to worry every day about whether these proprietary silos will suddenly go up in flames with all my carefully-constructed workflows and data in tow.&lt;/p&gt;

&lt;p&gt;Despite the low prices on the App Store, I now get decision fatigue whenever I go to purchase an app. How long is this product going to be around? How reliable is this developer? How easy is it to export the data? How open are all the underlying formats and APIs? The price might be insignificant, but the commitment implied by my purchase is not trivial at all! Unfortunately, developers don‚Äôt seem to care much about the mental toll that pulling an app might cause, even when they were the ones touting life-changing productivity and workflow improvements in the first place. It‚Äôs one thing I miss about Windows utility software: so much of it is terribly designed, but at least I know it‚Äôll run more or less forever. (Both on account of the open platform and Windows‚Äô amazing legacy support.)&lt;/p&gt;

&lt;p&gt;It‚Äôs understandable why developers shut down their apps, but I wish there was another way out of this dead-end. Maybe apps could certify that all their back-end services are provided by external vendors and can be swapped out if necessary. (This is why I‚Äôm not too worried about apps like Reeder and Pocket Casts: I know that if they go away, I can take my precious data and switch right over to another app.) Maybe developers could pledge ‚Äî even with legal backing! ‚Äî to open-source their software if they ever decide to stop supporting it. Or going even further into this mythical socialist utopia, how about we finally figure out a way to fund open-source software from the get-go without having to beg for donations? With services like CloudKit, it‚Äôs no longer even necessary to spend a single cent of your money on servers. What‚Äôs the point of bringing something wonderful into the world if it only lasts for as long as people are willing to buy it? I can‚Äôt help but see that as hopelessly cynical.&lt;/p&gt;

&lt;p&gt;To be clear: I‚Äôm &lt;em&gt;not&lt;/em&gt; saying that developers should be expected to support and add features to their apps indefinitely. That would be a very extreme stance. But on the other end, adopting a scorched earth policy for your app once you tire of it is also pretty extreme and poisons the market to boot.&lt;/p&gt;

&lt;p&gt;Apps ‚Äî products that encapsulate &lt;em&gt;years&lt;/em&gt; of people‚Äôs lives ‚Äî should never outright disappear just because a developer can‚Äôt be bothered to support them anymore. If we don‚Äôt have that assurance, and if we can‚Äôt rely on our tools, all we‚Äôre doing is playing with toys.&lt;/p&gt;
</description>
        <pubDate>Sun, 21 Aug 2016 17:01:19 -0700</pubDate>
        <link>http://archagon.net/blog/2016/08/21/indie-app-reliance/</link>
        <guid isPermaLink="true">http://archagon.net/blog/2016/08/21/indie-app-reliance/</guid>
        
        
        <category>technology</category>
        
      </item>
    
  </channel>
</rss>
