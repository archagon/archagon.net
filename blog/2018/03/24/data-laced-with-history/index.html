<!DOCTYPE html>
<html lang="en-US">

<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Data Laced with History: Causal Trees & Operational CRDTs ‚Äî Archagon Was Here</title>
<meta name="description" content="Alexei's pile o'stuff, featuring writing on software development, travel, photography, and more.
">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic,900">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:300,400,500,600,700&amp;subset=latin-ext">

<!-- <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:300,300i,400,400i,700,700i&amp;subset=cyrillic,cyrillic-ext"> -->
<!-- <link href="//fonts.googleapis.com/css?family=Vollkorn:400,400i,600,600i,700,700i&amp;subset=cyrillic,cyrillic-ext,latin-ext" rel="stylesheet"> -->
<!-- <link href="https://fonts.googleapis.com/css?family=Muli:700,800,900" rel="stylesheet"> -->
<!-- <link href="https://fonts.googleapis.com/css?family=Cabin:400,500,600,700" rel="stylesheet"> -->

<link rel="stylesheet" href="/css/normalize.css">
<link rel="stylesheet" href="/css/main.css">

<link rel="canonical" href="http://archagon.net/blog/2018/03/24/data-laced-with-history/">

<link rel="icon" href="/images/favicon/favicon-96x96.png">

<!-- inline category colors -->
<style>
.category-default.category-swatch {
  background-color: #a1a18c; }
.category-default.document-header-category {
  background-color: #8a8a70; }
.category-default.post-title {
  background-color: #a1a18c;
  text-shadow: 0px 2px #8a8a70; }

.category-jekyll.category-swatch {
  background-color: #9e6948; }
.category-jekyll.document-header-category {
  background-color: #7b5138; }
.category-jekyll.post-title {
  background-color: #9e6948;
  text-shadow: 0px 2px #7b5138; }

.category-travel.category-swatch {
  background-color: #957dc3; }
.category-travel.document-header-category {
  background-color: #795bb2; }
.category-travel.post-title {
  background-color: #957dc3;
  text-shadow: 0px 2px #795bb2; }

.category-programming.category-swatch {
  background-color: #f87495; }
.category-programming.document-header-category {
  background-color: #f64370; }
.category-programming.post-title {
  background-color: #f87495;
  text-shadow: 0px 2px #f64370; }

.category-technology.category-swatch {
  background-color: #fb9635; }
.category-technology.document-header-category {
  background-color: #f87c05; }
.category-technology.post-title {
  background-color: #fb9635;
  text-shadow: 0px 2px #f87c05; }

.category-design.category-swatch {
  background-color: #6ebab3; }
.category-design.document-header-category {
  background-color: #4fa69e; }
.category-design.post-title {
  background-color: #6ebab3;
  text-shadow: 0px 2px #4fa69e; }

.category-releases.category-swatch {
  background-color: #5cacfc; }
.category-releases.document-header-category {
  background-color: #2992fc; }
.category-releases.post-title {
  background-color: #5cacfc;
  text-shadow: 0px 2px #2992fc; }

.category-reviews.category-swatch {
  background-color: #38c04f; }
.category-reviews.document-header-category {
  background-color: #2c993f; }
.category-reviews.post-title {
  background-color: #38c04f;
  text-shadow: 0px 2px #2c993f; }

.category-personal.category-swatch {
  background-color: #899fbc; }
.category-personal.document-header-category {
  background-color: #6885aa; }
.category-personal.post-title {
  background-color: #899fbc;
  text-shadow: 0px 2px #6885aa; }

</style>
</head>

<body class="body-background">

<header class="site-header">
    <!-- full-width background container -->
    <div class="site-header-title-background">
        <!-- centered padded section -->
        <div class="site-header-title-container wrapper">
            <div class="site-title">
                <a href="/"><img src="/images/avatar2.jpg" class="site-title-icon"></a>
                <a href="/"><img src="/images/graphics/title.svg" class="site-title-title"></a>
            </div>
        </div>
    </div>
    <!-- full-width background container -->
    <div class="site-header-nav-background header-footer-background">
        <!-- centered padded section -->
        <div class="site-nav-container wrapper">
            <nav class="site-nav">
                <ul>
                    <li><a class="site-nav-page-link" href="/">Blog</a></li>
                    <!-- <li><a class="site-nav-page-link" href="/timeline/">Travel</a></li> -->
                    <li><a class="site-nav-page-link" href="/archive/">Archive</a></li>
                    <!-- <li><a class="site-nav-page-link" href="/projects/">Projects</a></li> -->
                    <li><a class="site-nav-page-link" href="/about/">About</a></li>
                    <li><span class="site-nav-page-link site-nav-page-link-icons"><a href="/feed.xml"><img src="/images/feed-icon.png" class="header-footer-icon"></a>/<a href="https://twitter.com/archagon"><img src="/images/twitter-icon.png" class="header-footer-icon"></a></span></li>
                </ul>
            </nav>
        </div>
    </div>
</header>

<div class="page-content">

<div class="document-post category-default" id="">
<div class="wrapper">

<header class="section-header">
    <h1 class="post-title">Data Laced with History: Causal Trees & Operational CRDTs</h1>
    <h2 class="post-meta">Mar 24, 2018<span class="document-header-categories"> <span class="document-header-category category-programming">programming</span></span></h2>
</header>

<article class="section-content">

<div class="full-width"><img src="/images/blog/causal-trees/header.jpg" /></div>

<div class="donations notification">Hello! This article took a while to cobble together. If you find it useful, please consider leaving a donation via <a class="about-icon-container" href="https://donorbox.org/crdt-article"><img class="about-social-icon" src="/images/donation-icons/donorbox.png" /> <span class="about-social-service">DonorBox</span></a>, <a class="about-icon-container" href="https://www.buymeacoffee.com/archagon"><img class="about-social-icon" src="/images/donation-icons/bmac.svg" /> <span class="about-social-service">BuyMeACoffee</span></a>, or <a class="about-icon-container" href="ethereum:0x0d5dd8a8Cca8Bf7d0122F7A1Cc76c6b0666fCC56"><img class="about-social-icon" src="/images/donation-icons/ether.png" /> <span class="about-social-service">Ethereum</span></a>. (Thought I'd try something new!) Or, just buy yourself a nice Roost through my <a class="about-icon-container" href="http://amzn.to/2D7uYxz"><img class="about-social-icon" src="/images/donation-icons/amaz.png" /> <span class="about-social-service">Amazon affiliate link</span></a>. Donation or not, thank you for reading! üòä</div>

<p>(Sorry about the length! At some point in the distant past, this was supposed to be a short blog post. If you like, you can skip straight to the <a href="#demo-concurrent-editing-in-macos-and-ios">demo section</a> which will get to the point faster than anything else.)</p>

<p>Embarrassingly, most my app development to date has been confined to local devices. Programmers like to gloat about the stupendous mental castles they build of their circutous, multi-level architectures, but not me. In truth, networks leave me quite perplexed. I start thinking about data serializing to bits, servers performing secret handshakes and negotiating history, merge conflicts pushing into app-space and starting the whole process over again‚Äîand it all just turns to mush in my head. For peace of mind, my code needs to be <em>locally provable</em>, and this means things like idempotent functions, immediate mode rendering, contiguous memory, immutable data. Networks, unfortunately, throw a giant wrench in the works.</p>

<p>Sometime last year, after realizing that most of my ideas for document-based apps would probably require CloudKit for sync and collaboration, I decided to finally take a stab at the problem. Granted, there were tons of frameworks that promised to do the hard work of data model replication for me, but I didn‚Äôt want to black-box the most important part of my code. My gut told me that there had to be some arcane bit of knowledge‚Äîsome <em>foundational abstraction</em>‚Äîthat would allow me to network my documents in a more refined and functional way, without the stateful spaghetti of conventional network architectures. Instead of downloading a Github framework and <a href="http://amzn.to/2iigBOI">smacking the build button</a>, I wanted to develop a base set of skills that would allow me to easily network <em>any</em> document-based app in the future, even if I was starting from scratch.</p>

<!--more-->

<p>The first order of business was to devise a wishlist for my fantastical system:</p>

<ul>
  <li>Most obviously, users should be able to edit their documents immediately, without even touching the network. (In other words, the system should only require <em>optimistic concurrency</em>.)</li>
  <li>Sync should happen in the background, entirely separate from the main application code, and any remote changes should be seamlessly integrated in real-time. (Put another way, sync should be treated as a kind of progressive enchancement.)</li>
  <li>Merge should always be automatic, even for concurrent edits. The user should never be faced with a ‚Äúpick the correct revision‚Äù dialog box.</li>
  <li>A user should be able to work on their document offline for an indefinite period of time without accruing ‚Äúsync debt‚Äù. (Meaning that if, for example, sync is accomplished by way of an operation log, performance should not suffer even if a user spends a month offline and then sends all their hundreds of changes at once.)</li>
  <li>Secondary data structures and state should be minimized. Most of the extra information required for sync should be stored in the same place as the document, and moving the document to a new device should not break sync. (No out-of-band metadata or caches!)</li>
  <li>Network back-and-forth should be condensed down to a bare minimum, and rollbacks and re-syncs should practically never happen. To the greatest possible degree, network communication should be stateless and dumb.</li>
  <li>To top it all off, my chosen technique had to pass the ‚ÄúPhD Test‚Äù. That is to say, one shouldn‚Äôt need a PhD to understand and implement the chosen approach for custom data models.</li>
</ul>

<p>After musing over my bullet points, it occurred to me that the network problems I was dealing with‚Äîcloud sync, editing across multiple devices, real-time collaboration, offline support, and reconciliation of distant or conflicting revisions‚Äîwere all really different facets the same problem. Namely: how do we design a system such that any two revisions of the same document could always be merged deterministically and sensibly without requiring user intervention? Was such a thing even possible?</p>

<p>To start with, a document could be viewed as a collection of basic data fields: registers, sequences, dictionaries, and so forth. From the perspective of something like a distributed database, it was actually quite trivial to resolve conflicts across the network in this kind of row: just keep overwriting each field with the version sporting the highest timestamp. Of course, for anything other than basic registers, this was a terrible approach. Sequences and dictionaries weren‚Äôt blobs of homogenous data, but complex, mutable structures that users were directly manipulating‚Äînot just overwriting with each change. On merge, with databases and plain files alike, the common solution was to simply punt any conflicts to app-space so that a human could deal with them. But if these mutations were defined in terms of lower-level operations specific to each data type, could that information perhaps be leveraged to implement automatic conflict resolution?</p>

<p>In hope of uncovering some prior art, I started by looking at the proven leader in the field, Google Docs. Venturing down the deep rabbit hole of <a href="https://en.wikipedia.org/wiki/Collaborative_real-time_editor">real-time collaborative editing</a> techniques, I discovered that many of the problems I faced fell under the umbrella of <a href="https://en.wikipedia.org/wiki/Eventual_consistency">strong eventual consistency</a>. Unlike the more conventional <a href="https://en.wikipedia.org/wiki/Strong_consistency">strong consistency</a> model, where all clients receive changes in identical order and rely on locking to some degree, strong <em>eventual</em> consistency allows clients to individually diverge and then arrive at a final, consistent result once each update has been received. (Or, in a word, when the network is <em>quiescent</em>.)</p>

<p>There were a number of tantalizing techniques to investigate in this field, and I kept several questions in mind for my analysis. Could a given technique be generalized to arbitrary document formats and data types? Did the technique pass the PhD Test? And was it possible to use the technique in an architecture with smart clients and dumb servers?</p>

<p>The reason for that last question was CloudKit Sharing, a framework introduced in iOS 10. For the most part, this framework functioned as a superset of regular CloudKit, requiring only minor code changes to enable document sharing in an app. A developer didn‚Äôt even have to worry about connecting users or showing custom UI: Apple did most of the hard work in the background and leveraged standard system dialogs to make it work. But almost two years later, <a href="https://github.com/search?l=Swift&amp;q=UICloudSharingController&amp;type=Code&amp;utf8=‚úì">on the order of no one</a> seemed to be using it. Why was this? After all, most Apple APIs tended to be readily adopted, especially when they allowed the developer to expand into system areas which were normally out of bounds.</p>

<p>My hunch was that CloudKit Sharing forced the issue of real-time collaboration over a relatively dumb channel, which was a problem outside the purview of conventional sync approaches. CloudKit allowed developers to easily store, retrieve, and listen for new data, but not much else besides. Concurrent editing made this a problem. Unlike in the single-user/multi-device case, you couldn‚Äôt just pop up a merge dialog every time somebody touched your open document. But you also couldn‚Äôt resolve conflicts on the server side, since CloudKit did not permit developers to run custom code on their end. The only remaining options seemed to be some sort of ugly, heuristic auto-merge or data-dropping last-write-wins, neither of which was palatable by modern standards. Real-time collaboration along the lines of Google Docs appeared to be impossible using this system! But was it really?</p>

<p>I realized that this was my prize to be won. If I could figure out a way to develop auto-merging documents, I‚Äôd be able to implement sync and collaboration in my apps over CloudKit for free while also adopting Apple‚Äôs first-party sharing UI. So this became my ultimate research goal: a collaborative iPhone text editing demo that synced entirely over Apple‚Äôs servers. (And here‚Äôs a spoiler: <a href="#demo-concurrent-editing-in-macos-and-ios">it worked!</a>)</p>

<div class="toc-wrapper">
<div class="toc">
<div class="toc-header">
<h1>Table of Contents</h1>
</div>
<div class="toc-links">
<ul>
<li><a href="#convergence-techniques-a-high-level-overview">Convergence Techniques: A High-Level Overview</a>
<ul>
<li><a href="#operational-transformation">Operational Transformation</a></li>
<li><a href="#conflict-free-replicated-data-types">Conflict-Free Replicated Data Types</a></li>
<li><a href="#differential-synchronization">Differential Synchronization</a></li>
<li><a href="#finding-the-best-approach">Finding the Best Approach</a></li>
</ul>
</li>
<li><a href="#causal-trees">Causal Trees</a></li>
<li><a href="#demo-concurrent-editing-in-macos-and-ios">Demo: Concurrent Editing in macOS and iOS</a></li>
<li><a href="#operational-replicated-data-types">Operational Replicated Data Types</a>
<ul>
<li><a href="#what-is-an-ordt">What Is an ORDT?</a></li>
<li><a href="#the-ordt-pipeline">The ORDT Pipeline</a></li>
<li><a href="#garbage-collection">Garbage Collection</a></li>
<li><a href="#ordt-design--implementation">ORDT Design &amp; Implementation</a></li>
</ul>
</li>
<li><a href="#causal-trees-in-depth">Causal Trees In Depth</a>
<ul>
<li><a href="#implementation-details">Implementation Details</a></li>
<li><a href="#representing-non-string-objects">Representing Non-String Objects</a></li>
<li><a href="#performance">Performance</a></li>
<li><a href="#missing-features--future-improvements">Missing Features &amp; Future Improvements</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>
</div>
</div>

<h1 id="convergence-techniques-a-high-level-overview">Convergence Techniques: A High-Level Overview</h1>

<p>There are a few basic terms that are critical to understanding eventual consistency. The first is <strong>causality</strong>. An operation is <em>caused</em> by another operation when it directly modifies or otherwise involves the results of that operation, and determining causality is critical for reconstructing a sensible timeline (or <strong>linearization</strong>) of operations across the network. (An operation that causes another operation must always be ordered first.) However, we can‚Äôt always determine direct causality in a general way, so algorithms often assume that an operation is causally ahead of another operation if the site generating the newer operation has already seen the older operation on creation. (In other words, every operation seen by a site at the time a new operation is created is in that operation‚Äôs <em>causal past</em>.) This ‚Äúsoft‚Äù causality can be determined using a variety of schemes. The simplest is a <a href="https://en.wikipedia.org/wiki/Lamport_timestamps">Lamport timestamp</a>, which requires that every new operation have a higher Lamport timestamp than every other known operation, including any remote operations received. (Note that this approach is stateless. As long as each operation retains its Lamport timestamp, you don‚Äôt need any extra data in the system to determine causality.) Although there are eventual consistency schemes that can receive operations in any order, most algorithms rely on operations arriving at each site in their <strong>causal order</strong> (e.g. <code class="highlighter-rouge">insert A</code> necessarily arriving before <code class="highlighter-rouge">delete A</code>). When discussing convergence schemes, we can often assume causal order since it can be implemented fairly mechanically on the transport layer. If two operations are not causal‚Äîif they were created simultaneously on different sites without knowledge of each other‚Äîthey are said to be <strong>concurrent</strong>. An operation log in causal order can be described as having a <strong>partial order</strong>, since concurrent operations might be in different positions on different clients. If the log is guaranteed to be identical on all clients, it has a <strong>total order</strong>. Most of the hard work in eventual consistency involves reconciling and ordering these concurrent operations. Generally speaking, concurrent operations have to be made to <strong>commute</strong>, or have the same effect on the data regardless of their order of arrival. This can be done in a variety of ways<sup id="fnref:commutes"><a href="#fn:commutes" class="footnote">1</a></sup>.</p>

<p>Now, there are two competing approaches in strong eventual consistency state-of-the-art, both tagged with rather unappetizing initialisms: <a href="https://en.wikipedia.org/wiki/Operational_transformation">Operational Transformation</a> (OT) and <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">Conflict-Free Replicated Data Types</a> (CRDTs). Fundamentally, these approaches tackle the same problem. Given an object that has been edited by an arbitrary number of connected devices, how do we coalesce and apply their changes in a consistent way, even when those changes might be concurrent or arrive out of order? And, moreover, what do we do if a user goes offline for a long time, or if the network is unstable, or even if we‚Äôre in a peer-to-peer environment with no single source of truth?</p>

<h2 id="operational-transformation">Operational Transformation</h2>

<p><a href="https://en.wikipedia.org/wiki/Operational_transformation">Operational Transformation</a> is the proven leader in the field, notably used by Google Docs and (now Apache) Wave as well as Etherpad and ShareJS. Unfortunately, it is only ‚Äúproven‚Äù insofar as you have a company with billions of dollars and hundreds of PhDs at hand, as the problem is <em>hard</em>. With OT, each user has their own copy of the data, and each atomic mutation is called an <strong>operation</strong>. (For example, <code class="highlighter-rouge">insert A at index 2</code> or <code class="highlighter-rouge">delete index 3</code>.) Whenever a user mutates their data, they send their new operation to all their peers, often in practice through a central server. OT generally makes the assumption that the data is a black box and that incoming operations will be applied directly on top without the possibility of a rebase operation. Consequently, the only way to ensure that concurrent operations will commute in their effect is to <strong>transform</strong> them depending on their order.</p>

<p>Let‚Äôs say Peer A inserts a character in a string at position 3, while Peer B simultaneously deletes a character at position 2. If Peer C, who has the original state of the string, receives A‚Äôs edit before B‚Äôs, everything is peachy keen. If B‚Äôs edit arrives first, however, A‚Äôs insertion will be in the wrong spot. A‚Äôs insertion position will therefore have to be transformed by subtracting the length of B‚Äôs edit. This is fine for the simple case of two switched edits, but it gets a whole lot more complicated when you start dealing with more than a single pair of concurrent changes. (An algorithm that deals with this case‚Äîand thus, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.933&amp;rep=rep1&amp;type=pdf">provably</a>, with any conceivable case‚Äîis said to be have the ‚ÄúCP2/TP2‚Äù property rather than the pairwise ‚ÄúCP1/TP1‚Äù property. Yikes, where are professional namers when you need them?) In fact, the majority of published algorithms for string OT actually have subtle bugs in certain edge cases (such as the so-called ‚Äú<a href="http://www3.ntu.edu.sg/home/czsun/projects/otfaq/#_Toc321146192">dOPT puzzle</a>‚Äù), meaning that they aren‚Äôt strictly convergent without occasional futzing and re-syncing by way of a central server. And while the idea that you can treat your model objects strictly in terms of operations is elegant in its premise, the fact that adding a new operation to the schema requires figuring out its interactions with <em>every existing operation</em> is nearly impossible to grapple with.</p>

<h2 id="conflict-free-replicated-data-types">Conflict-Free Replicated Data Types</h2>

<p><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">Conflict-Free Replicated Data Types</a> are the new hotness in the field. In contrast to OT, the CRDT approach considers sync in terms of the underlying data structures, not sequences of operations. A¬†CRDT, at a high level, is a type of object that can be merged with any objects of the same type, in arbitrary order, to produce an identical union object. CRDT merge must be associative, commutative, and idempotent, and the resulting CRDT of each mutation or merge must be ‚Äúgreater‚Äù than than all its inputs. (Mathematically, this flow is said to form a <em>monotonic semilattice</em>.) As long as each connected peer eventually receives the updates of every other peer, the results will provably converge‚Äîeven if one peer happens to be a month behind. This might sound like a tall order, but you‚Äôre already aware of several simple CRDTs. For example, no matter how you permute the merge order of any number of insert-only sets, you‚Äôll still end up with the same union set in the end. Really, the concept is quite intuitive!</p>

<p>Of course, simple sets aren‚Äôt enough to represent arbitrary data, and much of CRDT research is dedicated to finding new and improved ways of implementing sequence CRDTs, often under the guise of string editing. Algorithms vary, but this is often accomplished by giving each individual letter its own unique identifier, then giving each letter a reference to its intended neighbor instead of dealing with indices. On deletion, letters are usually replaced with <strong>tombstones</strong> (placeholders), allowing an operation that deletes a character and another that references it to concurrently execute. This does tend to mean that sequence CRDTs perpetually grow in proportion to the number of deleted characters in a document, though there are various ways of dealing with this accumulated garbage.</p>

<p>One last thing to note is that there are actually two kinds of CRDTs: CmRDTs and CvRDTs. (Seriously, there‚Äôs got to be a better way to name these things‚Ä¶) CmRDTs, or operation-based CRDTs, only require peers to send each other their changes<sup id="fnref:op-crdt"><a href="#fn:op-crdt" class="footnote">2</a></sup>, but place some constraints on the transport layer. (For instance, exactly-once and/or causal delivery, depending on the CmRDT in question.) With CvRDTs, or state-based CRDTs, peers send each other their full data objects and then merge them locally, placing no constraints on the transport layer but taking up more bandwidth and possibly CPU time. Both types of CRDT are equivalent and can be converted to either form.</p>

<h2 id="differential-synchronization">Differential Synchronization</h2>

<p>There‚Äôs actually one more technique that‚Äôs worth discussing, and it‚Äôs a bit of an outlier. This is Neil Fraser‚Äôs <a href="https://neil.fraser.name/writing/sync/">Differential Synchronization</a>. Used in an earlier version of Google Docs before their flavor of OT was implemented, Differential Sync uses <a href="https://neil.fraser.name/writing/diff/">contextual diffing</a> between local revisions of documents to generate streams of frequent, tiny edits between peers. If there‚Äôs a conflict, the receiving peer uses <a href="https://neil.fraser.name/writing/patch/">fuzzy patching</a> to apply the incoming changes as best as possible, then contextually diffs the resulting document with a reproduced copy of the sender‚Äôs document (using a cached ‚Äúshadow copy‚Äù of the last seen version) and sends the new changes back. This establishes a sort of incremental sync loop. Eventually, all peers converge on a final, stable document state. Unlike with OT and CRDTs, the end result is not mathematically defined, but instead relies on the organic behavior of the fuzzy patching algorithm when faced with diffs of varying contexts and sizes.</p>

<h2 id="finding-the-best-approach">Finding the Best Approach</h2>

<p>Going into this problem, my first urge was to adopt Differential Sync. One might complain that this algorithm has too many subjective bits for production use, but that‚Äôs exactly what appealed to me about it. Merge is a complicated process that often relies on heuristics entirely separate from the data format. A human would merge two list documents and two prose documents very differently, even though they might both be represented as text. With Differential Sync, all this complex logic is encapsulated in the diff and patch functions. Much like git, the system is content-focused in the sense that the resulting patches don‚Äôt have any particular insight into the inner workings of the data type. The implementation of the data format could be refactored as needed, and the diff and patch functions could be tweaked and improved over time, and neither system would have to know about changes to the other. It also means that the documents in their original form could be preserved in their entirety server-side, synergizing nicely with Dropbox-style cloud backup. It felt like the perfect dividing line of abstraction.</p>

<p>But studying Differential Sync further, I realized that a number of details made it a non-starter. First, though the approach seems simple on the surface, its true complexity is concealed by the implementation of diff and patch. This class of algorithm works well for strings, but you basically need to be a seasoned algorithms expert to design one for a new data type. (Worse: the inherent fuzziness depends on non-objective metrics, so you might only figure out the effectiveness of new diff and patch algorithms after prolonged use and testing, not through formal analysis.) Second, diffing and patching as they currently exist are really meant for loosely-structured data formats such as strings and images. Barring conversion to text-based intermediary formats, tightly structured data would be very difficult to diff and patch while maintaining consistency. Next, there are some issues with using Differential Sync in an offline-first environment. Clients have to store their entire diff history while offline, and then, on reconnection, send the whole batch to their peers for a very expensive merge. Worse yet, assuming that other sites had been editing away in the meantime, distantly-divergent versions would very likely fail to merge on account of out-of-date context information in the diffs and lose much of the data for the reconnected peer. Finally, Differential Sync only allows one packet at a time to be in flight between two peers. If there are network issues, the whole thing grinds to a halt.</p>

<p>Begrudgingly, I had to abandon the elegance of Differential Sync and decide between the two deterministic approaches. CRDTs raised some troubling questions, including the impact of per-letter metadata and the necessity of tombstones in most sequence CRDTs. You could end up with a file that looked tiny (or even empty) but was in fact enormous under the hood. However, OT was a no-go right from the start. One, the event-based system would have been untenable to build on top of a simple database like CloudKit. You really needed active servers or peer-to-peer connections for that. And two, I discovered that the few known sequence OT algorithms guaranteed to converge in all cases‚Äîthe ones with the coveted CP2/TP2 property‚Äîended up relying on tombstones anyway! (If you‚Äôre interested, Raph Levien touches on this curious overlap <a href="https://medium.com/@raphlinus/towards-a-unified-theory-of-operational-transformation-and-crdt-70485876f72f">in this article</a>.) So it didn‚Äôt really matter which choice I made. If I wanted the resiliency of a provably convergent system, I had to deal with metadata-laden data structures that left some trace of their deleted elements.</p>

<p>And with their focus on data over process, CRDTs pointed to a paradigm shift in networked computing. A document format based on CRDTs‚Äîa voraciously-mergable ‚Äúgolden file‚Äù‚Äîwould push network issues completely of the way. The system would be completely functional, even in communication with remote devices. You‚Äôd be able to throw different versions of the same file together in any order to obtain the same merge result, never once having to ask anything of the user. Everything would work without quirks in offline mode regardless of how much time had passed. Instead of dealing with the endless headaches of coordination, data could be promiscuously streamed to any device listening for changes. The document would be topology-agnostic to such a degree that you could use it in a peer-to-peer environment, send it between phone and laptop via Bluetooth, share it with multiple local applications, and sync it through a traditional central database. All at the same time!</p>

<p>Here, a wily political thought crossed my mind. Could this be the chance to finally break free from the shackles of the cloud? It always felt like such an affront that my data had to snake through a tangle of corporate servers in order to reach the device next to me. We used to happily share files across applications and even operating systems, and now everything was funneled through these monolithic black boxes. What happened? How did we let computing become so darn <em>undemocratic</em>? It had gotten so bad that we <em>expected</em> our data and workflows to vanish whenever a startup got itself acquired!</p>

<p>CRDTs promised document formats the power to take on full responsibility over sync and collaboration, reverting the server from its gatekeeper role into a dumb, hot-swappable conduit. With this technology, we could return data to the control of its users once more! But the road here was fresh and unpaved, and I needed to figure out if I could use these structures in a performant and space-efficient way for non-trivial applications.</p>

<figure>
<img src="/images/blog/causal-trees/semilattice.svg" style="width:27rem" />
<figcaption>The mythical, eminently-mergable golden file in its adventures through the semilattice.</figcaption>
</figure>

<p>The next step was to read through the academic literature on CRDTs. There was a group of usual suspects for the hard case of sequence (text) CRDTs: <a href="https://hal.archives-ouvertes.fr/inria-00108523/document">WOOT</a>, <a href="https://hal.inria.fr/inria-00397981/document">Treedoc</a>, <a href="https://hal.inria.fr/inria-00336191/document">Logoot</a>/<a href="https://hal.archives-ouvertes.fr/hal-00921633/document">LSEQ</a>, and <a href="https://pdfs.semanticscholar.org/8470/ae40470235604f40382aea4747275a6f6eef.pdf">RGA</a>. WOOT is the progenitor of the genre and makes each character in a string reference its adjacent neighbors on both sides. Recent analysis has shown this to be inefficient compared to newer approaches. Treedoc has a similar early-adoptor performance penalty and additionally requires coordination for its garbage collection‚Äîa no-go for true decentralization. Logoot (which is optimized further by LSEQ) curiously avoids tombstones by treating each sequence item as a unique point along a dense (infinitely-divisible) number line, and in exchange adopts item identifiers (similar to bignums) which have unbounded growth. Unfortunately, it has a problem with <a href="https://stackoverflow.com/questions/45722742/logoot-crdt-interleaving-of-data-on-concurrent-edits-to-the-same-spot">interleaved text on concurrent edits</a>. RGA makes each character implicitly reference its intended leftmost neighbor and uses a hash table to make character lookup efficient. It also features an additional update operation alongside the usual insert and delete. This approach often comes out ahead in benchmark comparisons, though the paper is annoyingly dense in theory. I also found a couple of recent, non-academic CRDT designs such as <a href="https://github.com/y-js/yjs">Y.js</a> and <a href="http://google.github.io/xi-editor/docs/crdt-details.html">xi</a>, both of which bring something new to the table but feel rather convoluted in comparison to the good-enough RGA. In almost all cases, conflicts between concurrent changes were resolved by way of a creator UUID plus a logical timestamp per character. Sometimes, they were discarded when an operation was applied; other times, they persisted even after merge.</p>

<p>Reading the literature was highly educational, and I now had a good intuition about the behavior of convergent sequence CRDTs. But I just couldn‚Äôt find very much in common between the disparate approaches. Each one brought its own operations, proofs, optimizations, conflict resolution methods, and garbage collection schemes to the table. Many of the papers blurred the line between theory and implementation, making it even harder to suss out any underlying principles. I felt confident using these algorithms for convergent arrays, but I wasn‚Äôt quite sure how to build my own convergent data structures using the same principles.</p>

<p>Finally, I discovered the one key CRDT that made things click for me.</p>

<h1 id="causal-trees">Causal Trees</h1>

<p>A a state-based CvRDT, on a high level, can be viewed as a data blob along with a commutative, associative, and idempotent merge function that can always generate a monotonically further-ahead third blob from any given two. An operation-based CmRDT, meanwhile, can be viewed as a data blob together with a stream of commutative-in-effect (and perhaps causally-ordered) operations that mutate and monotonically push it forward. Could these two systems be combined? Can we treat the data blob as something other than a black box?</p>

<p>Say you‚Äôre designing a sequence CvRDT from scratch. Instead of picking an existing sequence CRDT, you‚Äôve been wickedly tempted by the operational approach of CmRDTs! You wonder if it‚Äôs possible to take those CmRDT operations and fold them into an efficient CvRDT data structure, combining the benefits of a ubiquitously-mergable data structure with the flexibility and expressiveness of defining your model in terms of atomic operations.</p>

<p>To have some data to work with, here‚Äôs an example of a concurrent string mutation.</p>

<figure>
<img src="/images/blog/causal-trees/network-chart.svg" style="width:40rem" />
<figcaption><span>The small numbers over the letters are <a href="https://en.wikipedia.org/wiki/Lamport_timestamps">Lamport timestamps</a>.</span></figcaption>
</figure>

<p>Site 1 types ‚ÄúCMD‚Äù, sends its changes to Site 2 and Site 3, then resumes its editing. Sites 2 and 3 then make their own changes and send them back to Site 1 for the final merge. The result, ‚ÄúCTRLALTDEL‚Äù, is the most intuitive merge we might expect: insertions and deletions all persist, runs of characters don‚Äôt split up, and most recent changes come first.</p>

<p>First idea: just take the standard set of array operations (<code class="highlighter-rouge">insert A at index 0</code>, <code class="highlighter-rouge">delete index 3</code>, etc.), turn each operation into its own immutable struct, stick the structs into an array in their creation order, and read them back to reconstruct the original array as needed. (In other words, define your CvRDT to be an event log.) This won‚Äôt be convergent by default since there needs to be some way to establish a total order of operations when merging two such arrays, but it‚Äôs easy to fix this by giving each operation a globally-unique ID in the form of an owner UUID<sup id="fnref:uuid"><a href="#fn:uuid" class="footnote">3</a></sup> plus a Lamport timestamp. With this scheme, no two operations can ever have the same ID: operations from the same owner will have different timestamps, while operations from different owners will have different UUIDs. The Lamport timestamps will order operations causally while the UUID will be used for tiebreaking when concurrent operations happen to have the same Lamport timestamp. Now, when a new operational array arrives from a remote peer, the merge is as simple as iterating through both arrays and shifting any new operations to their proper spots: an elementary merge sort.</p>

<div class="mostly-full-width"><img src="/images/blog/causal-trees/indexed.svg" /></div>

<p>Success: it‚Äôs an operation-based, fully-convergent CvRDT! Well, sort of. There are two major issues here. First, reconstructing the original array by processing the full operational array has <em>O</em>(<em>n</em><sup>2</sup>) complexity<sup id="fnref:complexity"><a href="#fn:complexity" class="footnote">4</a></sup>, and it has to happen on every key press to boot. Second, intent is completely clobbered. Reading the operations back, we get something along the lines of ‚ÄúCTRLDATLEL‚Äù (with a bit of handwaving when it comes to inserts past the array bounds). Just because a data structure converges doesn‚Äôt mean it makes a lick of sense! As shown in the earlier OT section, concurrent index-based operations can be made to miss their intended characters depending on the order. (Recall that this is the problem OT solves by transforming operations, but here our operations are immutable.) In a sense, this is because the operations are specified incorrectly. They make an assumption that doesn‚Äôt get encoded in the operations themselves‚Äîthat an index can always uniquely identify a character‚Äîand thus lose the commutativity of their intent when this turns out not to be the case.</p>

<p>OK, so the first step is to fix the intent problem. Fundamentally, <code class="highlighter-rouge">insert A at index 0</code> isn‚Äôt <em>really</em> what the user wants to do. People don‚Äôt think in terms of indices. They want to insert a character at the cursor position, which is perceived as being between two letters‚Äîor more simply, to the immediate right of a single letter. We can encode this by switching our operations to the format <code>insert A<sup>id</sup> after B<sup>id</sup></code>, where each letter in the array is uniquely identified. Given causal order and assuming that deleted characters persist until any operations that reference them are processed, the intent of the operations is now commutative: there will only ever be that one specific ‚ÄòB‚Äô in the array, allowing us to always position ‚ÄòA‚Äô just as the user intended.</p>

<p>So how do we identify a particular letter? Just ‚ÄòA‚Äô and ‚ÄòB‚Äô are ambiguous, after all. We could generate a new ID for each inserted letter, but this isn‚Äôt necessary: we already have unique UUID/timestamp identifiers for all our operations. Why not just use operation identifiers as proxies for their output? In other words, an <code class="highlighter-rouge">insert A</code> operation could stand for that particular letter ‚ÄòA‚Äô when referenced by other operations. Now, no extra data is required, and everything is still defined in terms of our original atomic and immutable operations.</p>

<div class="mostly-full-width"><img src="/images/blog/causal-trees/causal.svg" /></div>

<p>This is significantly better than before! We now get ‚ÄúCTRLALTDEL‚Äù correctly ordered and even preserving character runs as desired. But performance is still an issue. As it stands, the output array would still take <em>O</em>(<em>n</em><sup>2</sup>) to reconstruct. The main roadblock is that array insertions and deletions tend to be <em>O</em>(<em>n</em>) operations, and we need to replay our entire history whenever remote changes come in or when we‚Äôre recreating the output array from scratch. Array <em>push</em> and <em>pop</em>, on the other hand, are only <em>O</em>(1) amortized. What if instead of sorting our entire operational array by timestamp+UUID, we positioned operations in the order of their output? This could be done by placing each operation to the right of its causal operation (parent), then sorting it in reverse timestamp+UUID order among the remaining operations<sup id="fnref:rga"><a href="#fn:rga" class="footnote">5</a></sup>. In effect, this would cause the operational array to mirror the structure of the output array. The result would be identical to the previous approach, but the speed of execution would be substantially improved.</p>

<div class="mostly-full-width"><img src="/images/blog/causal-trees/causal-ordered.svg" /></div>

<p>With this new order, local operations require a bit of extra processing when getting inserted into the operational array. Instead of simply appending to the back, they have to first locate their parent, then find their spot among the remaining operations: <em>O</em>(<em>n</em>) instead of <em>O</em>(1). In return, producing the output array is now only <em>O</em>(<em>n</em>), since we can read the operations in order and (mostly) push/pop elements in the output array as we go along<sup id="fnref:deleteref"><a href="#fn:deleteref" class="footnote">6</a></sup>. In fact, we can almost treat this operational array <em>as if it were the string itself</em>, even going as far as using it as a backing store for a fully-functional <code class="highlighter-rouge">NSMutableString</code> subclass (with some performance caveats). The operations are no longer just instructions, but also the output data!</p>

<p>(Observe that throughout this process, we have not added any extra data to our operation structs. We have simply arranged them in a more precise causal order than the default timestamp+UUID sort, which is possible since we‚Äôre aware of the precise causal characteristics of our data model. For example, we know that no matter how high a timestamp an insert operation might have, its final position in the string is solely determined by its parent and any concurrent (sibling) sequences of operations with a higher timestamp+UUID. Every other operation in timestamp+UUID order between that operation and its parent is irrelevant, even if the Lamport timestamps conservatively imply otherwise. This new order allows an insert operation to place its character in the output array right as it is read. In other words: the Lamport timestamp is a convenient upper bound on causality, but we can do a lot better with domain knowledge.)</p>

<p>Pulled out of its containing array, we can see that what we‚Äôve designed is, in fact, an operational <em>tree</em>‚Äîone which happens to be implicitly stored as a depth-first, in-order traversal in contiguous memory. Concurrent edits are sibling branches. Subtrees are runs of characters. By the nature of reverse timestamp+UUID sort, sibling subtrees are sorted in the order of their head operations.</p>

<p><img src="/images/blog/causal-trees/tree.svg" style="width:40rem" /></p>

<p>This is the underlying premise of the Causal Tree CRDT.</p>

<p>In contrast to all the other CRDTs I‚Äôd been looking into, the design presented in Victor Grishchenko‚Äôs <a href="http://www.ds.ewi.tudelft.nl/~victor/articles/ctre.pdf">brilliant paper</a> was simultaneously clean, performant, and consequential. Instead of dense layers of theory and twisting data structures, everything was centered around the idea of atomic, immutable, and globally unique operations, stored in low-level data structures and directly usable as the data they represented. From this, entire classes of features effortlessly followed.</p>

<p>The rest of the paper will be describing <a href="https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTFramework">my own CT implementation in Swift</a>, incorporating most of the concepts in the original paper but with tweaks to certain details based on further research.</p>

<p>In CT parlance, the operation structs that make up the tree are called <strong>atoms</strong>. Each atom has a unique <strong>identifier</strong> comprised of a <strong>site</strong> UUID, <strong>index</strong>, and Lamport <strong>timestamp</strong><sup id="fnref:awareness"><a href="#fn:awareness" class="footnote">7</a></sup>. The index and timestamp serve the same role of logical clock, and the data structure could be made to work with one or the other in isolation. (The reason to have both is to enable certain optimizations: the index for <em>O</em>(1) atom lookups by identifier, and the timestamp for <em>O</em>(1) causality queries between atoms.) The heart of an atom is its <strong>value</strong>, which defines the behavior of the operation and stores any relevant data. For an insert operation, this would be the new character to place, while delete operations contain no extra data. An atom also has a <strong>cause</strong> (or parent), which is the identifier of the atom it is said to ‚Äúfollow‚Äù. As explained above, this causal link simply represents the character to the left of an insertion or the target of a deletion. Assuming that the site is stored in 2 bytes<sup id="fnref:uuid2"><a href="#fn:uuid2" class="footnote">8</a></sup>, the index in 4 bytes, and the timestamp in 4 bytes, each character in a basic Causal Tree string is, at minimum, 12√ó the size of an ordinary C-string character.</p>

<p>In Swift code, an atom might look something like this:</p>

<div class="language-swift highlighter-rouge"><pre class="highlight"><code><span class="kd">struct</span> <span class="kt">Id</span><span class="p">:</span> <span class="kt">Codable</span><span class="p">,</span> <span class="kt">Hashable</span>
<span class="p">{</span>
    <span class="k">let</span> <span class="nv">site</span><span class="p">:</span> <span class="kt">UInt16</span>
    <span class="k">let</span> <span class="nv">index</span><span class="p">:</span> <span class="kt">UInt32</span>
    <span class="k">let</span> <span class="nv">timestamp</span><span class="p">:</span> <span class="kt">UInt32</span>
<span class="p">}</span>

<span class="kd">struct</span> <span class="kt">Atom</span><span class="o">&lt;</span><span class="kt">T</span><span class="p">:</span> <span class="kt">Codable</span><span class="o">&gt;</span><span class="p">:</span> <span class="kt">Codable</span>
<span class="p">{</span>
    <span class="k">let</span> <span class="nv">id</span><span class="p">:</span> <span class="kt">Id</span>
    <span class="k">let</span> <span class="nv">cause</span><span class="p">:</span> <span class="kt">Id</span>
    <span class="k">let</span> <span class="nv">value</span><span class="p">:</span> <span class="kt">T</span>
<span class="p">}</span>
</code></pre>
</div>

<p>While a string value might look like this:</p>

<div class="language-swift highlighter-rouge"><pre class="highlight"><code><span class="kd">enum</span> <span class="kt">StringValue</span><span class="p">:</span> <span class="kt">Codable</span>
<span class="p">{</span>
    <span class="k">case</span> <span class="n">null</span>
    <span class="k">case</span> <span class="nf">insert</span><span class="p">(</span><span class="nv">char</span><span class="p">:</span> <span class="kt">UInt16</span><span class="p">)</span>
    <span class="k">case</span> <span class="n">delete</span>
  
    <span class="c1">// insert Codable boilerplate here</span>
<span class="p">}</span>

<span class="kd">typealias</span> <span class="kt">StringAtom</span> <span class="o">=</span> <span class="kt">Atom</span><span class="o">&lt;</span><span class="kt">StringValue</span><span class="o">&gt;</span>
</code></pre>
</div>

<p>What‚Äôs great about this representation is that Swift automatically compresses enums with associated values to their smallest possible byte size, i.e. the size of the largest associated value plus a byte for the case, or even less if Swift can determine that a value type has some extra bits available.</p>

<p>For convenience, a CT begins with a ‚Äúzero‚Äù root atom, and the ancestry of each subsequent atom can ultimately be traced back to it. The depth-first, in-order traversal of our operational tree is called a <strong>weave</strong>, equivalent to the operational array discussed earlier. Instead of representing our tree as an inefficient tangle of pointers, we store it in memory as this weave array. Additionally, since we know the creation order of every atom on each site by way of its index (or timestamp), and since a CT by definition is not allowed to contain any causal gaps, we can always derive a given site‚Äôs exact sequence of operations from the beginning of time. This sequence of site-specific atoms in creation order is called a <strong>yarn</strong>. Yarns are more of a cache than a primary data structure in a CT, but I keep them around together with the weave to enable <em>O</em>(1) atom lookups. To pull up an atom based on its identifier, all you have to do is grab the site‚Äôs yarn array and read out the atom at the identifier‚Äôs index.</p>

<figure>
<img src="/images/blog/causal-trees/yarns.svg" style="width:53rem" />
<figcaption>Each row, or yarn, represents the full, contiguous sequence of operations for a given site.</figcaption>
</figure>

<p>Storing the tree as an array means we have to be careful while modifying it, or our invariants will be invalidated and the whole thing will fall apart. When a local atom is created and parented to another atom, it is inserted immediately to the right of its parent in the weave. It‚Äôs easy to show that this logic preserves the sort order: since the new atom necessarily has a higher Lamport timestamp than any other atom in the weave, it belongs in the spot closest to the parent. On merge, we have to be a bit more clever if we want to keep things <em>O</em>(<em>n</em>). The naive solution‚Äîiterating through the incoming weave and individually sorting each new atom into our local weave‚Äîwould be <em>O</em>(<em>n</em><sup>2</sup>). If we had an easy way to compare any two atoms, we could perform a simple and efficient merge sort. Unfortunately, the order of two atoms is a non-binary function since it involves ancestry information in addition to the timestamp and UUID. In other words, you can‚Äôt write a simple comparator for two atoms in isolation without also querying the full CT.</p>

<p>Fortunately, we can use our knowledge of the underlying tree structure to keep things simple. (The following algorithm assumes that both weaves are correctly ordered and preserve all their invariants.) Going forward, it‚Äôs useful to think of each atom as the head of a subtree in the larger CT. On account of the DFS ordering used for the weave, all of an atom‚Äôs descendants are contained in a contiguous range immediately to its right called a <strong>causal block</strong>. To merge, we compare both weaves atom-by-atom until we find a mismatch. There are three possibilities in this situation: the local CT has a subtree missing from the incoming CT, the incoming CT has a new subtree missing from the local CT, or the two CTs have concurrent sibling subtrees. (Proving that the only possible concurrent change to the same spot is that of sibling subtrees is an exercise left to the reader.) The first two cases are easy to check and deal with: verify that one of the two atoms appears in the other‚Äôs CT and keep inserting or fast-forwarding atoms until the two weaves line up again. For the last case, we have to arrange the two causal blocks in their proper order. The end of a causal block is easy to determine using an algorithm featured in the paper<sup id="fnref:lemma"><a href="#fn:lemma" class="footnote">9</a></sup>, and the only thing left to do after that is to compare the two head atoms and arrange the causal blocks accordingly. (Note that any stored yarns must also be updated as the weave changes!)</p>

<p>One more data structure to note is a collection of site+timestamp pairs called a <strong>weft</strong>, which is simply a fancy name for a <a href="https://en.wikipedia.org/wiki/Version_vector">version vector</a>. You can think of this as a filter on the tree by way of a cut across yarns: one where only the atoms with a timestamp less than or equal to the one for their site in the weft are included. Wefts are very useful for functions such as past revision viewing and garbage collection, since they can uniquely address and split the data structure at any point in its mutation timeline.</p>

<figure>
<img src="/images/blog/causal-trees/weft.svg" style="width:53rem" />
<figcaption>The dotted line represents weft 1:6‚Äì2:7‚Äì3:7 in Lamport timestamp format, or weft 1:3‚Äì2:1‚Äì3:0 in index format. The two representations are equivalent.</figcaption>
</figure>

<p>A weft needs to be <strong>consistent</strong> in two ways. First, there‚Äôs consistency in the distributed computing sense: causality of operations must be maintained. This is easily enforced by ensuring that the tree is fully-connected under the cut. Second, the resulting tree must be able to produce an internally-consistent data structure with no invariants violated. This isn‚Äôt an issue with strings, but there are other kinds of data where a tree might fall apart if cut in the wrong place. (More on that below.) In the given example, the weft describes the string ‚ÄúCDADE‚Äù, providing a hypothetical view of the distributed data structure in the middle of all three edits.</p>

<h1 id="demo-concurrent-editing-in-macos-and-ios">Demo: Concurrent Editing in macOS and iOS</h1>

<p>Words, words, words! To prove that the Causal Tree is a useful and effective data structure in the real world, <a href="https://github.com/archagon/crdt-playground">I‚Äôve implemented a generic version in Swift together with a demo app</a>. Please note that this is strictly an educational codebase and not a production-quality library! My goal with this project was to dig for knowledge, not create another framework du jour. I apologize that there‚Äôs no good documentation or Javascript demonstration. It‚Äôs messy, it‚Äôs slow, and it‚Äôs surely broken in some places‚Äîbut it gets this particular job done.</p>

<div class="caption full-width">
<video controls="" muted="" preload="none" width="100%" poster="/images/blog/causal-trees/demo/mac-main.jpg">
<source src="/images/blog/causal-trees/demo/mac-main.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>
<p>From 0:00‚Äì0:23, sites 1‚Äì3 are created and connect to each other in a ring. From 0:23‚Äì0:34, sites 4 and 5 are forked from 1, establish a two-way connection to 1 to exchange peer info, then go back offline. At 0:38, site 4 connects to 5, which is still not sending data to anyone. At 0:42, site 5 connects to 1 and site 1 connects to 4, finally completing the network. At 0:48, all the sites go offline, then return online at 1:06.</p>
</div>

<p>The first part of the demo is a macOS P2P simulator. Every window you see represents an independent site, each of which has a unique UUID and holds its own copy of the CT. The CTs are edited locally through the type-tailored editing view. New sites must be forked from existing sites, copying over the current state of the CT. Sites can go ‚Äúonline‚Äù and establish one-way connections to one or more known peers, which sends over their CT and known peer list about once a second. On receipt, each site merges the inbound CT into their own. Not every site knows about every peer, and forked sites will be invisible to the rest of the network until they go online and connect to one of their known peers. All of this is done locally to simulate a partitioned, unreliable P2P network with a high degree of flexibility: practically any kind of network topology or partition can be set up using these windows. For string editing, the text view uses the CT directly as its backing store by way of an <code class="highlighter-rouge">NSMutableString</code> <a href="https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTFramework/StringRepresentation/CausalTreeStringWrapper.swift">wrapper</a> plugged into a bare-bones <code class="highlighter-rouge">NSTextStorage</code> <a href="https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CloudKitRealTimeCollabTest/Model/CausalTreeCloudKitTextStorage.swift">subclass</a>.</p>

<div class="caption full-width">
<video controls="" muted="" preload="none" width="100%" poster="/images/blog/causal-trees/demo/mac-yarns.jpg">
<source src="/images/blog/causal-trees/demo/mac-yarns.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>
</div>

<p>You can open up a yarn view that resembles the diagram in the <a href="http://www.ds.ewi.tudelft.nl/~victor/articles/ctre.pdf">CT paper</a>, though this is only really legible for simple cases. In this view, you can select individual atoms with the right mouse button to list their details.</p>

<div class="caption full-width">
<video controls="" muted="" preload="none" width="100%" poster="/images/blog/causal-trees/demo/mac-shapes.jpg">
<source src="/images/blog/causal-trees/demo/mac-shapes.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>
<p>The three sites are connected in a ring. At 0:43, all sites go offline, then return online at 1:00.</p>
</div>

<p>Also included is an example of a CT-backed data type for working with simple vector graphics. Using the editing view, you can create shapes, select and insert points, move points and shapes around, change the colors, and change the contours. Just as before, everything is synchronized with any combination of connected peers, even after numerous concurrent and offline edits. (To get a sense of how to use CTs with general non-string data types, read on!)</p>

<div class="caption full-width">
<video controls="" muted="" preload="none" width="100%" poster="/images/blog/causal-trees/demo/mac-revisions.jpg">
<source src="/images/blog/causal-trees/demo/mac-revisions.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>
</div>

<p>Each site can display previously-synced, read-only revisions of its document via the dropdown list. This feature is just one of many emergent properties of CTs. On account of the immutable, atomic, and ordered nature of the format, you get this functionality effectively for free!</p>

<div class="caption full-width">
<video controls="" muted="" preload="none" width="100%" poster="/images/blog/causal-trees/demo/iphone.jpg">
<source src="/images/blog/causal-trees/demo/iphone.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>
<p>The phone on the left shares an iCloud account with the phone in the middle, while the phone on the right is logged in to a different iCloud account and has to receive a CloudKit Share. At 0:29 and 1:21, remote cursor sync is demonstrated, and 1:30‚Äì2:00 shows offline use. At 2:15, simultaneous predictive typing is used to demo editing under high concurrency. Apologies for the occasional delays: iCloud is slow and my network code is a mess!</p>
</div>

<p>The second part of the demo is a very simple CloudKit-based text editing app for iOS. Much of it is wonky and unpolished (since I‚Äôm very much a CloudKit newbie), but the important part is that real-time collaboration (including remote cursors) works correctly and efficiently, whether syncing to the same user account, collaborating with others via CloudKit Sharing, or just working locally for long periods of time. The network layer only deals with binary data blobs and has no insight into the particular structure of the data, and all conflicts are resolved automatically in the same section of code. No extra coordinating servers are required: the dumb CloudKit database works perfectly fine!</p>

<p>My CT implementation isn‚Äôt quite production ready yet (though I‚Äôll keep hammering away for use in my own commercial projects), but I think it‚Äôs convincing proof that the technique is sound and practical for collaborative, document-based applications.</p>

<h1 id="operational-replicated-data-types">Operational Replicated Data Types</h1>

<p>Causal Trees, however, are just the beginning: there is a more general pattern at work here. Recent research projects, including Victor Grishchenko‚Äôs <a href="https://github.com/gritzko/ron">Replicated Object Notation</a> (RON) and the paper <a href="https://arxiv.org/pdf/1710.04469.pdf"><em>Pure Operation-Based Replicated Data Types</em></a> (hereafter <em>PORDT</em>), have discovered an elegant conception of CRDTs in terms of homogeneous operational units. I believe that these hybrid data structures stand at the vanguard of a fundamental, unifying theory of CRDTs!</p>

<p>For the sake of clarity, and since neither of the above projects seems terribly concerned with nomenclature, I‚Äôm going to be calling this new breed of CRDTs <strong>operational replicated data types</strong> for the rest of this article‚Äîpartly to avoid confusion with the exiting term ‚Äúoperation-based CRDTs‚Äù (or CmRDTs), and partly because ‚Äúreplicated data type‚Äù (RDT) seems to be gaining popularity over ‚ÄúCRDT‚Äù, and the term can be expanded to ‚ÄúORDT‚Äù without impinging on any existing terminology.</p>

<h2 id="what-is-an-ordt">What Is an ORDT?</h2>

<p>Much like Causal Trees, ORDTs are directly assembled out of tiny, timestamped, uniquely-identified ‚Äúoperations‚Äù arranged in a basic container structure. (For clarity, I‚Äôm going to be referring to this container as the <strong>structured log</strong> of the ORDT.) Each operation represents an atomic action performed on the data structure while simultaneously functioning as the unit of data resultant from that action. This crucial event‚Äìdata duality means that an ORDT can be understood as either a conventional data structure with each unit of data augmented with event information, or alternatively as an event log of atomic actions ordered to resemble the output data type for ease of execution. (Refer back to the array explorations in the previous section.) Consequently, an ORDT doesn‚Äôt necessarily need to be evaluated to produce its output data structure: many queries could be run on the structured log as-is<sup id="fnref:ops"><a href="#fn:ops" class="footnote">10</a></sup>. Whether syncing a single operation, applying a longer patch, or performing a full-on merge, any change to the data structure is integrated through the same path: a kind of low-level ‚Äúrebase‚Äù of operations in the container. This means that the distinction between the CmRDT and CvRDT approach becomes effectively moot.</p>

<p>The decomposition of data structures into tagged units of atomic change feels like one of those rare foundational abstractions that could clarify an entire field of study. Indeed, many existing CRDTs (such as RGA) have made passes at this concept without fully embracing it, incorporating authorship and logical timestamps into proto-operational structures that often get consumed during merge. With the ORDT approach, those same CRDTs can be expressed in a general way, unifying their interface and performance characteristics across the board while simultaneously enabling a wide variety of useful features. RON has working implementations for LWW (last-writer-wins) registers, RGA, and basic sets, while <em>PORDT</em> additionally defines MVRegisters, AWSets, and RWSets.</p>

<figure class="mostly-full-width">
<img src="/images/blog/causal-trees/rdts.svg" />
<figcaption>Some example ORDTs. Note that each ORDT has its own operation order: counter operations are arranged strictly by their Lamport timestamp (though the order really doesn't matter), LWW operations are sorted first by key and then by Lamport timestamp, and sequence operations are sorted as described in the CT section.</figcaption>
</figure>

<p>What are some of the key advantages to this operational approach? For one, merge and operation ordering become trivial, since idempotency and commutativity naturally derive from the fact that each ORDT is merely a collection of unique, ordered operations. Even causal order, which is critical for convergence in most CmRDTs, becomes a secondary concern: operations aren‚Äôt merged or applied so much as inserted into the structured log, and out-of-order events missing causal ancestors could simply be ignored on evaluation. (RON, for example, simply regards any causally-separated segments of an ORDT as ‚Äúpatches‚Äù that can be applied once the missing operations come in.) Actions that require reverting the data structure to a particular timestamp‚Äîgarbage collection, past revision viewing, delta updates‚Äîbecome as simple as taking a version vector and dividing the operations into two sets. Since each operation is uniquely identified, it‚Äôs possible to make deep permalinks from one ORDT into another; for example, by defining the cursor in a text editor as a reference to the atom representing its leftmost letter. (<a href="https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTFramework/StringRepresentation/CRDTTextEditing.swift">This is what my iOS demo does</a>.) On account of their uniformity, and since there‚Äôs no history to replay, rehydrating the data structures from bits into objects becomes a basic <em>O</em>(<em>n</em>) or <em>O</em>(<em>n</em>log<em>n</em>) read, bringing us closer to the ideal of our zippy ‚Äúgolden file‚Äù.</p>

<p>Defining data structures in terms of these low-level operations might seem like a needlessly bloated approach; for wouldn‚Äôt it make more sense to keep the data structure pure and to move the convergence and history stuff over to a separate data structure? But I‚Äôd argue that the operational approach is the only one that stays true to nature of the problem. One way or another, every action in a convergent data type needs to be uniquely defined, identified, and timestamped. If that information isn‚Äôt grouped together, the scheme will require complex coordination between the history parts and the data parts. Some new CRDTs (such as the one used in <a href="http://google.github.io/xi-editor/docs/crdt-details.html">xi</a>) do indeed try to keep the data structure and history separate; but the result is that the history restoration code has to be painfully tailored to the given data type, that the time complexity of critical algorithms (such as past revision viewing and merge) approaches <em>O</em>(<em>n</em><sup>2</sup>) with the length of the history log, and that there‚Äôs no standard way to send operations between sites. In other words, though this approach may seem pleasant at first glance, it has no generality and is very difficult to reason about. Paradoxically, separating the concerns makes the system far more specialized. Meanwhile, ORDTs perform these tasks without a peep while maintaining blazing-fast <em>O</em>(<em>n</em>log<em>n</em>) performance! I‚Äôd go as far as to say that defining CRDTs operationally is the <em>only</em> way to make them performant and comprehensible across the board, even though the marriage of state and history might initially seem a bit ugly.</p>

<h2 id="the-ordt-pipeline">The ORDT Pipeline</h2>

<p>ORDT operations are immutable and globally unique. Each operation is bestowed, at minimum, with an ID in the form of a site UUID and a Lamport timestamp, a location identifier (which is generally the ID of another operation), and a value. An operation is meant to represent an atomic unit of change to the data structure, local in effect and directly dependent on one other operation at most. (In practice, operations can be designed to do pretty much anything with the data, but non-atomic or multi-causal operations will prevent the structured log from being linearly interpretable and may severely affect performance, simplicity, and intent. Think: ‚Äú<a href="https://en.wikipedia.org/wiki/Bubble_(computing)">bubbles</a>‚Äù.) Although each operation only contains a single Lamport timestamp, the location (parent) pointer gives us almost as much additional causality and context information as a regular version vector. Consequently, it becomes possible to identify and separate out concurrent operations without the untenable <em>O</em>(<em>n</em><em>s</em>) space complexity of a version vector per operation, as many distributed systems are required to do.</p>

<p>New operations (local and remote) are incorporated into the ORDT through a series of functions. The pipeline begins with an incoming stream of remote operations. For an ORDT in CvRDT (state) mode, this would be a state snapshot in the form of another structured log; for CmRDT (operation) mode, any set of causally-linked operations, and often just a single one.</p>

<figure class="mostly-full-width">
<img src="/images/blog/causal-trees/pipeline.svg" />
<figcaption>The operational pipeline. Both the reducer/effect and mapper/eval steps use pure functions tailored to the given ORDT. Location information has been stripped from each operation to simplify the diagram.</figcaption>
</figure>

<p>New operations, together with the current structured log, are fed into a <strong>reducer</strong> (RON) or <strong>effect</strong> (<em>PORDT</em>) step. This takes the form of a function that inserts and orders the operations into the structured log, then removes any redundant operations as needed.</p>

<p>What are these ‚Äúredundant operations‚Äù, you might ask? Isn‚Äôt the log meant to be immutable? Generally, yes‚Äîbut in some ORDTs, new operations might definitively supersede previous operations and make them redundant for convergence. Take a LWW register, for example. In this very basic ORDT, the value of an operation with the highest timestamp+UUID supplants any previous operation‚Äôs value. Since merge only needs to compare a new operation with the previous highest operation, it stands to reason there‚Äôs simply no point in keeping the older operations around. (<em>PORDT</em> defines these stale operations in terms of <strong>redundancy relations</strong>, which are unique to each ORDT and are applied as part of the effect step.)</p>

<figure>
<img src="/images/blog/causal-trees/cleanup.svg" style="width:78rem" />
<figcaption>Cleaning up redundant operations in a simple multi-LWW (dictionary) ORDT. Both produce the same result and still contain enough information to correctly integrate any inbound operations.</figcaption>
</figure>

<p>Here, I have to diverge from my sources. In my opinion, the cleanup portion of the reducer/effect step ought to be separated out. Even though some ORDT operations might be made redundant, retaining every operation in full allows us to know the exact state of our ORDT at any point in its history. Without this ability, relatively ‚Äúfree‚Äù features such as garbage collection and past revision viewing become much harder (if not impossible) to implement in a general way. Ergo, I posit that at this point in the pipeline, we ought to have a simpler <strong>arranger</strong> step. This function would perform the same sort of merge and integration as the reducer/effect functions, but it wouldn‚Äôt actually remove or modify any of the operations. Instead of happening implicitly, the cleanup step would be triggered in a standard way when space actually needs to be reclaimed. This procedure is described in more detail in the garbage collection section below.</p>

<p>(I should note that RON and <em>PORDT</em> additionally clean up operations in the reducer/effect step by stripping some or all of the metadata when it‚Äôs no longer required. For instance, in the RON implementation of RGA, the location data of an operation is stripped by the reducer once the operation is properly positioned in the structured log. However, I‚Äôm against this sort of mutation of operations for the same sort of reason.)</p>

<p class="nojustify">The final bit of the pipeline is the <strong>mapper</strong> (RON) or <strong>eval</strong> (<em>PORDT</em>) step. This is the code that finally makes sense of the structured log. It can either be a function that produces an output data structure by executing the operations in order, or alternatively a collection of functions that directly interface with the structured log. In the case of string ORDTs, the mapper might simply emit a native string object, or it might take the form of an interface that lets you call methods like <code class="highlighter-rouge">length</code>, <code class="highlighter-rouge">characterAtIndex:</code>, or even <code class="highlighter-rouge">replaceCharactersInRange:withString:</code> directly on the structured log.</p>

<p>The arranger/reducer/effect and the mapper/eval functions together form the two halves of the ORDT: one dealing with the memory layout of data, the other with its user-facing interpretation. The data half, as manifest in the structured log, needs to be ordered such that the queries from the interface half remain performant. If the structured log for an ORDT ends up kind of looking like the abstract data type it is meant to represent (e.g. a CT‚Äôs weave ‚áÑ array), then the design is probably on the right track. Effectively, the operations should be able to stand for the data.</p>

<p>So how is the structured log stored, anyway? <em>PORDT</em> does not appear to concern itself with the order of operations: all are simply stuck in a set. Unfortunately, this is highly inefficient for more complex data types like sequences, since the set has to be sorted for each query. RON‚Äôs insight is that the order of operations really matters for mapper performance, and so the operations are arranged in a kind of compressed array called a <strong>frame</strong>. In both cases, operational storage is generic without any type-specific code. Everything custom about a particular data type is handled in the reducer/mapper and eval functions.</p>

<p>But this is another spot where I have to diverge from my sources. Rather than treating the structured log and all its associated functions as independent entities, I prefer to conceptualize the whole thing as a persistent, type-tailored object, distributing operations among various internal data structures and exposing merge and data access through an OO interface. In other words, the structured log, arranger, and parts of the mapper would combine to form one giant object.</p>

<figure class="mostly-full-width">
<img src="/images/blog/causal-trees/object-log.svg" />
<figcaption>An example object-based log for a string ORDT. The first cache is for "yarns" and the second is for ranges of visible characters. With these two caches, we can use the operations as a direct backing store for the native string interface.</figcaption>
</figure>

<p>ORDTs are meant to fill in for ordinary data structures, and sticking operations into some homogenous frame might lead to poor performance depending on the use case. For instance, many text editors now prefer to use the <a href="https://en.wikipedia.org/wiki/Rope_(data_structure)">rope data type</a> instead of simple arrays. With a RON-style frame, this transition would be impossible: you‚Äôre stuck with the container you‚Äôre given. But with an object-based ORDT, you could almost trivially switch out the internal data structure for a rope and be on your merry way. (Only the merge function would require some extra care.) And this is just the beginning: more complex ORDTs might require numerous associated data types and caches to ensure optimal performance. The OO approach would ensure that all these secondary structures stayed together and remained consistent during merge, and also offer a unified interface for data access.</p>

<p>(With all the pieces in place, it becomes trivial to reinterpret our Causal Tree as an object-based ORDT. The structured log is the weave array together with any yarn caches. The arranger is the merge function. The mapper is the <code class="highlighter-rouge">NSMutableString</code> wrapper. All the parts are already there with slightly different names.)</p>

<h2 id="garbage-collection">Garbage Collection</h2>

<p>Garbage collection has been a sticking point in CRDT research, and I believe that ORDTs offer an excellent foundation for exploring this problem. A garbage-collected ORDT can be thought of as a data structure in two parts: the ‚Äúlive‚Äù part and the compacted part. As we saw earlier, a CT can be split into two segments by way of a version vector (or ‚Äúweft‚Äù). The same applies to any operational ORDT. With a garbage-collected ORDT, we can simply store a <strong>baseline</strong> weft alongside the main data structure to serve as the dividing line between the live and compact parts. Then, any site that receives the new baseline would be obliged to compact the operations falling under that weft, and to drop or orphan any operations that are not included in the weft, but have a direct causal connection to any removed operations. The baseline can be thought of as just another operation in the ORDT: one that requires all prior operations to pass through the ORDT‚Äôs particular garbage collection routine. The trick is making this operation commutative.</p>

<p>(This section is a bit speculative since I haven‚Äôt implemented any of it yet, but I believe the logic is sound.)</p>

<figure>
<img src="/images/blog/causal-trees/baseline.svg" style="width:53rem" />
<figcaption>The dotted line represents baseline 1:6‚Äì2:7‚Äì3:7. In practice, S1@T2 may not necessarily be removed in order to preserve S1@T3's ancestral ordering information.</figcaption>
</figure>

<p>What exactly does it mean to compact an ORDT? There are really two mechanisms in play here. First, there‚Äôs ‚Äúlossless‚Äù compaction, which is simply dropping operations that are no longer necessary for future convergence. (In <em>PORDT</em>, this property of operations is called <strong>causal redundancy</strong>, and the cleanup is performed in the effect function. Remember, we split this off from our arranger.) In essence, lossless compaction is strictly a local issue, since the only thing it affects is the ability for a client to rewind the ORDT and work with past revisions. As such, we don‚Äôt even have to store it in a replicated variable: sites can just perform this cleanup step at their discretion. However, only simpler ORDTs (such as LWW registers) tend to have operations with this property.</p>

<p>The second kind of compaction involves dropping operations that are no longer reflected in the ORDT‚Äôs output, but that others sites may still require to fully converge in the future. In a CT-style string ORDT, this would involve removing delete operations together with their target operations, then preserving the order of any sibling subtrees concurrent to that delete<sup id="fnref:rewrite"><a href="#fn:rewrite" class="footnote">11</a></sup>. The risk here is that if a deleted operation has children other than its delete on any remote sites, then those child operations will be orphaned if the baseline fails to include them. We can mitigate this by first stipulating that no new operations may be <em>knowingly</em> parented to operations with attached delete operations, and also that no delete operations may have any children or be deleted themselves. (In other words, sibling insert and delete operations would only ever occur as the result of a concurrent mutation. This is the expected behavior anyway since the user can‚Äôt append a character to a deleted character in the editor UI, but it should be codified programmatically.) With this precondition in place, we know that once a site has received a delete operation, it will never produce any new siblings for that operation. We therefore also know that once <em>every</em> site in the network has seen a particular delete operation and its causal ancestors‚Äîwhen that delete operation is <em>stable</em>‚Äîthat no new operations concurrent to the delete will ever appear in the future, and that a baseline could in theory be constructed that avoids orphaning any operations across the network. (<em>PORDT</em> uses similar logic for its <strong>stable</strong> step, which comes after the effect step and cleans up any <em>causally stable</em> operations provably delivered to all other sites.)</p>

<p>Here‚Äôs where we hit a snag. Generally speaking, CRDT research focuses on operation-based CmRDTs, with the latent assumption that those CRDTs are going be used as part of some distributed system. In other words: the CRDTs are meant to support real-time collaboration and smooth over any sync issues, but client-server (or client-cloud, or even client-client) communication is still expected. In my own exploration of this topic, I have made no such assumptions. The CRDTs that have been described in this article are system-agnostic mathematical structures, and it makes no difference to any of the algorithms how the data gets from one place to another. Even communication isn‚Äôt a strict requirement! Someone could leave a copy of their CvRDT on an office thumb drive, return a year later, and successfully merge all the new changes back into their copy. This means that every time some additional bit of synchronization is mandated or assumed, the possibility space of the design shrinks and generality is lost. The messiness of time and state are injected into an otherwise purely functional system.</p>

<p>Unfortunately, garbage collection might be the one subsystem where a bit of coordination is actually required.</p>

<p>Take baseline selection, for instance. In an <a href="https://en.wikipedia.org/wiki/CAP_theorem">available and partition-tolerant system</a> system, is it possible to devise a selection scheme that always garbage collects without orphaning any operations? Logically speaking, no: if some site copies the ORDT from storage and then works on it in isolation, there‚Äôs no way the other sites will be able to take it into account when picking their baseline. However, if we require our system to only permit forks via request to an existing site, and also that any forked sites ACK back to their origin site on successful initialization, then we would have enough constraints to make non-orphaning selection work. Each site could hold a map of every site‚Äôs ID to its last known version vector. When a fork happens (and is acknowledged), the origin site would add the new site ID to its map and seed it with its own timestamp. This map would be sent with every operation or state snapshot between sites and merge into the receiver‚Äôs map alongside the ORDT. (In essence, this structure would act as a distributed overview of the network.) Now, any site with enough information about the others would be free to independently set a baseline that a) is causally consistent, b) is consistent by the rules of the ORDT, c) includes only those removable operations that have been received by every site in the network, and d) also includes every operation affected by the removal of those operations. With these preconditions, you can prove that even concurrent updates of the baseline across different sites will converge.</p>

<figure>
<img src="/images/blog/causal-trees/garbage-collection.gif" />
<figcaption>An example of network knowledge propagation. Site 2 is forked from 1, Site 3 from 2, and Site 4 from 3‚Äîall with state AB. At the start, Site 1's C has been received by Site 2, but not Site 3. Maps are updated on receipt, not on send. In the end, Site 1 knows that every site has at least moved past ABE (or weft 1:2‚Äì2:X‚Äì3:X‚Äì4:9), making it a candidate for the new baseline.</figcaption>
</figure>

<p>But questions still remain. For instance: what do we do if a site simply stops editing and never returns to the network? It would at that point be impossible to set the baseline anywhere in the network past the last seen version vector from that site. Now some sort of timeout scheme has to be introduced, and I‚Äôm not sure this is possible in a truly partitioned system. There‚Äôs just no way to tell if a site has left forever or if it‚Äôs simply editing away in its own parallel partition. So we‚Äôd have to add some sort of mandated communication between sites, or perhaps some central authority to validate connectivity, and now the system is constrained even further! In addition, as an <em>O</em>(<em>s</em><sup>2</sup>) space complexity data structure, the site-to-version-vector map could get unwieldily depending on the number of peers.</p>

<p>Alternatively, we might relax rule c) and allow the baseline to potentially orphan remote operations. In this scheme, we would have a sequence of baselines associated with our ORDT. Any site would be free to pick a new baseline that was explicitly higher than (not concurrent to!) the previous highest baseline, taking care to pick one that had the highest chance of preserving operations on other sites<sup id="fnref:preservation"><a href="#fn:preservation" class="footnote">12</a></sup>. Then, any site receiving new baselines in the sequence would be required to apply them in order<sup id="fnref:baselines"><a href="#fn:baselines" class="footnote">13</a></sup>. Upon receiving and executing a baseline, a site that had operations causally dependent on any freshly-removed operations but not included in the baseline would be obliged to either drop them or to add them to some sort of secondary ‚Äúorphanage‚Äù ORDT.</p>

<p>But even here we run into problems with coordination. If this scheme worked as written, we would be a-OK, so long as sites were triggering garbage collection relatively infrequently and only during quiescent moments (as determined to the best of a site‚Äôs ability). But we have a bit of an issue when it comes to picking monotonically higher baselines. What happens if two sites concurrently pick new baselines that orphan each others‚Äô operations?</p>

<p><img src="/images/blog/causal-trees/garbage.svg" style="width:19rem" /></p>

<p>Assume that at this point in time, Site 2 and Site 3 don‚Äôt know about each other and haven‚Äôt received each other‚Äôs operations yet. The system starts with a blank garbage collection baseline. Site 2 decides to garbage collect with baseline 1:3‚Äì2:6, leaving behind operations ‚ÄúACD‚Äù. Site 3 garbage collects with baseline 1:3‚Äì3:7, leaving operations ‚ÄúABE‚Äù. Meanwhile, Site 1‚Äîwhich has received both Site 2 and 3‚Äôs changes‚Äîdecides to garbage collect with baseline 1:3‚Äì2:6‚Äì3:7, leaving operations ‚ÄúAED‚Äù. So what do we do when Sites 2 and 3 exchange messages? How do we merge ‚ÄúACD‚Äù and ‚ÄúABE‚Äù to result in the correct answer of ‚ÄúAED‚Äù? In fact, too much information has been lost: 2 doesn‚Äôt know to delete C and 3 doesn‚Äôt know to delete B. We‚Äôre kind of stuck.</p>

<p>(I have to stress that baseline operations <em>must</em> behave like ordinary ORDT operations, in the sense that they have to converge to the same result regardless of their order of arrival. If they don‚Äôt, our CRDT invariants break and eventual consistency falls out of reach!)</p>

<p>In this toy example, it may still be possible to converge by drawing inferences about the missing operations from the baseline version vector of each site. But that trick won‚Äôt work with more devious examples featuring multiple sites deleting each others‚Äô operations and deletions spanning multiple adjacent operations. <em>Maybe</em> there exists some clever scheme which can bring us back to the correct state with any combination of partial compactions, but my hunch is that this situation is provably impossible to resolve in a local way without accruing ancestry metadata‚Äîat which point you‚Äôre left with the same space complexity as in the non-compacted case anyway.</p>

<p>Therefore‚Äîjust as with the non-orphaning baseline strategy‚Äîit seems that the only way to make this work is to add a bit of coordination. This might take the form of:</p>

<ul>
  <li>Designating one or more sites superusers and making them decide on the baselines for all other sites.</li>
  <li>Putting the baseline to vote among a majority/plurality of connected sites.</li>
  <li>Relying on a server to synchronously store the current baseline. (This might be the best strategy for a system built on top of something like CloudKit. The syncing mechanism is centralized and synchronous anyway, so might as well force sites to pull the baseline on sync.)</li>
  <li>Enforcing a real-time clock scheme. As long as clients are synced to an accurate master clock, perhaps operations could become compactable once some preset amount of time has passed. (There has to be some sort of mitigation for sites that can‚Äôt keep time accurately enough.)</li>
  <li>Allowing sites that end up losing in a concurrent baseline adjustment to pull the full ORDT from somewhere, or to get the necessary parts from their peers.</li>
</ul>

<p>In summary: while baseline operations are not commutative for every possible value, they can be made commutative with just a sprinkle of coordination. Either you ensure that a baseline <em>does not leave orphaned operations</em> (which requires some degree of knowledge about every site on the network), or you ensure that <em>each new baseline is higher than the last</em> (which requires a common point of synchronization). Fortunately, the messy business of coordination is localized to the problem of picking the data for a single operation, not to the functioning of the operation itself or any other part of the ORDT. There‚Äôs nothing special or unique about the baseline operation with respect to the rules of CRDTs, and so it can be treated, transferred, and processed just like any other operation. And if the baseline fails to get updated due to network conditions, nothing bad actually happens, and sites are still free to work on their documents. The scheme degrades very gracefully.</p>

<p>As one last thought, if the ORDT propagation mechanism is restricted to state snapshots (as in CvRDT mode), you could allow any site to arbitrarily set the baseline, but then replace any removed operations on merge if the incoming state snapshot happens to include causal dependents on those removed operations. (This is possible because every state snapshot is a consistent version of the ORDT, so the missing operations can be revived without having to make any additional requests.) Personally, I‚Äôm not too comfortable with this approach. My feeling is that it breaks CRDT monotonicity by allowing state to be restored, though it‚Äôs not clear to me where this inconsistency might rear its head. It‚Äôs much more correct for baselines to follow the rules of every other operation and move the CRDT forward through the monotonic semilattice. But I concede that this could possibly be the one perfect, coordination-free garbage collection approach, just as long as strictly CvRDT use was OK.</p>

<p>Finally, remember that in many cases, ‚Äúdon‚Äôt worry about garbage collection‚Äù is also a viable option! Most collaborative documents aren‚Äôt meant to be edited in perpetuity, and assuming good faith on the part of all collaborators, it would be surprising if the amount of deleted content (and thus, garbage) in a typical document was more than 2 or 3 times its visible length.</p>

<h2 id="ordt-design--implementation">ORDT Design &amp; Implementation</h2>

<p>I‚Äôve been thinking about the best way to integrate operation-based CRDTs into production software. <a href="https://github.com/gritzko/ron">RON</a>, though incomplete, offers a blueprint for a general, flexible, and highly functional system. However, I think there‚Äôs a lot to be said for object-based ORDTs‚Äîespecially insofar as low-latency software is concerned.</p>

<p>To reiterate, RON stores the operations for any ORDT in a homogeneous, immutable ‚Äúframe‚Äù data structure and pushes everything unique about the ORDT into the reducer and mapper functions. The system is data-oriented and self-configuring. Each set of operations contains location and data type information which allows the system to route operations to the correct ORDT frame without any boilerplate. The reducers are actually multi-mode functions that can merge individual operations, partial frames (patches), or full frames (state snapshots) in <em>O</em>(<em>n</em>log<em>n</em>) time by way of heap sort, allowing RON to function equally well in CmRDT or CvRDT mode (and perhaps even mix modes on the fly). Operations are described using a regular language that compresses very well when stored in a frame, and an even more efficient binary mode is available. The end result is this teeming river of operations that can automatically form itself into larger, interconnected structures.</p>

<p>In the object-based approach, operations, reducer/mapper functions, and any relevant caches are herded into persistent, mutable objects. Certainly, there are many hassles with this compared to the RON paradigm: everything is tightly-coupled, ownership becomes a critical factor, a lot more boilerplate is involved. Since there‚Äôs no built-in data layer, object management becomes a major concern. In exchange, you can target performance chokepoints with precision. A generic RON frame with <em>O</em>(<em>n</em>) reads and O(<em>n</em>log<em>n</em>) writes might be good in the general case, but there are plenty of problems where <em>O</em>(1) or <em>O</em>(log<em>n</em>) performance for certain functions is a hard requirement. Objects have the freedom to distribute their operations among various data structures, maintain caches of operations, and otherwise structure themselves for maximally efficient queries. Since operations are stored as independent structs, they take up more space than in a compressed RON frame, but also benefit tremendously from memory locality and random access. The conception of ORDTs as independent structures allows them to be used in non-network contexts; for example, as a way of dealing with local file merge or synchronizing data across threads. (Atom Xray and xi <a href="https://google.github.io/xi-editor/docs/crdt.html">already use CRDTs in this manner</a>, and it seems that lock-free data structures could similarly benefit from this approach.) And unlike in RON, there‚Äôs no mapping step from frame to user data: the object can be used as a native data type, never goes stale, never has to convert itself to different formats. (Think of the <code class="highlighter-rouge">NSMutableString</code> wrapper around the CT: you can use it just like any old system string.) All these factors really give this approach the leg up in low-level code.</p>

<p>Consider a hypothetical replicated bitmap as a thought experiment. Perhaps in the same vein as Reddit‚Äôs <a href="http://i.imgur.com/ajWiAYi.png">/r/place</a>, you‚Äôre working on a giant image with a bunch of different people‚Äîsome online, some offline‚Äîand you want the whole thing to sensibly merge when the different parts come together. As a starting point, say the bitmap is conceived as a grid of LWW registers<sup id="fnref:lww"><a href="#fn:lww" class="footnote">14</a></sup>, and that each operation contains a single pixel‚Äôs coordinates and RGBA color as the value. Let‚Äôs also say that the image is 5000√ó5000 pixels and that each set-pixel operation couldn‚Äôt be made smaller than 16 bytes. This means that once the entire canvas fills up, you‚Äôll be using about 400MB of uncompressed memory without even considering past history operations. Given that throughput for a single site could be in the hundreds of pixels per second, it‚Äôs crucial that each set-pixel operation execute locally in <em>O</em>(log<em>n</em>) time at most. It‚Äôs also vital for the garbage collector to be able to trim the ORDT very often and very quickly, since even a few layers of history would eat up all your RAM. (Technically, garbage collection isn‚Äôt even needed in a LWW context‚Äîsee <em>causal redundancy</em> above‚Äîbut maybe it‚Äôs desirable for the app to have the full bitmap history until the memory situation is truly dire.) And just like a real bitmap, perhaps it should even be possible to tile this ORDT and pull different chunks from storage as you‚Äôre working on them.</p>

<p>My feeling is that RON‚Äôs general approach would falter here. The pipeline simply couldn‚Äôt be tuned to fix these performance hot spots, and millions of pixel operations would grind it to a halt. With the object-based approach, you could store store the bitmap as a specialized k-d tree of buffers. The pixel values would be the operations themselves and each buffer would represent a particular area of pixels, subdivided when needed to store each pixel‚Äôs past operations. Since the buffers would be stored in contiguous chunks of memory, subdivision and rebalancing would be very efficient. Garbage collection could be as simple as un-subdividing any buffer with too many subdivisions. Assuming that the RGBA value for each operation was formatted correctly and that a stride could be passed along to the graphics framework, nodes could be blitted as-is into another buffer, making it trivial to only update the dirty parts of the rendered image. In short, it seems that performance could end up being very close to that of an <em>actual</em> bitmap. It wouldn‚Äôt even surprise me if /r/place itself‚Äîwith its 16 million changes and 1 million unique sites‚Äîcould be reproduced with this kind of object!</p>

<figure>
<img src="/images/blog/causal-trees/bitmap.svg" style="width:60rem" />
<figcaption>A mockup of what an object-based bitmap ORDT might look like under the hood. Each colored square is a pixel operation. Grid coordinates with subdivisions represent pixels with a change history. Each section of the grid is stored in its own contiguous block of memory.</figcaption>
</figure>

<p>Finally, a few nascent thoughts on designing new ORDTs. The inherently-ordered and immutable nature of operations means that the ORDT approach is basically a ‚Äúreplicated data type construction kit‚Äù. Since ORDTs are merely collections of unique operations, commutativity and idempotency are built in by definition. The hard design work is in figuring out how to atomize the data structure, define causal relationships, arrange the operations inside the structured log or object, and optimize performance for critical methods. In other words: perfect engineering work, and not something that requires a PhD! The key CRDT bits are already proven.</p>

<p>I‚Äôve admittedly only gone through this process for the nascent bitmap ORDT shown above, but here are some ideas anyway:</p>

<ul>
  <li>The operations <em>are</em> the data. Design your operations and organize your data structures so that you can query the ORDT directly instead of having to actually execute the operations first. Start with the data type you‚Äôre trying to ORDT-ify and figure out the best way to divide it into atomic pieces of data while keeping the original structure intact. Not every data type will be susceptible to atomization, but many will be.</li>
  <li>As much as possible, avoid operations that have non-local effects, multiple causes, or affect multiple future operations. (Good operation: <code class="highlighter-rouge">insert letter after letter</code>. Bad operation: <code class="highlighter-rouge">reverse the string</code>.) There has to be a degree of symmetry between the operations and their effect on the data structure: local in cause, local in consequence.</li>
  <li>Keep in mind the essential functions: initialization, operation insertion, merging, garbage collection, serialization and deserialization. Nothing should be slower than <em>O</em>(<em>n</em>log<em>n</em>).</li>
  <li>If garbage collection is to be used, restrict the effective range of your removable operations. Ensure that only operations prior and concurrent to the removable operation could possibly be affected by its removal‚Äînone afterwards.</li>
  <li>If using the object-based approach, ensure that each operation only exists in a single internal data structure at a time. Don‚Äôt rely on ‚Äúincidental state‚Äù such as insertion order; keep your internal data structures organized, sorted, and balanced at all times. Avoid moving operations between internal data structures. Instead of thinking of your object as having state, treat it as an organizational framework for your immutable operations.</li>
  <li>One exception: caches of operations might be needed for optimal performance in some scenarios. (For example, yarns in the CT.) If you have caches, make absolutely, 100% sure that they‚Äôre consistent following all mutating operations; that they‚Äôre never serialized; and that it‚Äôs possible to efficiently recreate them on initialization and deserialization. Caches are one of the easiest ways to corrupt your data!</li>
</ul>

<p>With that said, the need to design a new ORDT should be relatively rare. Most documents can be designed through the composition of existing ORDTs, e.g. sequences and maps. Still: it‚Äôs a fun subject to think about!</p>

<h1 id="causal-trees-in-depth">Causal Trees In Depth</h1>

<p>ORDTs give us the power to transform practically any data type into a convergent structure, and so it would seem sensible to define convergent document formats as compositions of these elements. However, I‚Äôd like to argue that our original Causal Tree, though nominally intended for sequence use, happens to be of the most fundamental and versatile expressions of the ORDT formula, and is in fact well-suited to document use all by its lonesome self.</p>

<p>First, the structure of a CT has strong parallels to the git model, making it very intuitive to work with. Rather than pointing to a historic revision of a file, each ‚Äúcommit‚Äù (operation) stands for an atomic change in data, while the full timeline considered together forms the final output data. (In effect, the weave could be simply viewed a rebase of the entire timeline.) Related operations naturally chain together and appear as ranges in the weave, and conflicts are reified as sibling branches that can easily be resolved in the mapper/eval step‚Äîor even presented to the user as in an MVRegister. Causality and authorship information can be used to splice and rearrange the timeline in order to produce, for example, a local copy at a specific point in time, or without a particular author‚Äôs changes. Local changes could be held in memory, worked on in isolation, and then grafted onto the main tree all at once. The same mental tools used to reason about git naturally transfer over to CTs, with the simplification that none of the commits actually interfere with each other<sup id="fnref:git"><a href="#fn:git" class="footnote">15</a></sup>.</p>

<p>Next, we know <a href="http://www.staff.city.ac.uk/~ross/papers/FingerTree.html">from other domains</a> that trees can be used to simulate practically any existing data type, from arrays to dictionaries to registers. Subtrees can be used to separate out different parts of the document, so you could have a sequence subtree, a dictionary subtree, and multiple other independent structures cohabiting in the same tree. CTs are inherently structured and composable.</p>

<p>Finally, since CTs are (generally) stored in contiguous memory, most operations are <em>O</em>(<em>n</em>) or <em>O</em>(<em>n</em>log<em>n</em>) and massively benefit from spatial locality‚Äîto the point where complex copy-on-write or locking schemes can be eschewed in favor of straight, dumb copies when working with multiple threads. It‚Äôs hard to beat a plain ol‚Äô range-of-memory when it comes to optimal performance, especially when serialization and deserialization are such frequent operations.</p>

<p>Together, all these properties make CTs perfect for use as a sort of quick-and-dirty ‚Äúconvergent struct‚Äù. But we need to flesh out a few details first‚Ä¶</p>

<h2 id="implementation-details">Implementation Details</h2>

<p>Before even touching the CT code, it makes sense to define a general CvRDT protocol. Among other benefits, this would make CvRDTs composable by allowing container CvRDTs  to forward all relevant calls to their child CvRDTs.</p>

<div class="language-swift highlighter-rouge"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">protocol</span> <span class="kt">CvRDT</span><span class="p">:</span> <span class="kt">Codable</span><span class="p">,</span> <span class="kt">Hashable</span>
<span class="p">{</span>
    <span class="c1">// must obey CvRDT convergence properties</span>
    <span class="k">mutating</span> <span class="kd">func</span> <span class="nf">integrate</span><span class="p">(</span><span class="n">_</span> <span class="nv">v</span><span class="p">:</span> <span class="k">inout</span> <span class="k">Self</span><span class="p">)</span>
    
    <span class="c1">// for avoiding needless merging; should be efficient</span>
    <span class="kd">func</span> <span class="nf">superset</span><span class="p">(</span><span class="n">_</span> <span class="nv">v</span><span class="p">:</span> <span class="k">inout</span> <span class="k">Self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kt">Bool</span>
    
    <span class="c1">// ensures that our invariants are correct, for debugging and sanity checking</span>
    <span class="kd">func</span> <span class="nf">validate</span><span class="p">()</span> <span class="k">throws</span> <span class="o">-&gt;</span> <span class="kt">Bool</span>
<span class="p">}</span>
</code></pre>
</div>

<p>CvRDTs are especially vulnerable to bad input since there‚Äôs no guarantee of a central server to fix mistakes. In order to minimally safeguard against malicious and misbehaving peers, I‚Äôve added a validation method to this interface. In the CT case, the <code class="highlighter-rouge">validate</code> method goes through the weave and checks as many preconditions as possible, including child ordering, atom type, priority atom behavior, and several others.</p>

<p>Next: UUIDs. So far, I‚Äôve been describing my site identifiers as 16-bit integers since it‚Äôs unlikely that any document would have more than 65,000 collaborators. (And frankly, in most cases 8 or even 4 bits would do.) However, this is not enough for any reasonable definition of a UUID. Without coordination, you‚Äôll need a minimum of 128 bits to generate a truly unique value, but storing two full 128-bit UUIDs in each atom‚Äîone for its own site and one for its cause‚Äîwould balloon it to 3√ó its original size!</p>

<p>I‚Äôve solved this with the help of a secondary CRDT that is stored and transferred along with the CT: an ordered, insert-only array of known UUIDs called the <strong>site map</strong>. The 16-bit site identifier corresponding to a UUID is simply its index in this array.</p>

<figure>
<img src="/images/blog/causal-trees/site-map.svg" style="width:68.5rem" />
</figure>

<p>When two CTs merge, their site maps merge as well. This means that our site identifiers are only unique locally, not globally: if a new UUID gets added at a remote site and is then inserted into our site map, the sorted order of our local UUIDs might change. When this happens, I traverse each CT and remap any outdated site identifiers to their new values‚Äîa simple <em>O</em>(<em>n</em>) operation. This is facilitated by the following interface:</p>

<div class="language-swift highlighter-rouge"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">protocol</span> <span class="kt">IndexRemappable</span>
<span class="p">{</span>
    <span class="k">mutating</span> <span class="kd">func</span> <span class="nf">remapIndices</span><span class="p">(</span><span class="n">_</span> <span class="nv">map</span><span class="p">:</span> <span class="p">[</span><span class="kt">SiteId</span><span class="p">:</span><span class="kt">SiteId</span><span class="p">])</span>
<span class="p">}</span>
</code></pre>
</div>

<p>Any CRDT that makes use of the site map needs to implement this protocol. Whenever a merge that would cause some of the site IDs to change is invoked, the <code class="highlighter-rouge">remapIndices</code> method gets called on the CRDT before the merge is actually executed. We‚Äôre running <em>O</em>(<em>n</em>) operations when receiving remote data anyway, so performance is not a huge factor. Nonetheless, I made one additional tweak to ensure that remapping only happens very rarely. Instead of storing just the UUID in the site map, I also store the wall clock time at which the UUID was added. In the site map, these tuples are sorted first by time, then by UUID. Assuming that modern connected devices tend to have relatively accurate clocks (but not relying on this fact for correctness), we can ensure that new sites almost always get appended to the end of the ordered array and thus avoid shifting any of the existing UUIDs out of their previous spots. The only exception is when multiple sites happen to be added concurrently or when the wall clock on a site is significantly off.</p>

<p>The skeleton for our CT interface ends up looking something like this:</p>

<div class="language-swift highlighter-rouge"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">protocol</span> <span class="kt">CausalTreeSiteUUIDT</span><span class="p">:</span> <span class="kt">Hashable</span><span class="p">,</span> <span class="kt">Comparable</span><span class="p">,</span> <span class="kt">Codable</span> <span class="p">{}</span>
<span class="kd">public</span> <span class="kd">protocol</span> <span class="kt">CausalTreeValueT</span><span class="p">:</span> <span class="kt">IndexRemappable</span><span class="p">,</span> <span class="kt">Codable</span> <span class="p">{}</span>

<span class="kd">public</span> <span class="kd">final</span> <span class="kd">class</span> <span class="kt">SiteIndex</span>
    <span class="o">&lt;</span><span class="kt">S</span><span class="p">:</span> <span class="kt">CausalTreeSiteUUIDT</span><span class="o">&gt;</span> <span class="p">:</span>
    <span class="kt">CvRDT</span><span class="p">,</span> <span class="kt">NSCopying</span>
<span class="p">{</span>
    <span class="c1">// etc.</span>
<span class="p">}</span>

<span class="kd">public</span> <span class="kd">final</span> <span class="kd">class</span> <span class="kt">Weave</span>
    <span class="o">&lt;</span><span class="kt">S</span><span class="p">:</span> <span class="kt">CausalTreeSiteUUIDT</span><span class="p">,</span> <span class="kt">V</span><span class="p">:</span> <span class="kt">CausalTreeValueT</span><span class="o">&gt;</span> <span class="p">:</span>
    <span class="kt">CvRDT</span><span class="p">,</span> <span class="kt">IndexRemappable</span><span class="p">,</span> <span class="kt">NSCopying</span>
<span class="p">{</span> 
    <span class="c1">// etc.</span>
<span class="p">}</span>

<span class="kd">public</span> <span class="kd">final</span> <span class="kd">class</span> <span class="kt">CausalTree</span>
    <span class="o">&lt;</span><span class="kt">S</span><span class="p">:</span> <span class="kt">CausalTreeSiteUUIDT</span><span class="p">,</span> <span class="kt">V</span><span class="p">:</span> <span class="kt">CausalTreeValueT</span><span class="o">&gt;</span> <span class="p">:</span>
    <span class="kt">CvRDT</span><span class="p">,</span> <span class="kt">IndexRemappable</span><span class="p">,</span> <span class="kt">NSCopying</span>
<span class="p">{</span>
    <span class="kd">public</span> <span class="kd">private(set)</span> <span class="k">var</span> <span class="nv">siteIndex</span><span class="p">:</span> <span class="kt">SiteIndex</span><span class="o">&lt;</span><span class="kt">S</span><span class="o">&gt;</span>
    <span class="kd">public</span> <span class="kd">private(set)</span> <span class="k">var</span> <span class="nv">weave</span><span class="p">:</span> <span class="kt">Weave</span><span class="o">&lt;</span><span class="kt">S</span><span class="p">,</span> <span class="kt">V</span><span class="o">&gt;</span>
    
    <span class="c1">// etc., with CvRDT interface calls forwarded to the site index and weave</span>
<span class="p">}</span>
</code></pre>
</div>

<p>In order to support viewing past revisions, my CT exposes its operation array to the outside world through a <a href="https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTFramework/CRDTCausalTreesWeave.swift#L723">specialized collection struct</a>. By passing in a consistent weft to the accessor function, you can read a historic version of the CT through the exact same interface as the current version, substantially simplifying any wrappers that use the CT as their backing store. To get a list of consistent wefts, all you need to do is store the current weft right before any remote changes are integrated.</p>

<p>One last feature specific to CTs is the priority flag for atoms. If an atom has priority, that atom and all its descendants get sorted ahead of any sibling subtrees in the parent‚Äôs causal block, even if it has a lower Lamport timestamp. (Put another way, a priority flag is simply another variable to be used in the sorting comparator, i.e. timestamp+UUID+priority.) This property gives us a lot of structural control, ensuring that, for instance, delete atoms hug their target atoms and never find themselves lost in the weave if some concurrent insert operations appear at the same spot. It does require some special casing during weave mutation and merge, however.</p>

<p>With the priority flag in tow, the value enum for our CT string atoms now looks something like this:</p>

<div class="language-swift highlighter-rouge"><pre class="highlight"><code><span class="kd">protocol</span> <span class="kt">CausalTreePrioritizable</span> <span class="p">{</span> <span class="k">var</span> <span class="nv">priority</span><span class="p">:</span> <span class="kt">Bool</span> <span class="p">{</span> <span class="k">get</span> <span class="p">}</span> <span class="p">}</span>

<span class="kd">enum</span> <span class="kt">StringValue</span><span class="p">:</span> <span class="kt">IndexRemappable</span><span class="p">,</span> <span class="kt">Codable</span><span class="p">,</span> <span class="kt">CausalTreePrioritizable</span>
<span class="p">{</span>
    <span class="k">case</span> <span class="n">null</span>
    <span class="k">case</span> <span class="nf">insert</span><span class="p">(</span><span class="nv">char</span><span class="p">:</span> <span class="kt">UInt16</span><span class="p">)</span>
    <span class="k">case</span> <span class="n">delete</span>
  
    <span class="kd">func</span> <span class="nf">priority</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kt">Bool</span>
    <span class="p">{</span>
        <span class="k">if</span> <span class="k">case</span> <span class="o">.</span><span class="n">delete</span> <span class="o">=</span> <span class="k">self</span>
        <span class="p">{</span>
            <span class="k">return</span> <span class="kc">true</span>
        <span class="p">}</span>
        <span class="k">else</span>
        <span class="p">{</span>
            <span class="k">return</span> <span class="kc">false</span>
        <span class="p">}</span>
    <span class="p">}</span>
    
    <span class="k">mutating</span> <span class="kd">func</span> <span class="nf">remapIndices</span><span class="p">(</span><span class="n">_</span> <span class="nv">map</span><span class="p">:</span> <span class="p">[</span><span class="kt">SiteId</span><span class="p">:</span><span class="kt">SiteId</span><span class="p">])</span> <span class="p">{}</span>
  
    <span class="c1">// insert Codable boilerplate here</span>
<span class="p">}</span>

<span class="kd">typealias</span> <span class="kt">StringAtom</span> <span class="o">=</span> <span class="kt">Atom</span><span class="o">&lt;</span><span class="kt">StringValue</span><span class="o">&gt;</span>
</code></pre>
</div>

<p>And that‚Äôs all we really need to start implementing custom data types!</p>

<h2 id="representing-non-string-objects">Representing Non-String Objects</h2>

<p>To implement a custom data type as a CT, you first have to ‚Äúatomize‚Äù it, or decompose it into a set of basic operations, then figure out how to link those operations such that a mostly linear traversal of the CT will produce your output data. (In other words, make the structure analogous to a one- or two-pass parsable format.)</p>

<p>In the demo section, I presented a CT designed for B√©zier drawing. Here‚Äôs how I coded the value enum for each atom:</p>

<div class="language-swift highlighter-rouge"><pre class="highlight"><code><span class="kd">enum</span> <span class="kt">DrawDatum</span><span class="p">:</span> <span class="kt">IndexRemappable</span><span class="p">,</span> <span class="kt">Codable</span><span class="p">,</span> <span class="kt">CausalTreePrioritizable</span>
<span class="p">{</span>    
    <span class="k">case</span> <span class="n">null</span> <span class="c1">// no-op for grouping other atoms</span>
    <span class="k">case</span> <span class="n">shape</span>
    <span class="k">case</span> <span class="nf">point</span><span class="p">(</span><span class="nv">pos</span><span class="p">:</span> <span class="kt">NSPoint</span><span class="p">)</span>
    <span class="k">case</span> <span class="n">pointSentinelStart</span>
    <span class="k">case</span> <span class="n">pointSentinelEnd</span>
    <span class="k">case</span> <span class="nf">trTranslate</span><span class="p">(</span><span class="nv">delta</span><span class="p">:</span> <span class="kt">NSPoint</span><span class="p">,</span> <span class="nv">ref</span><span class="p">:</span> <span class="kt">AtomId</span><span class="p">)</span>
    <span class="k">case</span> <span class="nf">attrColor</span><span class="p">(</span><span class="kt">ColorTuple</span><span class="p">)</span>
    <span class="k">case</span> <span class="nf">attrRound</span><span class="p">(</span><span class="kt">Bool</span><span class="p">)</span>
    <span class="k">case</span> <span class="n">delete</span>
  
    <span class="k">var</span> <span class="nv">priority</span><span class="p">:</span> <span class="kt">Bool</span>
    <span class="p">{</span>
        <span class="k">switch</span> <span class="k">self</span>
        <span class="p">{</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">null</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">true</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">shape</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">false</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">point</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">false</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">pointSentinelStart</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">false</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">pointSentinelEnd</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">false</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">trTranslate</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">true</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">attrColor</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">true</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">attrRound</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">true</span>
        <span class="k">case</span> <span class="o">.</span><span class="nv">delete</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">true</span>
        <span class="p">}</span>
    <span class="p">}</span>
    
    <span class="k">mutating</span> <span class="kd">func</span> <span class="nf">remapIndices</span><span class="p">(</span><span class="n">_</span> <span class="nv">map</span><span class="p">:</span> <span class="p">[</span><span class="kt">SiteId</span><span class="p">:</span><span class="kt">SiteId</span><span class="p">])</span>
    <span class="p">{</span>
        <span class="k">switch</span> <span class="k">self</span>
        <span class="p">{</span>
        <span class="k">case</span> <span class="o">.</span><span class="nf">trTranslate</span><span class="p">(</span><span class="k">let</span> <span class="nv">delta</span><span class="p">,</span> <span class="k">let</span> <span class="nv">ref</span><span class="p">):</span>
            <span class="k">if</span> <span class="k">let</span> <span class="nv">newSite</span> <span class="o">=</span> <span class="n">map</span><span class="p">[</span><span class="n">ref</span><span class="o">.</span><span class="n">site</span><span class="p">]</span>
            <span class="p">{</span>
                <span class="k">self</span> <span class="o">=</span> <span class="o">.</span><span class="nf">trTranslate</span><span class="p">(</span><span class="nv">delta</span><span class="p">:</span> <span class="n">delta</span><span class="p">,</span> <span class="nv">ref</span><span class="p">:</span> <span class="kt">AtomId</span><span class="p">(</span><span class="nv">site</span><span class="p">:</span> <span class="n">newSite</span><span class="p">,</span> <span class="nv">index</span><span class="p">:</span> <span class="n">ref</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
            <span class="p">}</span>
        <span class="k">default</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="p">}</span>
    <span class="p">}</span>
  
    <span class="c1">// insert Codable boilerplate here</span>
<span class="p">}</span>

<span class="kd">typealias</span> <span class="kt">DrawAtom</span> <span class="o">=</span> <span class="kt">Atom</span><span class="o">&lt;</span><span class="kt">DrawDatum</span><span class="o">&gt;</span>
</code></pre>
</div>

<p>Swift is kind enough to compress this down to about 23 bytes: the maximum size of an associated value tuple (opTranslate, which has a 16-byte <code class="highlighter-rouge">NSPoint</code> and a 6 byte <code class="highlighter-rouge">AtomId</code>) plus a byte for the case.</p>

<p>Note that <code class="highlighter-rouge">trTranslate</code> has an atom ID as an associated value. Since atom IDs are unique, you can reference them from other atoms without issue<sup id="fnref:causalpast"><a href="#fn:causalpast" class="footnote">16</a></sup>. It‚Äôs a great way to represent ranged operations: just pick an atom that represents the outer position of your range, add the ID to the operation‚Äôs value, and handle it in your mapping/evaluation code. (This should especially come in handy when dealing with text formatting in rich text editors.) The only caveat is that the atom has to update this value in its implementation of the <code class="highlighter-rouge">IndexRemappable</code> protocol. (Incidentally, I still need to port this functionality to my string CT‚Äôs delete operation: ranged deletes are so much more performant than deleting each character individually!)</p>

<p>Anyway, back to shapes. For the following sample document‚Ä¶</p>

<figure>
<img src="/images/blog/causal-trees/draw-shapes.svg" style="width:40rem" />
</figure>

<p>‚Ä¶we might end up with a tree shaped like this. (For completeness, I‚Äôve added a few extra transformation and attribute operations that aren‚Äôt directly visible in the user-facing data.)</p>

<figure>
<img src="/images/blog/causal-trees/draw-tree.svg" />
<figcaption>The pink operations have the priority flag and sort ahead of their sibling subtrees.</figcaption>
</figure>

<p>Just a few simple rules define the higher-level structures that represent shapes, points, and properties in this tree. A <code class="highlighter-rouge">shape</code> atom can only be parented to other <code class="highlighter-rouge">shape</code> atoms or to the root starting atom. Each <code class="highlighter-rouge">shape</code> has a null atom as its only child, acting as the root node for all property subtrees relevant to that shape. This atom can contain three child subtrees at most: a chain of transformations, a chain of attributes, and a chain of points. Transformation and attribute chains hug their parent in the weave via the priority flag while points go last. Any new transformations and attributes are parented to the last member of their corresponding chain. The value for a chain of operations (currently only <code class="highlighter-rouge">trTranslate</code>) is cumulative, while the value for a chain of attributes (<code class="highlighter-rouge">attrColor</code> or <code class="highlighter-rouge">attrRound</code>) is just the last atom in the chain. Point chains act more like traditional sequences. A point chain is seeded with a start and end sentinel to cleanly delineate it from its neighbors, and the traversal order corresponds to the order of the points in the output <code class="highlighter-rouge">NSBezierPath</code>. Like shapes, points can have child transformation and attribute chains. Points can also have child delete atoms. (Shapes aren‚Äôt currently deletable: you can individually remove all the points anyway and I got lazy.)</p>

<p>In essence, this particular CT consists of a bunch of superimposed ORDTs: sequences for shapes and points, LWW registers for attributes, and a sort of counter for transformations.</p>

<p>Here is the weave we get from reading the tree in DFS order:</p>

<figure class="mostly-full-width">
<img src="/images/blog/causal-trees/draw-weave.svg" />
<figcaption>The green brackets are shape blocks, blue brackets are point blocks, and red brackets are attribute blocks.</figcaption>
</figure>

<p>The rules for generating the output image from this weave are very simple. If you hit a shape atom, you‚Äôre in a shape block until you run into another shape atom or the end of the weave. The shape‚Äôs operation and attribute chains are traversed first on account of their priority flag, and the results are cached for use in the next step. An <code class="highlighter-rouge">NSBezierPath</code> is created once you start reading points. Each point block has to read forward a bit to parse its operation and attribute chains (if any). If a delete atom is found, you can simply move on to the next point. Otherwise, the point‚Äôs position is determined by combining its origin and transform (if any) with the parent shape‚Äôs transform (if any). The point is added to the <code class="highlighter-rouge">NSBezierPath</code> either as as a line or as a B√©zier curve if it has the rounded attribute. Then, once the next shape block or the end of weave is reached, the path is drawn and stroked.</p>

<p>When I first started reading up on CRDTs, it was unclear to me how conflict resolution was formalized. Every CRDT seemed to do something a bit different and it was rare to find an approach that the developer could tweak depending on their needs. In CTs, the answer is refreshingly simple: conflicts occur when an atom has more children than expected, and the presentation of this fact is delegated to a higher layer. Translation operations in the B√©zier CT are a good example. Let‚Äôs say three different sites concurrently move the same point in the same direction. By default, the CT would produce a weave with three consecutive translations. Applying them in order would be consistent, but it would also triple the magnitude of the translation and match none of the sites‚Äô intentions. Instead, we can detect when a translation atom has multiple children and then simply average out those values. This would cause the final translation to reasonably approximate each of the original values and hopefully leave all three sites satisfied. If some user still finds this merge offensive, they can manually adjust the translation and implicitly ‚Äúcommit‚Äù the change with their new operation.</p>

<p>This is only one possible approach, however, and the developer is free to act at their leisure when a conflict is detected: present a selection to the user, pick the value with the lowest timestamp, use some special function for combining the values. The underlying CT will <em>always</em> remain consistent under concurrency, and conflict resolution is merely a matter of interpretation.</p>

<p>Finally, my implementation includes a <a href="https://github.com/archagon/crdt-playground/blob/269784032d01dc12bd46d43caa5b7047465de5ae/CRDTPlayground/TestingExtras/Data%20Interfaces/CausalTreeBezierWrapper.swift">new, stateless layer</a> on top of the CT that provides a more model-appropriate API and sanity checking. Since the B√©zier tree has more constraints on its structure than the underlying CT, there‚Äôs an additional, higher-level <code class="highlighter-rouge">validate</code> method that verifies the new preconditions after the base CT is itself validated. Other helper functions ensure that the consistency of the tree is not compromised when new points, shapes, or attributes are added. From the outside, callers can safely use methods like <code class="highlighter-rouge">addShape</code> or <code class="highlighter-rouge">updateAttributes</code> on the wrapper without having to worry about the CT at all. It looks just like any other model object. (Incidentally, this approach to layering CRDTs is discussed in <a href="https://arxiv.org/pdf/1212.2338.pdf">this paper</a>, though the technique isn‚Äôt exactly novel.)</p>

<p>It‚Äôs possible that the use case of representing custom data types via CTs is a bit esoteric. Certainly, I wouldn‚Äôt use a CT for complex, versioned document formats akin to PSD or DOC. But just as with structs versus objects, or tuples versus arrays, I can imagine a number of scenarios where a small, custom CT might make the code so much cleaner and more performant than a higher-level collection of array, map, and register CRDTs. Quick, versatile, and simple data structures often turn out to be very useful in practice!</p>

<h2 id="performance">Performance</h2>

<p>OT and CRDT papers often cite 50ms<sup id="fnref:latency"><a href="#fn:latency" class="footnote">17</a></sup> as the threshold at which people start to notice latency in their text editors. Therefore, any code we might want to run on a CT‚Äîincluding merge, initialization, and serialization/deserialization‚Äîhas to fall within this range. Except for trivial cases, this precludes <em>O</em>(<em>n</em><sup>2</sup>) or slower complexity: a 10,000 word article at 0.01ms per character would take 8 hours to process! The essential CT functions therefore have to be <em>O</em>(<em>n</em>log<em>n</em>) at the very worst.</p>

<p>The simplest implementation of a weave is a contiguous array of atoms. Since every mutation resolves to an atom insertion, <em>O</em>(<em>n</em>) is the baseline for any mutation (except for appends to the end). On account of spatial locality, this should be fine for the majority of use cases: <a href="https://www.mikeash.com/pyblog/friday-qa-2016-04-15-performance-comparisons-of-common-operations-2016-edition.html">Mike Ash‚Äôs benchmarks</a> show that an iPhone 6s can <code class="highlighter-rouge">memcpy</code> 1MB in 0.12ms, meaning that performance will probably be fine as long as the CT stays under ‚âà400MB. It also helps that the CT involves only a limited number of heap allocations and no pointer-chasing at all. If that‚Äôs not good enough, it should be possible to switch out the array for something like xi‚Äôs <a href="http://google.github.io/xi-editor/docs/rope_science_00.html">copy-on-write rope</a> for specialized use cases.</p>

<p>My CT implementation maintains a cache of site yarns alongside the weave which incurs a slight performance penalty. Yarns are also stored as one contiguous array, meaning that there‚Äôs an additional <em>O</em>(<em>n</em>) cost for every weave mutation. Additionally, whenever a CT is received from another site, its yarns have to be regenerated on initialization. (Yarns are not part of the serialized data for reasons mentioned at the end of the ORDT section.) Yarn generation is <em>O</em>(<em>n</em>log<em>n</em>) since it‚Äôs isomorphic to sorting the weave. In exchange, the yarns give us <em>O</em>(1) for the very common operation of looking up atoms by their identifier. Finding an atom‚Äôs weave index is still <em>O</em>(<em>n</em>), but this is a minor issue since the index is only really used when inserting new operations, and that‚Äôs an <em>O</em>(<em>n</em>) process already.</p>

<p>Merging with another CT is almost always <em>O</em>(<em>n</em>log<em>n</em>). This involves iterating the two weaves together, comparing atoms by parentage and timestamp, constructing a new interwoven weave, and then regenerating the yarn cache. On occasion, a priority atom conflict might require finding the least common ancestor between two atoms in <em>O</em>(<em>n</em>), but this should be exceedingly rare. (And in any case, it‚Äôs unlikely that the two operations will differ by more than a couple of ancestors.)</p>

<p>Weave validation is only <em>O</em>(<em>n</em>). All we have to do is look at each atom and keep track of a few counters to ensure that sibling order is correct and that causality is not violated. This is usually invoked on deserialization.</p>

<p>As state-based CRDTs, CTs have a large memory footprint, both on account of the operation size and accumulated garbage. Assuming that a document is unlikely to contain more than 30% garbage, a 20,000 word article (like this one!) would eat up about 2.5MB versus 125KB as a simple C-string. While perhaps egregious in principle, I don‚Äôt think this is really that big of a deal in practice. First, even a 400,000-word, novel-length document would ‚Äúonly‚Äù take up 50MB of memory in the absolute worst case‚Äîeasily digestible by modern devices. If keeping such large data structures in memory isn‚Äôt acceptable, and if random atom access isn‚Äôt essential to the task at hand, a <a href="https://github.com/gritzko/ron#wire-format-base64">RON-style frame compression strategy</a> may be pursued.</p>

<p>Additionally, the eminently compressible CT format could be shrunk to a fraction of its full size during network transmission and storage. As a quick test, I saved a 125,000-atom, book-length CT to disk. Uncompressed, it took up 3.3MB; compressed via zip, a mere 570KB, or ‚âà6√ó the size of the equivalent C-string.</p>

<h2 id="missing-features--future-improvements">Missing Features &amp; Future Improvements</h2>

<p>Finally, it‚Äôs worth noting a few features that my CT currently lacks.</p>

<p>For the moment, I‚Äôve decided to omit garbage collection altogether. I‚Äôll mainly be using CTs in document-based applications with relatively small files and a limited number of collaborators, so the CTs will only be expected to grow until the document is complete. This is not just a matter of laziness: I‚Äôm very interested in building apps for mesh network style environments without any connectivity guarantees, and garbage collection immediately places constraints on the architecture of such a system. If you were using the CT for long-lived tasks such as database replication, messaging, or even preference syncing, you‚Äôd certainly want to implement one of the baselining strategies described in the ORDT section.</p>

<p>Some CRDTs offer native undo and redo functionality, but I‚Äôm quite happy with this being delegated to a higher level. For example, in the case of string CTs, <code class="highlighter-rouge">UITextView</code> seamlessly turns undo and redo commands into conventional deletes and inserts. Although this may result in excess garbage compared to explicit undo and redo operations, I think this sort of strictly local approach is more architecturally correct than the alternative. (I‚Äôm not in the camp that believes remote changes should be locally undoable.) As a performance tweak and compromise, it might make sense to keep new operations separate from the main CT and only merge them when some set amount of time has passed or when the user has paused their editing. If an undo happens, these pending operations could simply be dropped. My feeling is that this would significantly increase the complexity of certain functions in the CT and create a new vector for consistency issues, but it‚Äôs certainly worth investigating.</p>

<p>The atom priority flag adds so much to the CT‚Äôs expressiveness, and I think it could be improved even further by switching to a full integer. <code class="highlighter-rouge">INT_MIN</code> atoms would stick to their parent, <code class="highlighter-rouge">INT_MAX</code> atoms would float to the back, and the rest would be sorted in numeric order. I‚Äôm also eager to play around with alternate tree traversal orders: to see, for example, if a BFS weave might be faster than the current DFS weave for certain kinds of data. It‚Äôs not yet clear to me whether these changes might break some of our invariants or intractably slow down merge.</p>

<p>One huge advantage to storing the weave as a contiguous array is that it could be memory-mapped and used as an object‚Äôs backing data without having to deserialize it first. Better yet: if something like <a href="https://capnproto.org">Cap‚Äôn Proto</a> were used to represent the atoms, this property could even be retained across the network! A user would be able to receive CT data from a peer or from disk, work with those bytes directly, and then send them right back the way they came. In preparation for this scenario, it would be a good idea to leave a bit of extra space in each atom‚Äôs value for possible expansion of operations in the future. The validation function should also be made to throw an exception if an atom is discovered with an unknown case for its value enum.</p>

<p>My CT is only a dumb data structure, and as such, has no provisions for dealing with malicious users or Byzantine faults. A bad actor could easily spoof someone‚Äôs UUID and corrupt the data structure with a few choice atoms. The <code class="highlighter-rouge">validate</code> method would likely catch this attempt, but there‚Äôs no path for recovery after that. Consequently, production systems using CTs will likely need to deal with encryption and/or data recovery for when Bad Things happen. But that‚Äôs almost certainly a concern for a different architectural layer, not the data structure itself.</p>

<h1 id="conclusion">Conclusion</h1>

<p>Whew, that was a bit more than I intended to write!</p>

<p>I didn‚Äôt even think such a thing was possible, but CRDTs have proven to be that perfect convergent data type I set out to discover. You can use them in practically any computing environment and they will happily merge. They work offline just as well as online. They‚Äôre relatively easy to understand without having to write a dissertation. They‚Äôre composable with each other. You can use them for real-time collaboration, cloud sync, or local file sharing‚Äîall without requiring any network coordination.</p>

<p>But even more remarkable is the discovery of Causal Trees and operation-based CRDTs. With this reformulation of CRDTs, there‚Äôs finally a consistent way to understand, design, and implement arbitrary replicated data types. By breaking up conventional data structures into globally-unique atomic operations and giving them an order, you can construct efficient CRDTs out of practically anything. Operations can be sent around as-is or condensed into dense state snapshots, combining all the benefits of CmRDTs, CvRDTs, and even OT. Version vectors can be used to perform garbage collection, view past revisions, and otherwise divide up the document in an almost trivial way. Conflict resolution can be precisely tailored to fit the needs of the app and data type. Individual, atomic changes can be sourced to individual contributors and even linked to between ORDTs. Even simple objects can be made convergent with this approach, allowing coordination on the level of individual threads or processes. And all this can be done while <em>simplifying</em> the architecture, not mucking it up, since the paradigm is almost entirely functional!</p>

<p>Sure, there are tradeoffs compared to conventional, centralized sync techniques. For instance, CRDT data is always ‚Äúlive‚Äù, even while you‚Äôre offline. A user could accidentally edit their document on two offline devices, then find that they‚Äôve automatically merged into a mess on reconnection. The lack of an authoritative server gives malicious users a lot of power since they can irrevocably screw up a document without any possibility of a rollback. CRDTs have to maintain tons of extra data for convergence and require their peers to be smart and performant: server-based architectures are naturally more resource-efficient, and you‚Äôd also be hard-pressed to avoid them for data-heavy uses such as screen sharing or video editing. CRDTs are fairly rigid structures that require substantial pre-design and future-proofing. You can‚Äôt necessarily layer them on top of existing systems without significant refactoring.</p>

<p>A CRDT will never be as fast or bandwidth-efficient as Google Docs, for such is the power of centralization. But in exchange for a completely peer-to-peer computing future? A world full of systems able to own their data and freely collaborate with one another? Data-centeric code that‚Äôs entirely free from network concerns?</p>

<p>I‚Äôd say: it‚Äôs surely worth a try!</p>

<h1 id="references">References</h1>

<p><strong>OT Algorithm Papers</strong></p>

<ul>
  <li><a href="https://hal.inria.fr/file/index/docid/109039/filename/OsterCollaborateCom06.pdf">Tombstone Transformation Functions for Ensuring Consistency in Collaborative Editing Systems</a></li>
</ul>

<p><strong>CRDT Algorithm Papers</strong></p>

<ul>
  <li><a href="https://hal.inria.fr/inria-00555588/document">A Comprehensive Study of Convergent and Commutative Replicated Data Types</a></li>
  <li><a href="https://hal.archives-ouvertes.fr/inria-00108523/document">Data Consistency for P2P Collaborative Editing</a> (WOOT)</li>
  <li><a href="https://hal.inria.fr/inria-00397981/document">CRDTs: Consistency Without Concurrency Control</a> (Treedoc)</li>
  <li><a href="https://hal.inria.fr/inria-00336191/document">Logoot: A P2P Collaborative Editing System</a></li>
  <li><a href="https://hal.archives-ouvertes.fr/hal-00921633/document">LSEQ: An Adaptive Structure for Sequences in Distributed Collaborative Editing</a></li>
  <li><a href="https://pdfs.semanticscholar.org/8470/ae40470235604f40382aea4747275a6f6eef.pdf">Replicated Abstract Data Types: Building Blocks for Collaborative Applications</a> (RGA)</li>
  <li><a href="http://www.ds.ewi.tudelft.nl/~victor/articles/ctre.pdf">Deep Hypertext with Embedded Revision Control Implemented in Regular Expressions</a> (Causal Trees)</li>
</ul>

<p><strong>Operational CRDT Papers</strong></p>

<ul>
  <li><a href="https://arxiv.org/pdf/1710.04469.pdf">Pure Operation-Based Replicated Data Types</a></li>
</ul>

<p><strong>Other OT and CRDT Papers</strong></p>

<ul>
  <li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.933&amp;rep=rep1&amp;type=pdf">Operational Transformation in Real-Time Group Editors: Issues, Algorithms, and Achievements</a> (CP2/TP2)</li>
  <li><a href="https://hal.inria.fr/inria-00629503/document">Evaluating CRDTs for Real-Time Document Editing</a> (CRDT performance analysis)</li>
  <li><a href="https://hal.inria.fr/hal-01343941/document">High Responsiveness for Group Editing CRDTs</a> (CRDT performance analysis)</li>
  <li><a href="https://arxiv.org/pdf/1212.2338.pdf">Controlled Conflict Resolution for Replicated Document</a> (CRDT layering)</li>
</ul>

<p><strong>Non-Academic CRDT Writing</strong></p>

<ul>
  <li><a href="https://medium.com/@raphlinus/towards-a-unified-theory-of-operational-transformation-and-crdt-70485876f72f">Towards a Unified Theory of Operational Transformation and CRDT</a> (foundation for the CRDT used in xi)</li>
  <li><a href="https://speakerdeck.com/ept/convergence-versus-consensus-crdts-and-the-quest-for-distributed-consistency">Convergence Versus Consensus: CRDTs and the Quest for Distributed Consistency</a> (great illustrated overview by the Automerge folks)</li>
</ul>

<p><strong>Operational CRDT Code</strong></p>

<ul>
  <li><a href="https://github.com/gritzko/ron">Replicated Object Notation</a> (the <a href="https://github.com/gritzko/ron/tree/master/rdt">rdt folder</a> contains the CRDT definitions)</li>
</ul>

<p><strong>Non-Operational CRDT Code</strong></p>

<ul>
  <li><a href="http://google.github.io/xi-editor/docs/crdt-details.html">xi</a></li>
  <li><a href="https://github.com/automerge/automerge">Automerge</a></li>
  <li><a href="https://github.com/atom/teletype-crdt">Atom Teletype</a></li>
  <li><a href="https://github.com/y-js/yjs">Y.js</a></li>
</ul>

<p><strong>Other Materials</strong></p>

<ul>
  <li><a href="http://disi.unitn.it/~montreso/ds/handouts/03-gpe.pdf">Distributed Algorithms</a> (I thought this was a great primer)</li>
</ul>

<div class="footnotes">
  <ol>
    <li id="fn:commutes">
      <p>Although it‚Äôs most intuitive to think of individual operations as commuting (or not), commutativity is actually a property of the entire system as a whole and can be specified in many places. For example, a data structure might be entirely composed of operations that are naturally commutative (e.g. only addition), in which case nothing more needs to be done. Or: the system might be designed such that every event is uniquely timestamped, identified, and placed in a totally-ordered event log, which can then be re-parsed whenever remote changes are inserted before the endpoint. Or: the system might still be event-based, but instead of keeping around an event log, incoming concurrent operations are altered to ensure that their effect on the data structure is identical regardless of their order of arrival. So even if two operations might not be <em>naturally</em> commutative, they could still be made to commute <em>in effect</em> through a variety of methods. The trick is making sure that these ‚Äúcommutativity transformations‚Äù produce sensible results.¬†<a href="#fnref:commutes" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:op-crdt">
      <p>This might sound a lot like Operational Transformation! Superficially, the approach is very similar, but the operations don‚Äôt have to be transformed since the data structures already have commutativity built in. <code class="highlighter-rouge">insert B to the right of A</code> does not change its meaning even in the presence of concurrent operations, so long as A leaves a tombstone once it‚Äôs been deleted. Again, we‚Äôre focused on the data structures here. Their design comes first, and all the other parts follow.¬†<a href="#fnref:op-crdt" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:uuid">
      <p>Note that UUIDs with the right bit-length don‚Äôt really need coordination to ensure uniqueness. If your UUID is long enough‚Äî128 bits, let‚Äôs say‚Äîrandomly finding two UUIDs that collide would require generating a billion UUIDs every second for decades. Most applications probably don‚Äôt need to worry about this possibility. If they do, UUIDs might need to be generated and agreed upon out-of-band. Fortunately, there‚Äôs very often a way to get a UUID from the OS or the network layer.¬†<a href="#fnref:uuid" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:complexity">
      <p>Throughout the rest of this article, <em>n</em> will generally refer to the total number of operations in a data structure, while <em>s</em> will refer to the total number of sites.¬†<a href="#fnref:complexity" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:rga">
      <p>In fact, this is also how the RGA algorithm does its ordering, though it‚Äôs not described in terms of explicit operations and uses a different format for the metadata.¬†<a href="#fnref:rga" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:deleteref">
      <p>There‚Äôs that one delete at S1@T7 that requires backtracking, but we can fix it by using a priority flag for that operation type. More on that later.¬†<a href="#fnref:deleteref" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:awareness">
      <p>In the original paper, atoms don‚Äôt have Lamport timestamps, only indices, and atoms are compared by their <strong>awareness</strong> instead of by timestamp. An atom‚Äôs awareness is a <a href="https://en.wikipedia.org/wiki/Version_vector">version vector</a> (called a <strong>weft</strong>) that encompasses all the previous atoms its site would have known about at the time of its creation. This value is derived by recursively combining the awareness of the atom‚Äôs parent with the awareness of the previous atom in its <strong>yarn</strong> (or ordered sequence of atoms for a given site). Though awareness gives us more information than a simple Lamport timestamp, it is also <em>O</em>(<em>n</em>)-slow to derive and makes certain functions (such as validation and merge) substantially more complex. The 4 extra bytes per atom for the Lamport timestamp are therefore a worthwhile tradeoff, and also one which the author of the paper has used in <a href="https://github.com/gritzko/ron">subsequent work</a>.¬†<a href="#fnref:awareness" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:uuid2">
      <p>I mentioned earlier that UUIDs should use on the order of 128 bits to ensure uniqueness. However, having two 128-bit UUIDs per character is simply untenable. The compression scheme I devised for this problem is described further below.¬†<a href="#fnref:uuid2" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:lemma">
      <p>Lemma 2: simply iterate through the atoms to the right of your head atom until you find one whose parent has a lower Lamport timestamp than the head. This atom is the first atom past the causal block. Although the paper uses awareness in this lemma, you can easily show that this property applies to Lamport timestamps as well.¬†<a href="#fnref:lemma" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:ops">
      <p>And indeed, not all operations are necessarily meant to be executed! For example, the MVRegister CRDT is designed to present every possibility of a concurrent change to the user. ORDT operations are <em>simultaneously</em> events and data, and in some situations might be treated more like one than the other. <em>PORDT</em> describes it thusly: ‚Äúindeed, there are useful concurrent data types in which the outcomes of concurrent executions are not equivalent (on purpose) to some linearization.‚Äù¬†<a href="#fnref:ops" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:rewrite">
      <p>There are a few possible ways to deal with the garbage-collected (pre-baseline) portion of the ORDT. For example, the compacted operations could be stored as an ordered block of data in their own fenced-off area of the structured log. (This is the strategy that <em>PORDT</em> adopts with its causally stable operations.) However, there may be performance repercussions (and headaches) from having the data split into two parts like that, especially if you‚Äôre relying on spatial locality and random access for the mapper/eval functions. An alternative is to keep the compacted operations mixed in with the live operations, but to only remove operations with no children other than a delete operation. This might sound wasteful‚Äîalmost every deleted character will still have an adjacent character, right?‚Äîbut this property does cascade. Once the final operation at the end of a consecutive range of deletes is removed, the others can be picked off one by one in turn. And as an additional optimization, if a deleted operation‚Äôs only child (other than the delete) is another deleted operation, then the child can take the place of its parent. This bit of rewriting of history is harmless since no new operations can be knowingly added to deleted operations, but may involve some extra code complexity and checks. Compaction schemes will vary for other ORDTs. Keep in mind that in order for an ORDT to produce identical output before and after garbage collection, every operation possibly affected by the removal of an operation needs to be dealt with. With sequence ORDTs, these would only be the parent and concurrent children of a delete; with other ORDTs, possibly more than that.¬†<a href="#fnref:rewrite" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:preservation">
      <p>If we still had access to our site-to-version-vector map, we could pick a baseline common to every reasonably active site. This heuristic could be further improved by upgrading our Lamport timestamp to a <a href="http://sergeiturukin.com/2017/06/26/hybrid-logical-clocks.html">hybrid logical clock</a>. (A Lamport timestamp is allowed to be arbitrarily higher than the previous timestamp, not just +1 higher, so it can be combined with a physical timestamp and correction data to retain the approximate wall clock time for each operation.)¬†<a href="#fnref:preservation" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:baselines">
      <p>We have to use a sequence of baselines with this scheme and not just a baseline register because all sites, per CRDT rules, must end up with the same data after seeing the same set of operations. (Remember: this is the definition of strong eventual consistency!) With a register, if a site happens to miss a few baselines, it could end up retaining some meant-to-be-orphaned operations if a new baseline gets introduced that happens to include them. Now some sites would have the orphans and others wouldn‚Äôt. Inconsistency!¬†<a href="#fnref:baselines" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:lww">
      <p>In reality, in order to make the merge more meaningful and avoid artifacts, it would be better to keep around a sequence ORDT of session IDs alongside the bitmap. Each site would generate new session IDs at sensible intervals and add them to the end of the sequence, and each new pixel would reference the last available session ID. Pixels would be sorted first by session, then by timestamp+UUID. (Basically, these would function as ad hoc layers.) But LWW is easier to talk about, so let‚Äôs just go with that.¬†<a href="#fnref:lww" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:git">
      <p>And in fact, CT-based documents would be quite synergetic with regular git function! Instead of pointing to a file blob, each git commit would only need to retain a single version vector together with the commit message. The CT would already include all the relevant history and authorship information and could restore the commit‚Äôs view of the data from the version vector alone, assuming no garbage collection had taken place.¬†<a href="#fnref:git" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:causalpast">
      <p>Well, as long as the referenced atom is in the new atom‚Äôs causal past. What this means is that you shouldn‚Äôt reference atoms that aren‚Äôt already part of your CT, which‚Äîwhy would anyone do that? Are you smuggling atom IDs through a side channel or something? I suppose it might be a case worth adding to the <code class="highlighter-rouge">validate</code> method to help detect Byzantine faults.¬†<a href="#fnref:causalpast" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
    <li id="fn:latency">
      <p>This is a number pulled from several CRDT papers, but in principle, I‚Äôm more inclined to agree with Atom Xray‚Äôs <a href="https://github.com/atom/xray#high-performance">8ms target</a>. Regardless, the conclusions don‚Äôt change very much: <em>O</em>(<em>n</em>log<em>n</em>) remains sufficient even with very large files, and there are alternatives for the edge cases.¬†<a href="#fnref:latency" class="reversefootnote">&#8617;&#xfe0e;</a></p>
    </li>
  </ol>
</div>
<div class="signature">
    <p>‚Äî<span class="signature-name">Archagon</span></p>
    <p class="signature-date">March 24, 2018</p>
</div>

</article>

</div>
</div>

</div>

<footer class="site-footer">
    <!-- full-width background container -->
    <div class="site-footer-background header-footer-background">
        <!-- centered padded section -->
        <div class="site-footer-container wrapper">
            <div class="site-footer-credits">
                <p>Copyright &copy; 2017 Alexei Baboulevitch. ("It's copylicious!")</p>
            </div>
            <div class="site-footer-links"> <!-- not really a list, so I don't feel bad about using div -->
                <a href="/feed.xml"><img src="/images/feed-icon.png" class="header-footer-icon"> <span>Subscribe via RSS</span></a>
                <a href="https://twitter.com/archagon"><img src="/images/twitter-icon.png" class="header-footer-icon"> <span>Tweet me up</span></a>
            </div>
        </div>
    </div>
</footer>

<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-44612590-2', 'auto');
    ga('send', 'pageview');
</script>

</body>

</html>